{"source_id":"core","type":"context_engineering","title":"Context Engineering Fundamentals","signals":["context_engineering","provider_adapter"],"tags":["ai","context","llm","production"],"summary":"Context Engineering principles - the evolution from prompt engineering to dynamic, context-aware AI systems for production-grade deployment.","chunks":[{"chunk_id":"core:context-eng-fundamentals:1","text":"## Context Engineering Fundamentals\n\n### Definition\nContext Engineering is the discipline of designing and optimizing how information is assembled and provided to LLMs at inference time.\n\n### Context Components\n```\ncontext = Assemble(instructions, knowledge, tools, memory, state, query)\n```\n\n- **Instructions**: System prompts and rules\n- **Knowledge**: Retrieved relevant information (RAG)\n- **Tools**: Available function definitions\n- **Memory**: Conversation history and learned facts\n- **State**: Current world/user state\n- **Query**: User's immediate request\n\n### Key Principles\n1. **Dynamic Adaptation**: Context assembly adapts to each query and state\n2. **Information Optimization**: Maximize relevant information within token limits\n3. **Structural Sensitivity**: Format aligns with LLM processing capabilities\n4. **System-Level Design**: Multi-component optimization, not simple prompting\n\n### Context Failures (Common Issues)\n- Insufficient context leading to hallucination\n- Irrelevant context diluting important information\n- Missing state causing inconsistent responses\n- Token overflow dropping critical information","start_line":1,"end_line":28}]}
{"source_id":"core","type":"context_engineering","title":"Context Window Optimization","signals":["context_engineering"],"tags":["ai","optimization","tokens","production"],"summary":"Strategies for optimizing context window usage including compression, prioritization, and dynamic context selection.","chunks":[{"chunk_id":"core:context-window-opt:1","text":"## Context Window Optimization\n\n### Token Budget Strategy\n- **Reserved**: System prompt, tools (fixed overhead)\n- **Dynamic**: Knowledge, memory, conversation\n- **Buffer**: 10-20% for response generation\n\n### Prioritization Order\n1. Active task instructions (highest)\n2. Immediate context (current conversation)\n3. Retrieved knowledge (RAG results)\n4. Historical memory (summarized)\n5. Background context (lowest)\n\n### Compression Techniques\n- **Summarization**: Compress long histories\n- **Deduplication**: Remove redundant information\n- **Selective Retrieval**: Only most relevant chunks\n- **Progressive Disclosure**: Expand on demand\n\n### Dynamic Context Selection\n```python\ndef select_context(query, available_contexts, max_tokens):\n    ranked = rank_by_relevance(query, available_contexts)\n    selected = []\n    tokens_used = 0\n    for ctx in ranked:\n        if tokens_used + ctx.tokens <= max_tokens:\n            selected.append(ctx)\n            tokens_used += ctx.tokens\n    return selected\n```","start_line":1,"end_line":30}]}
{"source_id":"core","type":"contract","title":"AI Agent Contract Template","signals":["contract_lock","agent_pattern"],"tags":["ai","agent","llm","template"],"summary":"Contract template for AI agents covering capabilities, tools, memory, guardrails, and evaluation criteria.","chunks":[{"chunk_id":"core:ai-agent-contract:1","text":"## AI Agent Contract\n\n### Agent Overview\n- **Name**: [Agent Name]\n- **Role**: [System prompt role definition]\n- **Model**: GPT-4 / Claude 3.5 / Llama 3\n\n### Capabilities\n- **Tools**: List of available functions\n- **Memory**: Short-term (window) + Long-term (vector DB)\n- **Planning**: ReAct / Chain-of-Thought / Tree of Thoughts\n\n### Guardrails\n- **Input**: PII redaction, injection detection\n- **Output**: Hallucination check, tone enforcement\n- **Budget**: Token limits per request/session\n- **Safety**: Content filtering, refusal patterns\n\n### Evaluation Criteria\n- **Accuracy**: % correct on golden Q&A set\n- **Latency**: P95 response time < 3s\n- **Cost**: $ per 1000 interactions\n- **Safety**: 0 harmful outputs\n\n### Escalation\n- Uncertain responses → human review\n- Error rate > 5% → alert + fallback\n- Token budget exceeded → graceful degradation","start_line":1,"end_line":28}]}
{"source_id":"core","type":"contract","title":"Web App Contract Template","signals":["contract_lock"],"tags":["web","template"],"summary":"A structured template for defining web application project contracts with clear goals, requirements, and acceptance criteria.","chunks":[{"chunk_id":"core:web-contract:1","text":"## Web Application Contract\n\n### Project Overview\n- **Name**: [Project Name]\n- **Type**: Web Application\n- **Target Users**: [Primary user personas]\n\n### Goals\n1. [Primary business goal]\n2. [User experience goal]\n3. [Technical goal]\n\n### Requirements\n- **MUST**: [Critical requirements that block ship]\n- **SHOULD**: [Important but not blocking]\n- **COULD**: [Nice-to-have features]\n\n### Acceptance Criteria\n- [ ] All MUST requirements implemented\n- [ ] Core user flows working end-to-end\n- [ ] Performance within acceptable thresholds\n- [ ] No critical security vulnerabilities","start_line":1,"end_line":20}]}
{"source_id":"core","type":"contract","title":"API Contract Template","signals":["contract_lock"],"tags":["api","template","backend"],"summary":"Template for API development contracts covering endpoints, authentication, rate limits, and versioning requirements.","chunks":[{"chunk_id":"core:api-contract:1","text":"## API Contract\n\n### Service Overview\n- **API Name**: [Service Name]\n- **Base URL**: /api/v1\n- **Authentication**: [JWT/API Key/OAuth2]\n\n### Endpoints\n| Method | Path | Description | Auth Required |\n|--------|------|-------------|---------------|\n| GET | /resources | List all | Yes |\n| POST | /resources | Create new | Yes |\n| GET | /resources/:id | Get by ID | Yes |\n\n### Rate Limits\n- Standard: 100 req/min\n- Authenticated: 1000 req/min\n\n### Versioning\n- URL path versioning (/v1, /v2)\n- Deprecation notice: 90 days minimum","start_line":1,"end_line":20}]}
{"source_id":"core","type":"contract","title":"CLI Tool Contract Template","signals":["contract_lock","state_machine"],"tags":["cli","template","rust","node"],"summary":"Contract template for command-line tools covering commands, flags, exit codes, and cross-platform requirements.","chunks":[{"chunk_id":"core:cli-contract:1","text":"## CLI Tool Contract\n\n### Tool Overview\n- **Name**: [tool-name]\n- **Purpose**: [One-line description]\n- **Platforms**: Windows, macOS, Linux\n\n### Commands\n| Command | Description | Example |\n|---------|-------------|--------|\n| init | Initialize workspace | tool init |\n| run | Execute main action | tool run --config x.json |\n| status | Show current state | tool status -v |\n\n### Exit Codes\n- 0: Success\n- 1: General error\n- 2: Invalid arguments\n- 3: Configuration error\n\n### Distribution\n- Single binary, no runtime dependencies\n- Install via curl/powershell one-liner","start_line":1,"end_line":22}]}
{"source_id":"core","type":"contract","title":"Acceptance Criteria: Performance","signals":["contract_lock"],"tags":["performance","criteria","web","api"],"summary":"Common performance acceptance criteria patterns for web apps and APIs including response times, throughput, and resource limits.","chunks":[{"chunk_id":"core:perf-criteria:1","text":"## Performance Acceptance Criteria\n\n### Response Time\n- P50 latency < 100ms for API calls\n- P95 latency < 500ms\n- P99 latency < 1000ms\n- Page load (LCP) < 2.5 seconds\n\n### Throughput\n- Handle 1000 concurrent users\n- Process 100 requests/second sustained\n\n### Resource Usage\n- Memory < 512MB under normal load\n- CPU < 70% average utilization\n- No memory leaks over 24h run\n\n### Failure Tolerance\n- Graceful degradation under 2x expected load\n- Auto-recovery within 30 seconds","start_line":1,"end_line":18}]}
{"source_id":"core","type":"contract","title":"Acceptance Criteria: UX Patterns","signals":["contract_lock"],"tags":["ux","criteria","web","accessibility"],"summary":"User experience acceptance criteria covering accessibility, responsiveness, error handling, and loading states.","chunks":[{"chunk_id":"core:ux-criteria:1","text":"## UX Acceptance Criteria\n\n### Accessibility\n- WCAG 2.1 AA compliant\n- Keyboard navigation for all actions\n- Screen reader compatible\n- Color contrast ratio >= 4.5:1\n\n### Responsiveness\n- Mobile-first design (320px minimum)\n- Tablet breakpoint at 768px\n- Desktop breakpoint at 1024px\n\n### Loading States\n- Skeleton screens for async content\n- Loading indicator within 100ms\n- Progress for operations > 3 seconds\n\n### Error Handling\n- Clear error messages in plain language\n- Actionable recovery suggestions\n- No raw exception traces to users","start_line":1,"end_line":20}]}
{"source_id":"core","type":"contract","title":"Acceptance Criteria: Error States","signals":["contract_lock"],"tags":["errors","criteria","reliability"],"summary":"Error handling acceptance criteria for graceful failures, user-friendly messages, and recovery options.","chunks":[{"chunk_id":"core:error-criteria:1","text":"## Error State Acceptance Criteria\n\n### User-Facing Errors\n- Friendly message explaining what happened\n- Suggested next steps or workarounds\n- Support contact or documentation link\n- Unique error code for support lookup\n\n### System Errors\n- Logged with full stack trace\n- Correlated with request ID\n- Alerting for error rate spikes\n- No sensitive data in error messages\n\n### Recovery\n- Retry button for transient failures\n- Auto-retry with exponential backoff\n- Preserve user input on form errors\n- Graceful fallback for non-critical features","start_line":1,"end_line":18}]}
{"source_id":"core","type":"contract","title":"Acceptance Criteria: Security","signals":["contract_lock","security_pattern"],"tags":["security","criteria","authentication"],"summary":"Security acceptance criteria covering authentication, authorization, data protection, and vulnerability scanning.","chunks":[{"chunk_id":"core:security-criteria:1","text":"## Security Acceptance Criteria\n\n### Authentication\n- Strong password policy enforced\n- MFA option available\n- Session timeout after inactivity\n- Secure token storage (httpOnly cookies)\n\n### Authorization\n- Role-based access control (RBAC)\n- Principle of least privilege\n- Permission checks on every request\n\n### Data Protection\n- TLS 1.2+ for all connections\n- Sensitive data encrypted at rest\n- PII not logged or exposed\n- GDPR/CCPA compliance if applicable\n\n### Vulnerability Management\n- No critical CVEs in dependencies\n- Regular security scanning\n- Responsible disclosure process","start_line":1,"end_line":21}]}
{"source_id":"core","type":"contract","title":"Out-of-Scope Patterns","signals":["contract_lock"],"tags":["scope","planning"],"summary":"Common patterns for defining what is explicitly out of scope to prevent scope creep during development.","chunks":[{"chunk_id":"core:out-of-scope:1","text":"## Out-of-Scope Definition Patterns\n\n### Explicit Exclusions\n- Mobile native apps (web responsive only)\n- Offline mode (online-first for v1)\n- Third-party integrations (future phase)\n- Legacy browser support (IE11, old Safari)\n- Multi-language i18n (English only for v1)\n\n### Scope Creep Prevention\n- Document all scope changes in writing\n- Require stakeholder sign-off for additions\n- Assess impact on timeline before accepting\n- Create separate tickets for future features\n\n### Boundary Markers\n- \"Not in this release\" tracking list\n- Future roadmap for deferred items\n- Clear versioning for scope (v1 vs v2)","start_line":1,"end_line":18}]}
{"source_id":"core","type":"contract","title":"Scope Creep Prevention Checklist","signals":["contract_lock"],"tags":["scope","planning","checklist"],"summary":"Checklist to identify and prevent scope creep during project development lifecycle.","chunks":[{"chunk_id":"core:scope-creep:1","text":"## Scope Creep Prevention Checklist\n\n### Before Accepting New Work\n- [ ] Is this in the original contract?\n- [ ] What is the timeline impact?\n- [ ] What existing work gets deprioritized?\n- [ ] Who approved this change?\n- [ ] Is there budget for this addition?\n\n### Red Flags\n- \"While you're at it, can you also...\"\n- \"This should be quick...\"\n- \"We forgot to mention...\"\n- Vague requirements that keep expanding\n\n### Response Strategy\n- Log the request formally\n- Provide effort estimate\n- Present trade-offs clearly\n- Defer to next phase if possible","start_line":1,"end_line":19}]}
{"source_id":"core","type":"plan","title":"Web App Implementation Plan Template","signals":["state_machine"],"tags":["web","plan","template"],"summary":"Structured implementation plan template for web application development with phases, milestones, and dependencies.","chunks":[{"chunk_id":"core:web-plan:1","text":"## Web App Implementation Plan\n\n### Phase 1: Foundation (Week 1-2)\n- [ ] Project scaffolding and tooling\n- [ ] Design system setup (colors, typography)\n- [ ] Core layout components\n- [ ] Authentication flow\n- [ ] CI/CD pipeline\n\n### Phase 2: Core Features (Week 3-4)\n- [ ] Primary user flows\n- [ ] Data models and API integration\n- [ ] Form handling and validation\n- [ ] Error boundaries and loading states\n\n### Phase 3: Polish (Week 5)\n- [ ] Responsive design refinements\n- [ ] Performance optimization\n- [ ] Accessibility audit\n- [ ] Cross-browser testing\n\n### Phase 4: Ship (Week 6)\n- [ ] Final QA pass\n- [ ] Documentation\n- [ ] Deployment and monitoring","start_line":1,"end_line":24}]}
{"source_id":"core","type":"plan","title":"API Implementation Plan Template","signals":["state_machine"],"tags":["api","plan","template","backend"],"summary":"Implementation plan template for API development covering design, implementation, testing, and deployment phases.","chunks":[{"chunk_id":"core:api-plan:1","text":"## API Implementation Plan\n\n### Phase 1: Design (Week 1)\n- [ ] OpenAPI/Swagger spec draft\n- [ ] Data model design\n- [ ] Authentication strategy\n- [ ] Rate limiting approach\n- [ ] Error response format\n\n### Phase 2: Core Implementation (Week 2-3)\n- [ ] Database schema and migrations\n- [ ] CRUD endpoints\n- [ ] Input validation\n- [ ] Business logic layer\n- [ ] Unit tests (80% coverage target)\n\n### Phase 3: Integration (Week 4)\n- [ ] External service integrations\n- [ ] Webhook handlers\n- [ ] Background job processing\n- [ ] Integration tests\n\n### Phase 4: Production Ready (Week 5)\n- [ ] Load testing\n- [ ] Security audit\n- [ ] Documentation\n- [ ] Deployment runbook","start_line":1,"end_line":26}]}
{"source_id":"core","type":"plan","title":"CLI Tool Implementation Plan Template","signals":["state_machine"],"tags":["cli","plan","template"],"summary":"Implementation plan for CLI tool development covering argument parsing, commands, cross-compilation, and distribution.","chunks":[{"chunk_id":"core:cli-plan:1","text":"## CLI Tool Implementation Plan\n\n### Phase 1: Foundation (Week 1)\n- [ ] Argument parsing setup\n- [ ] Configuration file handling\n- [ ] Logging infrastructure\n- [ ] Error handling patterns\n- [ ] Basic help and version commands\n\n### Phase 2: Core Commands (Week 2-3)\n- [ ] Primary command implementation\n- [ ] Subcommand structure\n- [ ] Interactive prompts\n- [ ] Progress indicators\n- [ ] Output formatting (JSON, table, plain)\n\n### Phase 3: Polish (Week 4)\n- [ ] Shell completions\n- [ ] Man page generation\n- [ ] Cross-platform testing\n- [ ] Performance profiling\n\n### Phase 4: Distribution (Week 5)\n- [ ] Cross-compilation setup\n- [ ] Install scripts (curl, PowerShell)\n- [ ] Release automation\n- [ ] Checksum generation","start_line":1,"end_line":26}]}
{"source_id":"core","type":"plan","title":"Test Strategy Template","signals":["iterate_loop"],"tags":["testing","plan","strategy"],"summary":"Comprehensive test strategy template covering unit, integration, e2e testing, and quality gates.","chunks":[{"chunk_id":"core:test-strategy:1","text":"## Test Strategy\n\n### Test Pyramid\n- Unit Tests (70%): Fast, isolated, mock dependencies\n- Integration Tests (20%): Real database, API contracts\n- E2E Tests (10%): Critical user journeys only\n\n### Coverage Targets\n- Overall: 80% line coverage minimum\n- Critical paths: 95% coverage\n- New code: Must not decrease coverage\n\n### Quality Gates\n- All tests pass before merge\n- No flaky tests allowed\n- Performance regression detection\n- Security scan clean\n\n### Test Environment\n- Local: SQLite, mocked externals\n- CI: Docker-based, ephemeral\n- Staging: Production-like, seeded data","start_line":1,"end_line":20}]}
{"source_id":"core","type":"plan","title":"Rollback and Safety Plan","signals":["release_install"],"tags":["rollback","safety","deployment"],"summary":"Rollback strategy template for safe deployments including triggers, procedures, and communication plans.","chunks":[{"chunk_id":"core:rollback-plan:1","text":"## Rollback and Safety Plan\n\n### Rollback Triggers\n- Error rate > 5% for 5 minutes\n- P95 latency > 2x baseline\n- Critical functionality broken\n- Security vulnerability discovered\n\n### Rollback Procedure\n1. Alert team in incident channel\n2. Revert to previous deployment\n3. Verify rollback successful\n4. Investigate root cause\n5. Document in post-mortem\n\n### Safety Measures\n- Blue-green deployments\n- Canary releases (5% → 25% → 100%)\n- Feature flags for risky changes\n- Database migration rollback scripts\n\n### Communication\n- Status page update within 5 minutes\n- Customer notification for major issues","start_line":1,"end_line":22}]}
{"source_id":"core","type":"evidence","title":"Evidence Collection Checklist","signals":["evidence_audit"],"tags":["evidence","checklist","audit"],"summary":"Comprehensive checklist for collecting evidence during development including diffs, logs, test results, and lint reports.","chunks":[{"chunk_id":"core:evidence-checklist:1","text":"## Evidence Collection Checklist\n\n### Code Changes\n- [ ] Git diff captured\n- [ ] Commit message follows convention\n- [ ] PR description complete\n- [ ] Linked to issue/ticket\n\n### Test Evidence\n- [ ] Test output captured\n- [ ] Coverage report generated\n- [ ] All tests passing\n- [ ] No skipped tests without reason\n\n### Quality Checks\n- [ ] Lint output clean (or warnings documented)\n- [ ] Format check passing\n- [ ] Type check passing\n- [ ] Security scan results\n\n### Build Artifacts\n- [ ] Build log captured\n- [ ] Binary checksums generated\n- [ ] Artifact sizes documented","start_line":1,"end_line":22}]}
{"source_id":"core","type":"evidence","title":"Git Diff Capture Best Practices","signals":["evidence_audit"],"tags":["git","diff","evidence"],"summary":"Best practices for capturing meaningful git diffs as evidence of work completed.","chunks":[{"chunk_id":"core:git-diff:1","text":"## Git Diff Capture Best Practices\n\n### What to Capture\n- Staged changes: `git diff --cached`\n- All changes: `git diff HEAD`\n- Specific files: `git diff -- path/to/file`\n- Summary stats: `git diff --stat`\n\n### Diff Formatting\n- Include file names and line numbers\n- Context of 3-5 lines around changes\n- Binary files noted but not diffed\n- Large diffs split by component\n\n### Storage\n- Save as .patch files for replay\n- Timestamp in filename\n- Compress if > 1MB\n- Link to commit SHA","start_line":1,"end_line":18}]}
{"source_id":"core","type":"audit","title":"Audit Event Schema Guidance","signals":["evidence_audit"],"tags":["audit","schema","logging"],"summary":"Guidance for designing audit event schemas with required fields, optional metadata, and privacy considerations.","chunks":[{"chunk_id":"core:audit-schema:1","text":"## Audit Event Schema\n\n### Required Fields\n- timestamp: ISO 8601 format with timezone\n- event_type: Enum of known event types\n- actor: User or system identifier\n- action: What was done (create, update, delete)\n- resource: What was affected\n- session_id: Correlation identifier\n\n### Optional Metadata\n- ip_address: For security audits\n- user_agent: Client identification\n- duration_ms: For performance tracking\n- previous_value: For change tracking\n- new_value: For change tracking (redacted if sensitive)\n\n### Privacy\n- No PII in audit logs by default\n- Redact sensitive fields\n- Retention policy defined","start_line":1,"end_line":20}]}
{"source_id":"core","type":"audit","title":"Session Naming Conventions","signals":["evidence_audit"],"tags":["session","naming","convention"],"summary":"Naming conventions for development sessions to enable clear tracking and correlation of work.","chunks":[{"chunk_id":"core:session-naming:1","text":"## Session Naming Conventions\n\n### Format\n- Pattern: {date}_{type}_{short-desc}_{id}\n- Example: 2024-01-15_feat_auth-flow_a1b2c3\n\n### Types\n- feat: New feature development\n- fix: Bug fix session\n- refactor: Code improvement\n- docs: Documentation work\n- test: Test writing session\n- build: Build/CI changes\n\n### Best Practices\n- Keep description under 20 chars\n- Use lowercase with hyphens\n- Include random suffix for uniqueness\n- Never reuse session IDs","start_line":1,"end_line":18}]}
{"source_id":"core","type":"audit","title":"Audit Log Retention Policies","signals":["evidence_audit"],"tags":["audit","retention","compliance"],"summary":"Guidelines for audit log retention periods based on compliance requirements and business needs.","chunks":[{"chunk_id":"core:audit-retention:1","text":"## Audit Log Retention Policies\n\n### Standard Retention\n- Development logs: 30 days\n- Production logs: 90 days\n- Security events: 1 year\n- Financial transactions: 7 years\n\n### Compliance Requirements\n- GDPR: Right to be forgotten considerations\n- SOC2: Minimum 1 year for security events\n- HIPAA: 6 years for healthcare data\n- PCI-DSS: 1 year minimum\n\n### Storage Strategy\n- Hot storage: Last 7 days (fast query)\n- Warm storage: 8-90 days (compressed)\n- Cold storage: 90+ days (archived)\n- Deletion: Automated after retention period","start_line":1,"end_line":18}]}
{"source_id":"core","type":"iterate","title":"Diagnose Failing Tests Playbook","signals":["iterate_loop"],"tags":["testing","debug","playbook"],"summary":"Step-by-step playbook for diagnosing and understanding failing tests before attempting fixes.","chunks":[{"chunk_id":"core:diagnose-tests:1","text":"## Diagnose Failing Tests Playbook\n\n### Step 1: Read the Error\n- Full error message and stack trace\n- Expected vs actual values\n- Which assertion failed\n\n### Step 2: Reproduce Locally\n- Run the specific test in isolation\n- Check if it's flaky (run 3x)\n- Verify test data/fixtures are correct\n\n### Step 3: Identify Root Cause\n- Is it a test bug or code bug?\n- Did recent changes break it?\n- Is it an environment issue?\n\n### Step 4: Categorize\n- Assertion failure: Logic bug\n- Timeout: Performance or async issue\n- Setup failure: Environment or fixture\n- Random failure: Flaky test or race condition","start_line":1,"end_line":20}]}
{"source_id":"core","type":"iterate","title":"Fix Strategy Ladder","signals":["iterate_loop"],"tags":["fixing","strategy","debugging"],"summary":"Graduated approach to fixing issues from quick fixes to larger refactors, with clear escalation criteria.","chunks":[{"chunk_id":"core:fix-ladder:1","text":"## Fix Strategy Ladder\n\n### Level 1: Quick Fix (< 15 min)\n- Typo or minor syntax error\n- Missing import or dependency\n- Configuration value wrong\n- Simple logic inversion\n\n### Level 2: Standard Fix (15-60 min)\n- Logic bug in single function\n- Missing edge case handling\n- Incorrect API usage\n- Test fixture needs update\n\n### Level 3: Medium Refactor (1-4 hours)\n- Multiple related bugs\n- Interface change needed\n- Better abstraction required\n- Significant test updates\n\n### Level 4: Large Refactor (> 4 hours)\n- Architectural issue\n- Create separate ticket\n- Discuss with team first\n- May need design review","start_line":1,"end_line":24}]}
{"source_id":"core","type":"iterate","title":"Max Iterations Policy","signals":["iterate_loop"],"tags":["iterate","policy","limits"],"summary":"Policy for setting maximum iteration limits in automated test-fix loops to prevent infinite cycles.","chunks":[{"chunk_id":"core:max-iterations:1","text":"## Max Iterations Policy\n\n### Recommended Limits\n- Simple lint fixes: 3 iterations\n- Unit test fixes: 5 iterations\n- Integration tests: 10 iterations\n- Full build cycle: 10 iterations\n\n### Escalation Triggers\n- Same error 3 times in a row\n- No progress after 50% of max\n- Error count increasing\n- Timeout exceeded\n\n### On Limit Reached\n1. Stop automated fixing\n2. Save current state\n3. Generate diagnostic report\n4. Flag for human review\n5. Log all attempted fixes","start_line":1,"end_line":19}]}
{"source_id":"core","type":"iterate","title":"Strict Mode Guidelines","signals":["iterate_loop"],"tags":["strict","quality","gates"],"summary":"Guidelines for strict mode in iterate loops where any failure stops the process immediately.","chunks":[{"chunk_id":"core:strict-mode:1","text":"## Strict Mode Guidelines\n\n### When to Use Strict Mode\n- Critical production fixes\n- Security-sensitive code\n- Financial calculations\n- Data migration scripts\n- Release candidates\n\n### Strict Mode Behavior\n- Fail on first error (no retry)\n- Warnings treated as errors\n- All lints must pass\n- No skipped tests allowed\n- Coverage must not decrease\n\n### When to Relax\n- Early prototyping\n- Exploratory development\n- Non-critical documentation\n- Known flaky test exclusions","start_line":1,"end_line":19}]}
{"source_id":"core","type":"iterate","title":"Test-Lint-Fix Loop Pattern","signals":["iterate_loop"],"tags":["testing","lint","automation"],"summary":"Standard pattern for automated test-lint-fix loops with ordering and failure handling.","chunks":[{"chunk_id":"core:test-lint-fix:1","text":"## Test-Lint-Fix Loop Pattern\n\n### Execution Order\n1. Format check (fastest)\n2. Lint check\n3. Type check\n4. Unit tests\n5. Integration tests (if unit passes)\n\n### On Failure\n- Capture full output\n- Parse error locations\n- Attempt targeted fix\n- Re-run failed check only\n- Success: continue to next check\n- Fail again: increment attempt counter\n\n### Exit Conditions\n- All checks pass: Success\n- Max iterations reached: Stop with report\n- Unrecoverable error: Stop immediately\n- User interrupt: Save state and exit","start_line":1,"end_line":20}]}
{"source_id":"core","type":"security","title":"Secret Redaction Rules","signals":["security_pattern"],"tags":["security","secrets","redaction"],"summary":"Rules for automatically detecting and redacting secrets from logs, diffs, and outputs.","chunks":[{"chunk_id":"core:secret-redaction:1","text":"## Secret Redaction Rules\n\n### Detection Patterns\n- API keys: sk-*, pk-*, api_key=, apikey:\n- AWS: AKIA*, aws_secret_access_key\n- GitHub: ghp_*, gho_*, github_token\n- Bearer tokens: Bearer *, Authorization: *\n- Passwords: password=, passwd:, pwd=\n- Private keys: -----BEGIN * PRIVATE KEY-----\n- Connection strings: ://user:pass@\n\n### Redaction Format\n- Replace with: [REDACTED]\n- Or: ***HIDDEN***\n- Keep type hint: [REDACTED:API_KEY]\n\n### What NOT to Redact\n- Public keys\n- Non-secret environment variables\n- Documentation examples\n- Test fixture placeholders","start_line":1,"end_line":20}]}
{"source_id":"core","type":"security","title":"Ignore and Allow Glob Patterns","signals":["security_pattern"],"tags":["security","glob","configuration"],"summary":"Guidance for configuring ignore and allow glob patterns for file operations and harvesting.","chunks":[{"chunk_id":"core:glob-patterns:1","text":"## Ignore and Allow Glob Patterns\n\n### Common Ignore Patterns\n- node_modules/**\n- .git/**\n- *.log\n- *.tmp\n- .env*\n- dist/**\n- build/**\n- coverage/**\n- *.min.js\n- vendor/**\n\n### Allow Patterns (override ignores)\n- !.env.example\n- !.github/**\n- !docs/**\n\n### Best Practices\n- Be specific, avoid ** alone\n- Test patterns before applying\n- Document unusual patterns\n- Review regularly for drift","start_line":1,"end_line":23}]}
{"source_id":"core","type":"security","title":"Safe Subprocess Execution Checklist","signals":["security_pattern"],"tags":["security","subprocess","safety"],"summary":"Checklist for safely executing subprocesses and external commands in applications.","chunks":[{"chunk_id":"core:subprocess-safety:1","text":"## Safe Subprocess Execution Checklist\n\n### Before Execution\n- [ ] Validate all input parameters\n- [ ] Avoid shell=true when possible\n- [ ] Use absolute paths for executables\n- [ ] Set explicit working directory\n- [ ] Define timeout limits\n\n### During Execution\n- [ ] Capture stdout and stderr\n- [ ] Monitor resource usage\n- [ ] Handle signals gracefully\n- [ ] Stream output for long processes\n\n### After Execution\n- [ ] Check exit code\n- [ ] Validate output format\n- [ ] Clean up temp files\n- [ ] Log execution details (redacted)\n\n### Never Do\n- Concatenate user input into commands\n- Trust subprocess output blindly\n- Ignore non-zero exit codes","start_line":1,"end_line":24}]}
{"source_id":"core","type":"security","title":"Environment Variable Security","signals":["security_pattern"],"tags":["security","environment","configuration"],"summary":"Best practices for handling environment variables securely in applications.","chunks":[{"chunk_id":"core:env-security:1","text":"## Environment Variable Security\n\n### Sensitive Variables\n- Never log or print\n- Never include in error messages\n- Never commit to source control\n- Rotate regularly\n\n### Loading Order\n1. Defaults (non-sensitive)\n2. Config files (checked in)\n3. Environment variables (override)\n4. Command-line args (highest priority)\n\n### Validation\n- Check required vars on startup\n- Fail fast if missing critical vars\n- Provide helpful error messages\n- Document all required variables\n\n### Examples\n- .env.example with placeholders\n- README with setup instructions\n- CI/CD secret management","start_line":1,"end_line":22}]}
{"source_id":"core","type":"release","title":"Release Artifact Naming Conventions","signals":["release_install"],"tags":["release","naming","distribution"],"summary":"Standard naming conventions for release artifacts to ensure clarity and prevent confusion.","chunks":[{"chunk_id":"core:artifact-naming:1","text":"## Release Artifact Naming Conventions\n\n### Binary Naming\n- Pattern: {name}-{os}-{arch}[.ext]\n- Examples:\n  - myapp-linux-x64\n  - myapp-macos-arm64\n  - myapp-windows-x64.exe\n\n### Archive Naming\n- Pattern: {name}-{version}-{os}-{arch}.{ext}\n- Examples:\n  - myapp-1.2.3-linux-x64.tar.gz\n  - myapp-1.2.3-windows-x64.zip\n\n### OS Values\n- linux, darwin/macos, windows\n\n### Arch Values\n- x64/x86_64, arm64/aarch64\n- Prefer shorter forms for filenames","start_line":1,"end_line":20}]}
{"source_id":"core","type":"release","title":"Checksum Verification Patterns","signals":["release_install"],"tags":["release","checksum","security"],"summary":"Patterns for generating and verifying checksums in release workflows.","chunks":[{"chunk_id":"core:checksum-patterns:1","text":"## Checksum Verification Patterns\n\n### Generation\n- SHA256 for all release binaries\n- One line per file: {hash}  {filename}\n- File: checksums.txt or SHA256SUMS\n\n### Verification (Unix)\n```\ncurl -LO release.tar.gz\ncurl -LO checksums.txt\nsha256sum -c checksums.txt\n```\n\n### Verification (Windows)\n```powershell\n$hash = (Get-FileHash release.zip).Hash\n$expected = (Get-Content checksums.txt | Select-String release.zip)\nif ($hash -ne $expected) { throw \"Mismatch\" }\n```\n\n### Best Practices\n- Sign checksums file with GPG\n- Include in release notes\n- Automate in CI/CD","start_line":1,"end_line":24}]}
{"source_id":"core","type":"release","title":"Self-Update Safety Patterns","signals":["release_install"],"tags":["release","update","safety"],"summary":"Safety patterns for implementing self-update functionality in CLI tools.","chunks":[{"chunk_id":"core:self-update:1","text":"## Self-Update Safety Patterns\n\n### Pre-Update Checks\n- Verify version is actually newer\n- Check disk space available\n- Validate download URL domain\n- Verify checksum before replacing\n\n### Update Process\n1. Download to temp location\n2. Verify checksum\n3. Backup current binary\n4. Atomic replace (rename)\n5. Verify new binary runs\n6. Clean up temp files\n\n### Rollback Strategy\n- Keep .bak of previous version\n- Auto-rollback if new version fails\n- Provide manual rollback command\n\n### Platform Notes\n- Windows: Can't replace running exe directly\n- Unix: Can replace, but restart required","start_line":1,"end_line":22}]}
{"source_id":"core","type":"release","title":"Install Script Best Practices","signals":["release_install"],"tags":["release","install","distribution"],"summary":"Best practices for creating reliable cross-platform install scripts.","chunks":[{"chunk_id":"core:install-scripts:1","text":"## Install Script Best Practices\n\n### Unix (curl | bash)\n- Detect OS and architecture\n- Verify curl/wget available\n- Download to temp first\n- Verify checksum\n- Install to ~/.local/bin or /usr/local/bin\n- Prompt for sudo if needed\n- Update PATH instructions\n\n### Windows (PowerShell)\n- Use Invoke-RestMethod for download\n- Detect architecture (x64/arm64)\n- Install to ~\\.local\\bin\n- Use native Write-Host for colors\n- Add to PATH guidance\n\n### Both Platforms\n- Fail loudly on errors\n- Provide uninstall instructions\n- Show version after install\n- Support --version flag immediately","start_line":1,"end_line":21}]}
{"source_id":"core","type":"template","title":"Changelog Entry Format","signals":["release_install"],"tags":["changelog","release","documentation"],"summary":"Standard format for changelog entries following Keep a Changelog conventions.","chunks":[{"chunk_id":"core:changelog-format:1","text":"## Changelog Entry Format\n\n### Structure\n- Group by version (newest first)\n- Date in ISO format (YYYY-MM-DD)\n- Categories: Added, Changed, Deprecated, Removed, Fixed, Security\n\n### Example\n```markdown\n## [1.2.0] - 2024-01-15\n\n### Added\n- New `brain search` command for semantic search\n- Core BrainPack shipped with CLI\n\n### Fixed\n- PowerShell color rendering on Windows\n- Memory leak in harvest command\n\n### Security\n- Updated dependencies to fix CVE-2024-XXXX\n```\n\n### Best Practices\n- Use imperative mood (Add, Fix, not Added, Fixed)\n- Link to issues/PRs\n- No internal jargon","start_line":1,"end_line":25}]}
{"source_id":"core","type":"template","title":"PR Description Template","signals":["evidence_audit"],"tags":["template","pr","documentation"],"summary":"Pull request description template for clear communication of changes.","chunks":[{"chunk_id":"core:pr-template:1","text":"## Pull Request Description Template\n\n### What\n[One paragraph describing the change]\n\n### Why\n[Business or technical reason for the change]\n\n### How\n[Brief technical approach taken]\n\n### Testing\n- [ ] Unit tests added/updated\n- [ ] Integration tests pass\n- [ ] Manual testing completed\n\n### Checklist\n- [ ] Code follows style guidelines\n- [ ] Documentation updated\n- [ ] No breaking changes (or documented)\n- [ ] Reviewed by: @teammate\n\n### Screenshots\n[If UI changes, include before/after]","start_line":1,"end_line":22}]}
{"source_id":"core","type":"template","title":"Bug Report Template","signals":["evidence_audit"],"tags":["template","bug","documentation"],"summary":"Template for filing clear and actionable bug reports.","chunks":[{"chunk_id":"core:bug-template:1","text":"## Bug Report Template\n\n### Description\n[Clear, concise description of the bug]\n\n### Steps to Reproduce\n1. [First step]\n2. [Second step]\n3. [Third step]\n\n### Expected Behavior\n[What should happen]\n\n### Actual Behavior\n[What actually happens]\n\n### Environment\n- OS: [e.g., Windows 11, macOS 14]\n- Version: [e.g., v1.2.3]\n- Shell: [e.g., PowerShell 7, bash 5]\n\n### Additional Context\n- Screenshots if applicable\n- Error logs (redacted)\n- Related issues","start_line":1,"end_line":24}]}
{"source_id":"core","type":"plan","title":"Code Review Checklist","signals":["evidence_audit"],"tags":["review","checklist","quality"],"summary":"Comprehensive code review checklist covering functionality, code quality, testing, and security.","chunks":[{"chunk_id":"core:review-checklist:1","text":"## Code Review Checklist\n\n### Functionality\n- [ ] Code does what it claims to do\n- [ ] Edge cases handled\n- [ ] Error handling appropriate\n- [ ] No obvious logic bugs\n\n### Code Quality\n- [ ] Clear naming for variables/functions\n- [ ] No unnecessary complexity\n- [ ] DRY principle followed\n- [ ] Comments explain \"why\" not \"what\"\n\n### Testing\n- [ ] Tests cover new functionality\n- [ ] Tests are readable and maintainable\n- [ ] No flaky tests introduced\n- [ ] Edge cases tested\n\n### Security\n- [ ] No secrets in code\n- [ ] Input validation present\n- [ ] No SQL injection vectors\n- [ ] Dependencies checked for CVEs","start_line":1,"end_line":24}]}
{"source_id":"core","type":"iterate","title":"Common Lint Errors and Fixes","signals":["iterate_loop"],"tags":["lint","errors","fixing"],"summary":"Common lint errors encountered during development and their typical fixes.","chunks":[{"chunk_id":"core:lint-fixes:1","text":"## Common Lint Errors and Fixes\n\n### Unused Variables\n- Error: Variable defined but never used\n- Fix: Remove or prefix with underscore (_unused)\n\n### Missing Return Type\n- Error: Function missing explicit return type\n- Fix: Add return type annotation\n\n### Unused Imports\n- Error: Import not used in file\n- Fix: Remove unused import statements\n\n### Line Too Long\n- Error: Line exceeds maximum length\n- Fix: Break into multiple lines, extract variable\n\n### Mixed Indentation\n- Error: Tabs and spaces mixed\n- Fix: Use consistent indentation (prefer spaces)","start_line":1,"end_line":20}]}
{"source_id":"core","type":"iterate","title":"Build Error Resolution Guide","signals":["iterate_loop"],"tags":["build","errors","debugging"],"summary":"Guide for resolving common build errors across different build systems.","chunks":[{"chunk_id":"core:build-errors:1","text":"## Build Error Resolution Guide\n\n### Missing Dependency\n- Error: Cannot find module/crate\n- Fix: Add to package.json/Cargo.toml, run install\n\n### Version Mismatch\n- Error: Incompatible versions\n- Fix: Check lock file, update or pin versions\n\n### Type Error\n- Error: Type mismatch or missing\n- Fix: Correct type annotations, add conversions\n\n### Linking Error\n- Error: Undefined symbol\n- Fix: Check feature flags, add missing native deps\n\n### Out of Memory\n- Error: Build killed/OOM\n- Fix: Increase memory, use incremental builds","start_line":1,"end_line":20}]}
{"source_id":"core","type":"contract","title":"Definition of Done","signals":["contract_lock"],"tags":["criteria","done","checklist"],"summary":"Standard definition of done checklist for completing work items.","chunks":[{"chunk_id":"core:definition-done:1","text":"## Definition of Done\n\n### Code Complete\n- [ ] All acceptance criteria met\n- [ ] Code reviewed and approved\n- [ ] Tests written and passing\n- [ ] No known bugs introduced\n\n### Quality Complete\n- [ ] Lint and format checks pass\n- [ ] Coverage target maintained\n- [ ] No new security warnings\n- [ ] Performance within bounds\n\n### Documentation Complete\n- [ ] Code comments updated\n- [ ] README updated if needed\n- [ ] Changelog entry added\n- [ ] API docs regenerated\n\n### Deployment Ready\n- [ ] Merged to main branch\n- [ ] CI/CD pipeline green\n- [ ] Ready for release","start_line":1,"end_line":24}]}
{"source_id":"core","type":"contract","title":"MOSCOW Prioritization Guide","signals":["contract_lock"],"tags":["prioritization","planning","requirements"],"summary":"Guide for using MOSCOW method to prioritize requirements in contracts.","chunks":[{"chunk_id":"core:moscow-guide:1","text":"## MOSCOW Prioritization\n\n### MUST Have\n- Critical for delivery\n- System won't work without\n- Cannot workaround\n- Legal/compliance requirement\n\n### SHOULD Have\n- Important but not critical\n- Workaround exists\n- Expected by users\n- Significant value add\n\n### COULD Have\n- Nice to have\n- Low impact if missing\n- Can defer to later phase\n\n### WON'T Have (this time)\n- Explicitly excluded\n- Deferred to future scope\n- Document why excluded","start_line":1,"end_line":22}]}
{"source_id":"core","type":"evidence","title":"Test Output Capture Standards","signals":["evidence_audit"],"tags":["testing","output","evidence"],"summary":"Standards for capturing and preserving test output as evidence.","chunks":[{"chunk_id":"core:test-output:1","text":"## Test Output Capture Standards\n\n### What to Capture\n- Full stdout and stderr\n- Exit code\n- Duration of each test\n- Memory usage (if monitoring)\n- Timestamp of run\n\n### Output Format\n- Plain text for logs\n- JSON for machine processing\n- JUnit XML for CI integration\n\n### Storage\n- Session directory with timestamp\n- Compress after 24 hours\n- Retain for audit period\n- Include in evidence bundle","start_line":1,"end_line":18}]}
{"source_id":"core","type":"security","title":"CORS Configuration Patterns","signals":["security_pattern"],"tags":["security","cors","web"],"summary":"Cross-Origin Resource Sharing configuration patterns for web APIs.","chunks":[{"chunk_id":"core:cors-patterns:1","text":"## CORS Configuration Patterns\n\n### Restrictive (Recommended)\n- Allow-Origin: Specific domains only\n- Allow-Methods: Only needed methods\n- Allow-Headers: Specific required headers\n- Max-Age: Cache preflight for 24h\n\n### Permissive (Development Only)\n- Allow-Origin: *\n- Allow-Credentials: false (required with *)\n- Never use in production\n\n### Best Practices\n- Validate Origin header server-side\n- Don't trust only client validation\n- List allowed origins explicitly\n- Audit CORS config regularly","start_line":1,"end_line":17}]}
{"source_id":"core","type":"security","title":"Input Validation Patterns","signals":["security_pattern"],"tags":["security","validation","input"],"summary":"Common input validation patterns to prevent security vulnerabilities.","chunks":[{"chunk_id":"core:input-validation:1","text":"## Input Validation Patterns\n\n### String Inputs\n- Max length check\n- Allowed characters whitelist\n- Trim whitespace\n- Normalize unicode\n\n### Numeric Inputs\n- Range validation\n- Type coercion safety\n- Overflow prevention\n\n### File Inputs\n- Extension whitelist\n- MIME type validation\n- Max size limit\n- Virus scanning for uploads\n\n### URL Inputs\n- Protocol whitelist (https only)\n- Domain validation\n- Path traversal prevention\n- No localhost/internal IPs","start_line":1,"end_line":23}]}
{"source_id":"core","type":"template","title":"Post-Mortem Template","signals":["evidence_audit"],"tags":["template","incident","retrospective"],"summary":"Template for documenting and learning from production incidents.","chunks":[{"chunk_id":"core:postmortem-template:1","text":"## Post-Mortem Template\n\n### Incident Summary\n- Date/Time: [When it happened]\n- Duration: [How long]\n- Impact: [What was affected]\n- Severity: [P1/P2/P3/P4]\n\n### Timeline\n- [HH:MM] First alert triggered\n- [HH:MM] Team notified\n- [HH:MM] Root cause identified\n- [HH:MM] Mitigation applied\n- [HH:MM] Fully resolved\n\n### Root Cause\n[What actually caused the incident]\n\n### Action Items\n- [ ] Immediate fix\n- [ ] Preventive measures\n- [ ] Monitoring improvements\n- [ ] Documentation updates\n\n### Lessons Learned\n[What we learned, no blame]","start_line":1,"end_line":25}]}
{"source_id":"core","type":"plan","title":"Sprint Planning Template","signals":["state_machine"],"tags":["planning","sprint","agile"],"summary":"Template for sprint planning with capacity, goals, and commitment tracking.","chunks":[{"chunk_id":"core:sprint-template:1","text":"## Sprint Planning Template\n\n### Sprint Overview\n- Sprint: [Number]\n- Dates: [Start] to [End]\n- Capacity: [Story points available]\n\n### Sprint Goal\n[One clear, measurable goal]\n\n### Committed Items\n| ID | Title | Points | Owner |\n|----|-------|--------|-------|\n| T-1 | Feature X | 5 | @dev |\n| T-2 | Bug fix Y | 2 | @dev |\n\n### Stretch Goals\n[Items to pick up if time permits]\n\n### Dependencies\n- [External team/service dependencies]\n\n### Risks\n- [Known risks and mitigation]","start_line":1,"end_line":23}]}
{"source_id":"core","type":"iterate","title":"Performance Debugging Playbook","signals":["iterate_loop"],"tags":["performance","debugging","profiling"],"summary":"Playbook for diagnosing and fixing performance issues.","chunks":[{"chunk_id":"core:perf-debug:1","text":"## Performance Debugging Playbook\n\n### Step 1: Quantify\n- Measure current baseline\n- Define target improvement\n- Identify bottleneck metric (CPU, memory, I/O)\n\n### Step 2: Profile\n- Use profiler for CPU-bound\n- Memory analyzer for leaks\n- Trace for I/O-bound\n- Flame graphs for visualization\n\n### Step 3: Analyze\n- Find hotspots (top 20%)\n- Look for N+1 queries\n- Check cache hit rates\n- Review algorithm complexity\n\n### Step 4: Fix\n- Optimize hot paths first\n- Add caching where beneficial\n- Batch database queries\n- Lazy load where possible","start_line":1,"end_line":22}]}
{"source_id":"core","type":"evidence","title":"Coverage Report Interpretation","signals":["evidence_audit","iterate_loop"],"tags":["testing","coverage","metrics"],"summary":"How to interpret and act on code coverage reports.","chunks":[{"chunk_id":"core:coverage-interpret:1","text":"## Coverage Report Interpretation\n\n### Metrics Explained\n- Line coverage: % of lines executed\n- Branch coverage: % of decision paths\n- Function coverage: % of functions called\n\n### Healthy Targets\n- 80% overall is good baseline\n- 95% for critical paths\n- 100% for security-sensitive code\n\n### What to Ignore\n- Generated code\n- Vendor/third-party code\n- Unreachable error handlers\n- Deprecated code paths\n\n### Red Flags\n- Coverage drops on PR\n- Critical code uncovered\n- Tests exist but coverage low (assertions missing)","start_line":1,"end_line":20}]}
{"source_id":"core","type":"release","title":"Semantic Versioning Guide","signals":["release_install"],"tags":["versioning","release","semver"],"summary":"Guide to semantic versioning for release management.","chunks":[{"chunk_id":"core:semver-guide:1","text":"## Semantic Versioning Guide\n\n### Version Format: MAJOR.MINOR.PATCH\n\n### MAJOR (breaking)\n- Remove public API\n- Change behavior incompatibly\n- Major dependency update\n\n### MINOR (feature)\n- Add new capability\n- Deprecate (not remove) API\n- Backward-compatible changes\n\n### PATCH (fix)\n- Bug fixes\n- Security patches\n- Documentation updates\n- Performance improvements\n\n### Pre-release\n- Alpha: 1.0.0-alpha.1 (unstable)\n- Beta: 1.0.0-beta.1 (feature complete)\n- RC: 1.0.0-rc.1 (release candidate)","start_line":1,"end_line":22}]}
{"source_id":"core","type":"plan","title":"Technical Debt Tracking","signals":["state_machine"],"tags":["planning","debt","maintenance"],"summary":"Framework for identifying, prioritizing, and addressing technical debt.","chunks":[{"chunk_id":"core:tech-debt:1","text":"## Technical Debt Tracking\n\n### Categories\n- Code debt: Hacks, workarounds, copy-paste\n- Design debt: Poor abstractions, missing patterns\n- Test debt: Missing coverage, flaky tests\n- Dependency debt: Outdated packages, vulnerabilities\n- Documentation debt: Outdated docs, missing examples\n\n### Prioritization\n- Pain level (1-5): How much it hurts development\n- Effort (1-5): How much work to fix\n- Risk (1-5): Consequences if not addressed\n- Priority = Pain × Risk / Effort\n\n### Tracking\n- Tag tickets with tech-debt label\n- Allocate 20% sprint capacity\n- Track debt reduction over time\n- Celebrate debt paydown","start_line":1,"end_line":19}]}
{"source_id":"core","type":"security","title":"Dependency Scanning Patterns","signals":["security_pattern"],"tags":["security","dependencies","scanning"],"summary":"Patterns for scanning and managing dependency vulnerabilities.","chunks":[{"chunk_id":"core:dep-scanning:1","text":"## Dependency Scanning Patterns\n\n### Scan Frequency\n- On every PR (blocking)\n- Daily for main branch\n- Weekly full audit\n\n### Severity Handling\n- Critical: Block merge, fix immediately\n- High: Fix within 48 hours\n- Medium: Fix within 1 week\n- Low: Track, fix when convenient\n\n### Safe Update Strategy\n1. Review changelog\n2. Check for breaking changes\n3. Run test suite\n4. Deploy to staging first\n5. Monitor for issues\n\n### Tools\n- Native: npm audit, cargo audit\n- Dedicated: Dependabot, Snyk, Renovate","start_line":1,"end_line":21}]}
{"source_id":"core","type":"contract","title":"API Versioning Strategy","signals":["contract_lock"],"tags":["api","versioning","contract"],"summary":"Strategies for versioning APIs to maintain backward compatibility.","chunks":[{"chunk_id":"core:api-versioning:1","text":"## API Versioning Strategy\n\n### Methods\n- URL path: /api/v1/resource (recommended)\n- Header: Accept-Version: v1\n- Query param: ?version=1 (not recommended)\n\n### When to Version\n- Breaking response format change\n- Removing fields or endpoints\n- Changing authentication method\n- Incompatible behavior change\n\n### Deprecation Process\n1. Announce deprecation (90 days notice)\n2. Add Deprecation header\n3. Log usage of deprecated endpoints\n4. Notify active users directly\n5. Remove after notice period\n\n### Best Practices\n- Support N and N-1 versions\n- Clear migration guides\n- Sunset dates documented","start_line":1,"end_line":22}]}
{"source_id":"core","type":"template","title":"README Structure Template","signals":["evidence_audit"],"tags":["template","readme","documentation"],"summary":"Standard structure for project README files.","chunks":[{"chunk_id":"core:readme-template:1","text":"## README Structure Template\n\n### Essential Sections\n1. Title and badges\n2. One-line description\n3. Quick install command\n4. Minimal usage example\n5. Link to full documentation\n\n### Recommended Sections\n- Features list\n- Requirements/Prerequisites\n- Configuration options\n- Contributing guidelines\n- License information\n- Support channels\n\n### Best Practices\n- Keep main README concise\n- Link to detailed docs\n- Update with each release\n- Include screenshots for UI","start_line":1,"end_line":20}]}
{"source_id":"core","type":"provider","title":"AI Provider Adapter Pattern","signals":["provider_adapter"],"tags":["ai","provider","adapter","pattern"],"summary":"Pattern for creating abstracted AI provider adapters that can switch between different LLM backends.","chunks":[{"chunk_id":"core:provider-adapter:1","text":"## AI Provider Adapter Pattern\n\n### Interface Design\n- Define common interface/trait for all providers\n- Methods: send_prompt, stream_response, get_capabilities\n- Return unified response format\n\n### Implementation\n- Factory pattern for provider instantiation\n- Configuration-driven provider selection\n- Graceful fallback on provider failure\n\n### Example Providers\n- Claude (Anthropic)\n- GPT (OpenAI)\n- Local LLMs (Ollama)\n- Mock provider (testing)\n\n### Configuration\n- Environment variable for default\n- CLI flag override: --provider\n- Provider-specific settings in config","start_line":1,"end_line":20}]}
{"source_id":"core","type":"provider","title":"Provider Registry Pattern","signals":["provider_adapter"],"tags":["registry","plugin","extensibility"],"summary":"Registry pattern for dynamically registering and discovering providers.","chunks":[{"chunk_id":"core:provider-registry:1","text":"## Provider Registry Pattern\n\n### Purpose\n- Central catalog of available providers\n- Dynamic discovery and registration\n- Lazy initialization on first use\n\n### Implementation\n- Global HashMap/registry of provider factories\n- Register at startup or via plugins\n- Lookup by name: registry.get(\"claude\")\n\n### Best Practices\n- Default provider in registry\n- Clear error on unknown provider\n- List available providers in help\n- Log provider selection at startup","start_line":1,"end_line":16}]}
{"source_id":"core","type":"provider","title":"Provider Response Streaming","signals":["provider_adapter"],"tags":["streaming","async","response"],"summary":"Patterns for streaming responses from AI providers in real-time.","chunks":[{"chunk_id":"core:provider-streaming:1","text":"## Provider Response Streaming\n\n### Why Stream\n- Better perceived latency\n- User feedback during generation\n- Early termination option\n- Memory efficiency for long outputs\n\n### Implementation\n- Async iterator/stream pattern\n- Chunk-by-chunk processing\n- Progress indicator during stream\n- Buffer for partial tokens\n\n### Error Handling\n- Timeout per chunk, not total\n- Reconnect on stream break\n- Save partial output on error\n- Clear termination signals","start_line":1,"end_line":18}]}
{"source_id":"core","type":"provider","title":"Provider Rate Limiting","signals":["provider_adapter","security_pattern"],"tags":["rate-limit","throttling","api"],"summary":"Client-side rate limiting patterns for API providers.","chunks":[{"chunk_id":"core:provider-ratelimit:1","text":"## Provider Rate Limiting\n\n### Client-Side Throttling\n- Track requests per minute\n- Queue requests when near limit\n- Exponential backoff on 429\n\n### Implementation\n- Token bucket algorithm\n- Sliding window counter\n- Priority queue for requests\n\n### Best Practices\n- Respect Retry-After header\n- Log rate limit events\n- Fallback to secondary provider\n- User notification on wait","start_line":1,"end_line":16}]}
{"source_id":"core","type":"cli","title":"Rust CLI Argument Parsing (Clap)","signals":["command_surface"],"tags":["rust","cli","clap","arguments"],"summary":"Best practices for argument parsing in Rust CLIs using derive macros.","chunks":[{"chunk_id":"core:rust-clap:1","text":"## Rust CLI with Clap\n\n### Derive Pattern\n- #[derive(Parser)] for main struct\n- #[derive(Subcommand)] for commands\n- #[derive(ValueEnum)] for enums\n\n### Field Attributes\n- #[arg(short, long)] for flags\n- #[arg(default_value)] for defaults\n- #[arg(value_enum)] for choices\n- #[command(subcommand)] for nested\n\n### Best Practices\n- Short and long flags for common options\n- Sensible defaults reduce required args\n- Help strings with #[arg(help = ...)]\n- Examples in about text","start_line":1,"end_line":18}]}
{"source_id":"core","type":"cli","title":"Go CLI with Cobra","signals":["command_surface"],"tags":["go","cli","cobra","arguments"],"summary":"Patterns for building CLI tools in Go using Cobra framework.","chunks":[{"chunk_id":"core:go-cobra:1","text":"## Go CLI with Cobra\n\n### Structure\n- cmd/ package for command files\n- Root command with PersistentFlags\n- Subcommands added via AddCommand\n\n### Flags\n- StringVar for string flags\n- BoolP for boolean with short\n- Viper integration for config\n\n### Best Practices\n- PreRun for validation\n- RunE to return errors\n- SilenceUsage for clean errors\n- Completions for shell support","start_line":1,"end_line":16}]}
{"source_id":"core","type":"cli","title":"Node CLI with Commander","signals":["command_surface"],"tags":["node","cli","commander","javascript"],"summary":"Patterns for building CLI tools in Node.js using Commander.","chunks":[{"chunk_id":"core:node-commander:1","text":"## Node CLI with Commander\n\n### Setup\n- program.name().description().version()\n- program.command() for subcommands\n- .option() for flags\n- .argument() for positional\n\n### Patterns\n- Async action handlers\n- Error handling with try/catch\n- process.exit for status codes\n- chalk/colors for output\n\n### Distribution\n- bin field in package.json\n- Shebang: #!/usr/bin/env node\n- npm link for local testing","start_line":1,"end_line":17}]}
{"source_id":"core","type":"cli","title":"CLI Output Formatting","signals":["command_surface"],"tags":["cli","output","formatting","colors"],"summary":"Patterns for formatting CLI output including colors, tables, and progress.","chunks":[{"chunk_id":"core:cli-output:1","text":"## CLI Output Formatting\n\n### Color Usage\n- Green: success, completion\n- Yellow: warnings, caution\n- Red: errors, failures\n- Cyan: info, progress\n- Dim: secondary information\n\n### Structured Output\n- Tables for lists/comparisons\n- JSON with --json flag\n- Progress bars for long ops\n- Spinners for indeterminate\n\n### Best Practices\n- Respect NO_COLOR env var\n- TTY detection for colors\n- Quiet mode (--quiet)\n- Verbose mode (-v, -vv)","start_line":1,"end_line":19}]}
{"source_id":"core","type":"cli","title":"CLI Exit Codes","signals":["command_surface"],"tags":["cli","exit-codes","errors"],"summary":"Standard exit code conventions for CLI tools.","chunks":[{"chunk_id":"core:cli-exitcodes:1","text":"## CLI Exit Codes\n\n### Standard Codes\n- 0: Success\n- 1: General error\n- 2: Invalid usage/arguments\n- 3: Configuration error\n- 4: Resource not found\n- 126: Permission denied\n- 127: Command not found\n\n### Best Practices\n- Document exit codes in help\n- Consistent across commands\n- Non-zero = failed\n- Scripts rely on exit codes","start_line":1,"end_line":16}]}
{"source_id":"core","type":"cli","title":"CLI Configuration Hierarchy","signals":["command_surface"],"tags":["cli","config","hierarchy"],"summary":"Configuration precedence patterns for CLI tools.","chunks":[{"chunk_id":"core:cli-config:1","text":"## CLI Configuration Hierarchy\n\n### Precedence (high to low)\n1. Command-line flags\n2. Environment variables\n3. Local config (./.toolrc)\n4. User config (~/.config/tool)\n5. System config (/etc/tool)\n6. Built-in defaults\n\n### Implementation\n- Layer configs, override in order\n- Clear provenance logging\n- --config to specify file\n- --no-config to skip files\n\n### Validation\n- Validate combined config\n- Report which source won\n- Fail fast on conflicts","start_line":1,"end_line":19}]}
{"source_id":"core","type":"cli","title":"Interactive Prompts","signals":["command_surface"],"tags":["cli","interactive","prompts"],"summary":"Patterns for interactive CLI prompts and wizards.","chunks":[{"chunk_id":"core:cli-prompts:1","text":"## Interactive Prompts\n\n### Prompt Types\n- Text input: single line\n- Password: hidden input\n- Confirm: yes/no\n- Select: choose from list\n- Multi-select: checkboxes\n\n### Best Practices\n- Default values for quick accept\n- Validation with helpful errors\n- Non-interactive fallback (--yes)\n- CI detection: skip prompts\n\n### UX\n- Clear prompts explain what's needed\n- Allow going back in wizards\n- Summary before final action","start_line":1,"end_line":18}]}
{"source_id":"core","type":"security","title":"Token Storage Best Practices","signals":["security_pattern"],"tags":["security","tokens","storage"],"summary":"Secure patterns for storing authentication tokens in CLI tools.","chunks":[{"chunk_id":"core:token-storage:1","text":"## Token Storage Best Practices\n\n### Secure Options (Preferred)\n- System keychain (keyring crate)\n- OS credential store\n- Encrypted config file\n\n### Fallback Options\n- File with 600 permissions\n- Environment variable (session only)\n- Never in command history\n\n### Implementation\n- Prompt for token if missing\n- Validate token on storage\n- Clear token on logout\n- Rotate token periodically","start_line":1,"end_line":17}]}
{"source_id":"core","type":"security","title":"Command Injection Prevention","signals":["security_pattern"],"tags":["security","injection","commands"],"summary":"Patterns to prevent command injection vulnerabilities.","chunks":[{"chunk_id":"core:cmd-injection:1","text":"## Command Injection Prevention\n\n### Never Do\n- shell=true with user input\n- String concatenation for commands\n- eval() on external input\n\n### Safe Patterns\n- Array of arguments (no shell)\n- Allowlist valid inputs\n- Escape special characters\n- Validate before execution\n\n### Example (safe)\n- Command::new(\"git\").arg(\"clone\").arg(url)\n- Not: format!(\"git clone {}\", url)","start_line":1,"end_line":16}]}
{"source_id":"core","type":"security","title":"Path Traversal Prevention","signals":["security_pattern"],"tags":["security","path","traversal"],"summary":"Preventing path traversal attacks in file operations.","chunks":[{"chunk_id":"core:path-traversal:1","text":"## Path Traversal Prevention\n\n### Attack Patterns\n- ../../../etc/passwd\n- Encoded: %2e%2e%2f\n- Null bytes: file.txt\\0.jpg\n\n### Defenses\n- Canonicalize paths\n- Check starts_with(allowed_root)\n- Reject .. components\n- Normalize before comparison\n\n### Implementation\n- PathBuf::canonicalize()\n- path.starts_with(&base_dir)\n- Reject absolute paths when relative expected","start_line":1,"end_line":16}]}
{"source_id":"core","type":"release","title":"Binary Stripping Best Practices","signals":["release_install"],"tags":["release","binary","optimization"],"summary":"Reducing binary size for release distributions.","chunks":[{"chunk_id":"core:binary-strip:1","text":"## Binary Stripping\n\n### Rust Release Optimization\n- strip = true in Cargo.toml\n- lto = true for link-time opt\n- opt-level = \"z\" for size\n- panic = \"abort\" (no unwinding)\n\n### Post-Build\n- strip --strip-all binary\n- UPX compression (optional)\n\n### Size Targets\n- CLI tools: < 10MB ideal\n- Plugins: < 5MB\n- WASM: < 1MB","start_line":1,"end_line":15}]}
{"source_id":"core","type":"release","title":"GitHub Actions Release Workflow","signals":["release_install"],"tags":["release","github-actions","ci"],"summary":"Pattern for automated releases via GitHub Actions.","chunks":[{"chunk_id":"core:gh-release-workflow:1","text":"## GitHub Actions Release Workflow\n\n### Trigger\n- on: push: tags: [\"v*.*.*\"]\n- Creates release on tag push\n\n### Jobs\n1. Build matrix: [linux, macos, windows] x [x64, arm64]\n2. Create checksums\n3. Create GitHub release\n4. Upload assets\n\n### Best Practices\n- Matrix for cross-compile\n- Artifact upload between jobs\n- Release notes from changelog\n- Draft release first, publish after verify","start_line":1,"end_line":17}]}
{"source_id":"core","type":"release","title":"Release Changelog Generation","signals":["release_install"],"tags":["release","changelog","automation"],"summary":"Automated changelog generation from commit history.","chunks":[{"chunk_id":"core:changelog-gen:1","text":"## Changelog Generation\n\n### Conventional Commits\n- feat: → Added section\n- fix: → Fixed section\n- docs: → Documentation\n- BREAKING CHANGE: → highlighted\n\n### Tools\n- git-cliff (Rust)\n- conventional-changelog (Node)\n- github-changelog-generator\n\n### Best Practices\n- Generate from tags\n- Include PR links\n- Categorize by type\n- Highlight breaking changes","start_line":1,"end_line":17}]}
{"source_id":"core","type":"template","title":"GitHub Issue Templates","signals":["evidence_audit"],"tags":["template","github","issues"],"summary":"Templates for GitHub issue forms to gather structured information.","chunks":[{"chunk_id":"core:issue-templates:1","text":"## GitHub Issue Templates\n\n### Bug Report Template\n- Description: What happened?\n- Steps to reproduce: 1, 2, 3\n- Expected vs actual behavior\n- Environment: OS, version, shell\n- Screenshots/logs if applicable\n\n### Feature Request Template\n- Problem to solve\n- Proposed solution\n- Alternatives considered\n- Additional context\n\n### Location\n- .github/ISSUE_TEMPLATE/\n- bug_report.yml\n- feature_request.yml","start_line":1,"end_line":18}]}
{"source_id":"core","type":"template","title":"Pull Request Template","signals":["evidence_audit"],"tags":["template","github","pr"],"summary":"Template for consistent pull request descriptions.","chunks":[{"chunk_id":"core:pr-template-file:1","text":"## Pull Request Template\n\n### Location\n- .github/PULL_REQUEST_TEMPLATE.md\n\n### Sections\n- What: Brief description of changes\n- Why: Reason/motivation for change\n- How: Technical approach taken\n- Testing: How this was tested\n- Checklist: Standard checks\n\n### Checklist Items\n- [ ] Tests added/updated\n- [ ] Docs updated\n- [ ] Changelog entry\n- [ ] Breaking changes noted","start_line":1,"end_line":17}]}
{"source_id":"core","type":"iterate","title":"Flaky Test Detection","signals":["iterate_loop"],"tags":["testing","flaky","detection"],"summary":"Patterns for detecting and handling flaky tests.","chunks":[{"chunk_id":"core:flaky-tests:1","text":"## Flaky Test Detection\n\n### Indicators\n- Passes locally, fails in CI\n- Fails intermittently\n- Order-dependent results\n- Time-sensitive assertions\n\n### Detection Strategy\n- Run test N times (e.g., 10x)\n- Different orders each run\n- Track historical pass rate\n- Flag tests with < 100% rate\n\n### Remediation\n- Fix root cause if possible\n- Quarantine while fixing\n- Add retry with backoff\n- Mark with skip reason","start_line":1,"end_line":18}]}
{"source_id":"core","type":"iterate","title":"Test Fixture Management","signals":["iterate_loop"],"tags":["testing","fixtures","data"],"summary":"Patterns for managing test fixtures and data.","chunks":[{"chunk_id":"core:test-fixtures:1","text":"## Test Fixture Management\n\n### Types\n- Static: JSON/YAML files in tests/\n- Generated: Created per test\n- Shared: Setup once, use many\n- Database: Seeded schemas\n\n### Best Practices\n- Isolate tests with unique fixtures\n- Clean up after tests\n- Version fixtures with code\n- Document fixture schema\n\n### Naming\n- test_data/scenario_name.json\n- fixtures/valid_user.json\n- mocks/api_response.json","start_line":1,"end_line":17}]}
{"source_id":"core","type":"iterate","title":"Test Timeout Configuration","signals":["iterate_loop"],"tags":["testing","timeout","configuration"],"summary":"Configuring appropriate timeouts for different test types.","chunks":[{"chunk_id":"core:test-timeouts:1","text":"## Test Timeout Configuration\n\n### Guidelines by Type\n- Unit tests: 100ms - 1s\n- Integration tests: 5-30s\n- E2E tests: 30s - 2min\n- Performance tests: as needed\n\n### Configuration\n- Default timeout per suite\n- Override per test annotation\n- Environment variable for CI\n\n### On Timeout\n- Kill and report failure\n- Log what was running\n- Check for resource leaks\n- Investigate slow tests","start_line":1,"end_line":16}]}
{"source_id":"core","type":"evidence","title":"Snapshot Testing Patterns","signals":["evidence_audit"],"tags":["testing","snapshots","evidence"],"summary":"Using snapshot testing for regression detection.","chunks":[{"chunk_id":"core:snapshot-testing:1","text":"## Snapshot Testing\n\n### Purpose\n- Capture expected output\n- Detect unintended changes\n- Review diffs easily\n\n### Implementation\n- Store snapshots alongside tests\n- Update with command flag\n- Review in PR diffs\n\n### Best Practices\n- Normalize timestamps/IDs\n- Human-readable formats\n- Commit snapshots to git\n- Small, focused snapshots","start_line":1,"end_line":16}]}
{"source_id":"core","type":"evidence","title":"Build Artifact Metadata","signals":["evidence_audit","release_install"],"tags":["build","artifacts","metadata"],"summary":"Recording metadata about build artifacts.","chunks":[{"chunk_id":"core:build-metadata:1","text":"## Build Artifact Metadata\n\n### What to Record\n- Commit SHA\n- Build timestamp\n- Builder (CI job ID)\n- Compiler version\n- Dependencies locked versions\n\n### Format\n- buildinfo.json alongside binary\n- Embedded in binary (--version)\n- Release notes attachment\n\n### Usage\n- Reproducibility verification\n- Bug report debugging\n- Audit trail","start_line":1,"end_line":16}]}
{"source_id":"core","type":"plan","title":"Dependency Update Strategy","signals":["state_machine"],"tags":["dependencies","planning","maintenance"],"summary":"Strategy for keeping dependencies updated safely.","chunks":[{"chunk_id":"core:dep-update:1","text":"## Dependency Update Strategy\n\n### Frequency\n- Security: immediately\n- Major: quarterly review\n- Minor/Patch: monthly batch\n\n### Process\n1. Review changelog\n2. Check breaking changes\n3. Update in feature branch\n4. Full test suite\n5. Staged rollout\n\n### Automation\n- Dependabot/Renovate for PRs\n- Auto-merge for patch versions\n- Require approval for major","start_line":1,"end_line":17}]}
{"source_id":"core","type":"plan","title":"Feature Flag Strategy","signals":["state_machine"],"tags":["feature-flags","planning","rollout"],"summary":"Using feature flags for safe feature rollout.","chunks":[{"chunk_id":"core:feature-flags:1","text":"## Feature Flag Strategy\n\n### Types\n- Release flags: hide incomplete features\n- Experiment flags: A/B testing\n- Ops flags: kill switches\n\n### Implementation\n- Boolean flag at minimum\n- Percentage rollout if needed\n- User targeting for betas\n\n### Lifecycle\n1. Create flag (default off)\n2. Develop behind flag\n3. Test with flag on\n4. Gradual rollout\n5. Clean up flag when stable","start_line":1,"end_line":17}]}
{"source_id":"core","type":"contract","title":"Data Migration Contract","signals":["contract_lock"],"tags":["migration","data","contract"],"summary":"Contract template for database migrations.","chunks":[{"chunk_id":"core:migration-contract:1","text":"## Data Migration Contract\n\n### Pre-Migration\n- [ ] Backup completed\n- [ ] Rollback script ready\n- [ ] Downtime window communicated\n- [ ] Dry run successful\n\n### Migration Steps\n- [ ] Run migration script\n- [ ] Verify data integrity\n- [ ] Update application code\n- [ ] Monitor for issues\n\n### Rollback Criteria\n- Data loss detected\n- Error rate > threshold\n- Performance degradation\n- User reports of issues","start_line":1,"end_line":18}]}
{"source_id":"core","type":"contract","title":"Integration Points Contract","signals":["contract_lock"],"tags":["integration","api","contract"],"summary":"Defining integration points and responsibilities.","chunks":[{"chunk_id":"core:integration-contract:1","text":"## Integration Points Contract\n\n### For Each Integration\n- Endpoint/interface specification\n- Authentication method\n- Rate limits and quotas\n- Error handling expectations\n- SLA requirements\n\n### Responsibilities\n- Provider: uptime, documentation\n- Consumer: rate limit respect, error handling\n- Both: communication on changes\n\n### Change Management\n- 30 day notice for breaking changes\n- Version new endpoints\n- Maintain backward compatibility","start_line":1,"end_line":16}]}
{"source_id":"core","type":"security","title":"Logging Sensitive Data Rules","signals":["security_pattern"],"tags":["logging","security","privacy"],"summary":"Rules for what should never appear in logs.","chunks":[{"chunk_id":"core:log-security:1","text":"## Logging Sensitive Data Rules\n\n### Never Log\n- Passwords or password hashes\n- API keys or tokens\n- Credit card numbers\n- Social security numbers\n- Session identifiers\n- Full request bodies with PII\n\n### Redaction Patterns\n- Authorization: [REDACTED]\n- \"password\": \"***\"\n- First 4 / Last 4 only\n\n### Safe Logging\n- User IDs (if not PII)\n- Request IDs\n- Timestamps\n- Status codes\n- General error categories","start_line":1,"end_line":19}]}
{"source_id":"core","type":"security","title":"HTTPS Configuration Checklist","signals":["security_pattern"],"tags":["security","https","tls"],"summary":"Checklist for secure HTTPS configuration.","chunks":[{"chunk_id":"core:https-config:1","text":"## HTTPS Configuration Checklist\n\n### Minimum Requirements\n- [ ] TLS 1.2 minimum (prefer 1.3)\n- [ ] Strong cipher suites only\n- [ ] Valid certificate chain\n- [ ] HSTS header enabled\n\n### Headers\n- Strict-Transport-Security\n- X-Content-Type-Options: nosniff\n- X-Frame-Options: DENY\n- Content-Security-Policy\n\n### Certificate Management\n- Auto-renewal (Let's Encrypt)\n- Expiry monitoring\n- Key rotation schedule","start_line":1,"end_line":17}]}
{"source_id":"core","type":"template","title":"Contributing Guidelines Template","signals":["evidence_audit"],"tags":["template","contributing","documentation"],"summary":"Template for project contributing guidelines.","chunks":[{"chunk_id":"core:contributing-template:1","text":"## Contributing Guidelines Template\n\n### Getting Started\n- Fork and clone repository\n- Install dependencies\n- Run tests locally\n- Read code of conduct\n\n### Making Changes\n- Create feature branch\n- Make focused commits\n- Write/update tests\n- Update documentation\n\n### Submitting\n- Open pull request\n- Fill out PR template\n- Respond to feedback\n- Squash if requested","start_line":1,"end_line":18}]}
{"source_id":"core","type":"template","title":"Code of Conduct Template","signals":["evidence_audit"],"tags":["template","conduct","community"],"summary":"Template for project code of conduct.","chunks":[{"chunk_id":"core:coc-template:1","text":"## Code of Conduct Summary\n\n### Expected Behavior\n- Be respectful and inclusive\n- Focus on constructive feedback\n- Accept differing viewpoints\n- Show empathy to others\n\n### Unacceptable Behavior\n- Harassment or discrimination\n- Personal attacks\n- Trolling or insulting comments\n- Publishing others' private info\n\n### Enforcement\n- Reports to maintainers\n- Investigation within 1 week\n- Actions: warning to ban\n- All decisions final","start_line":1,"end_line":18}]}
{"source_id":"core","type":"iterate","title":"Memory Leak Detection","signals":["iterate_loop"],"tags":["debugging","memory","performance"],"summary":"Detecting and fixing memory leaks in applications.","chunks":[{"chunk_id":"core:memory-leaks:1","text":"## Memory Leak Detection\n\n### Symptoms\n- Memory usage grows over time\n- Out of memory errors\n- Performance degradation\n- Process restart \"fixes\" it\n\n### Detection Tools\n- valgrind (C/C++)\n- heaptrack\n- Browser DevTools (JS)\n- Memory profilers\n\n### Common Causes\n- Event listeners not removed\n- Caches without limits\n- Circular references\n- Global state accumulation","start_line":1,"end_line":17}]}
{"source_id":"core","type":"iterate","title":"Deadlock Debugging","signals":["iterate_loop"],"tags":["debugging","concurrency","deadlock"],"summary":"Identifying and resolving deadlock issues.","chunks":[{"chunk_id":"core:deadlock-debug:1","text":"## Deadlock Debugging\n\n### Symptoms\n- Application hangs\n- No CPU usage but no progress\n- Multiple threads waiting\n\n### Detection\n- Thread dump analysis\n- Lock ordering analysis\n- Timeout-based detection\n\n### Prevention\n- Consistent lock ordering\n- Lock timeouts\n- Avoid nested locks\n- Use lock-free structures where possible\n- Document lock order requirements","start_line":1,"end_line":16}]}
{"source_id":"core","type":"plan","title":"API Design Checklist","signals":["contract_lock"],"tags":["api","design","checklist"],"summary":"Checklist for designing consistent, usable APIs.","chunks":[{"chunk_id":"core:api-design:1","text":"## API Design Checklist\n\n### Naming\n- [ ] Consistent resource naming\n- [ ] Plural nouns for collections\n- [ ] Descriptive action names\n\n### Structure\n- [ ] RESTful conventions\n- [ ] Consistent response format\n- [ ] Pagination for lists\n- [ ] Filtering and sorting\n\n### Usability\n- [ ] Clear error messages\n- [ ] Examples in documentation\n- [ ] Rate limit headers\n- [ ] Versioning strategy","start_line":1,"end_line":17}]}
{"source_id":"core","type":"plan","title":"Database Schema Guidelines","signals":["state_machine"],"tags":["database","schema","design"],"summary":"Guidelines for designing database schemas.","chunks":[{"chunk_id":"core:db-schema:1","text":"## Database Schema Guidelines\n\n### General\n- Use UUIDs or auto-increment for PKs\n- Timestamps: created_at, updated_at\n- Soft delete with deleted_at\n- Foreign keys with constraints\n\n### Naming\n- snake_case for columns\n- Plural table names\n- Prefix indexes: idx_table_column\n\n### Performance\n- Index frequently queried columns\n- Avoid SELECT *\n- Normalize, then denormalize if needed\n- Partition large tables","start_line":1,"end_line":17}]}
{"source_id":"core","type":"evidence","title":"Metrics Collection Patterns","signals":["evidence_audit"],"tags":["metrics","monitoring","observability"],"summary":"Patterns for collecting useful metrics.","chunks":[{"chunk_id":"core:metrics-patterns:1","text":"## Metrics Collection Patterns\n\n### Key Metrics\n- Latency (p50, p95, p99)\n- Throughput (req/sec)\n- Error rate (%)\n- Saturation (queue depth)\n\n### Implementation\n- Counters for totals\n- Gauges for current values\n- Histograms for distributions\n\n### Best Practices\n- Meaningful metric names\n- Consistent labels/tags\n- Avoid high cardinality\n- Alert on thresholds","start_line":1,"end_line":17}]}
{"source_id":"core","type":"evidence","title":"Distributed Tracing Basics","signals":["evidence_audit"],"tags":["tracing","observability","debugging"],"summary":"Basic patterns for implementing distributed tracing.","chunks":[{"chunk_id":"core:dist-tracing:1","text":"## Distributed Tracing Basics\n\n### Concepts\n- Trace: full request journey\n- Span: single operation\n- Context: passed between services\n\n### Implementation\n- Generate trace ID at entry\n- Propagate via headers\n- Create spans for key operations\n- Log trace ID for correlation\n\n### What to Trace\n- HTTP requests\n- Database queries\n- External service calls\n- Async job processing","start_line":1,"end_line":17}]}
{"source_id":"core","type":"release","title":"Staged Rollout Patterns","signals":["release_install"],"tags":["release","rollout","deployment"],"summary":"Patterns for gradually rolling out releases.","chunks":[{"chunk_id":"core:staged-rollout:1","text":"## Staged Rollout Patterns\n\n### Stages\n1. Internal dogfooding (1%)\n2. Canary (5%)\n3. Early adopters (25%)\n4. General availability (100%)\n\n### Monitoring Between Stages\n- Error rates\n- Performance metrics\n- User feedback\n- Rollback if issues\n\n### Timing\n- Internal: 1-2 days\n- Canary: 1 day minimum\n- Full rollout: 1-2 weeks total","start_line":1,"end_line":17}]}
{"source_id":"core","type":"release","title":"Hotfix Process","signals":["release_install"],"tags":["release","hotfix","emergency"],"summary":"Process for emergency production fixes.","chunks":[{"chunk_id":"core:hotfix-process:1","text":"## Hotfix Process\n\n### When to Hotfix\n- Security vulnerability\n- Data corruption risk\n- Critical feature broken\n- Major user impact\n\n### Process\n1. Assess severity and impact\n2. Create hotfix branch from main\n3. Minimal fix only\n4. Fast-track review\n5. Deploy immediately\n6. Backport to develop\n\n### Post-Hotfix\n- Post-mortem within 48h\n- Prevent recurrence\n- Update monitoring","start_line":1,"end_line":18}]}
{"source_id":"core","type":"contract","title":"Performance SLA Template","signals":["contract_lock"],"tags":["sla","performance","contract"],"summary":"Template for defining performance service level agreements.","chunks":[{"chunk_id":"core:perf-sla:1","text":"## Performance SLA Template\n\n### Metrics\n- Availability: 99.9% (8.7h downtime/year)\n- Response time: p95 < 200ms\n- Throughput: 1000 req/sec sustained\n\n### Measurement\n- External uptime monitoring\n- Response time from edge\n- 5-minute rolling windows\n\n### Exclusions\n- Planned maintenance windows\n- Force majeure events\n- Customer-caused issues\n\n### Remedies\n- Credits for SLA breaches\n- Root cause reports","start_line":1,"end_line":17}]}
{"source_id":"core","type":"contract","title":"Data Retention Policy Template","signals":["contract_lock"],"tags":["data","retention","policy"],"summary":"Template for defining data retention policies.","chunks":[{"chunk_id":"core:data-retention:1","text":"## Data Retention Policy\n\n### By Data Type\n- User data: Until account deletion + 30 days\n- Audit logs: 1 year\n- Analytics: 90 days aggregated\n- Backups: 30 day rolling\n\n### Deletion Process\n- Soft delete first (30 days)\n- Hard delete after grace period\n- Backup purging follows retention\n\n### Compliance\n- GDPR: right to erasure\n- Data subject requests: 30 days\n- Retention schedule documented","start_line":1,"end_line":16}]}
{"source_id":"core","type":"security","title":"API Key Best Practices","signals":["security_pattern"],"tags":["security","api-keys","authentication"],"summary":"Best practices for API key management.","chunks":[{"chunk_id":"core:api-keys:1","text":"## API Key Best Practices\n\n### Generation\n- Cryptographically random\n- Sufficient entropy (256 bits)\n- Prefix for type: sk_, pk_\n\n### Storage\n- Hash in database (for lookup)\n- Never log full key\n- Display only last 4 chars in UI\n\n### Management\n- Rotation capability\n- Expiration dates\n- Scope limitations\n- Revocation mechanism\n- Creation audit log","start_line":1,"end_line":17}]}
{"source_id":"core","type":"security","title":"Authentication Token Types","signals":["security_pattern"],"tags":["security","authentication","tokens"],"summary":"Overview of different authentication token types and use cases.","chunks":[{"chunk_id":"core:auth-tokens:1","text":"## Authentication Token Types\n\n### JWT (JSON Web Token)\n- Use: Stateless authentication\n- Pros: No server lookup needed\n- Cons: Can't revoke easily\n- Best for: APIs, microservices\n\n### Session Tokens\n- Use: Web application sessions\n- Stored: Database or cache\n- Can revoke: Yes, delete from store\n- Best for: Traditional web apps\n\n### API Keys\n- Use: Machine-to-machine auth\n- Long-lived, per-application\n- Best for: Service integrations","start_line":1,"end_line":17}]}
{"source_id":"core","type":"template","title":"Architecture Decision Record","signals":["evidence_audit"],"tags":["template","adr","documentation"],"summary":"Template for documenting architecture decisions.","chunks":[{"chunk_id":"core:adr-template:1","text":"## Architecture Decision Record\n\n### Title\n[Short descriptive title]\n\n### Status\n[Proposed, Accepted, Deprecated, Superseded]\n\n### Context\n[What is the issue we're addressing?]\n\n### Decision\n[What is our decision?]\n\n### Consequences\n[What are the results of this decision?]\n\n### Alternatives Considered\n[What else did we consider?]","start_line":1,"end_line":18}]}
{"source_id":"core","type":"template","title":"Runbook Template","signals":["evidence_audit"],"tags":["template","runbook","operations"],"summary":"Template for operational runbooks.","chunks":[{"chunk_id":"core:runbook-template:1","text":"## Runbook Template\n\n### Overview\n[What this runbook covers]\n\n### When to Use\n[Trigger conditions]\n\n### Prerequisites\n[Access, tools, permissions needed]\n\n### Steps\n1. [First action]\n2. [Second action]\n3. [Continue...]\n\n### Rollback\n[How to undo if something goes wrong]\n\n### Escalation\n[Who to contact if stuck]","start_line":1,"end_line":19}]}
{"source_id":"core","type":"iterate","title":"Root Cause Analysis Template","signals":["iterate_loop"],"tags":["debugging","rca","analysis"],"summary":"Template for conducting root cause analysis.","chunks":[{"chunk_id":"core:rca-template:1","text":"## Root Cause Analysis\n\n### 5 Whys Method\n1. Why did X happen? Because Y\n2. Why did Y happen? Because Z\n3. Continue until root cause\n\n### Categories\n- Process: Missing steps/checks\n- People: Training/knowledge gap\n- Technology: Bug/limitation\n- External: Third-party/environment\n\n### Output\n- Root cause statement\n- Contributing factors\n- Corrective actions\n- Prevention measures","start_line":1,"end_line":17}]}
{"source_id":"core","type":"iterate","title":"Debug Logging Strategy","signals":["iterate_loop"],"tags":["debugging","logging","strategy"],"summary":"Strategy for effective debug logging.","chunks":[{"chunk_id":"core:debug-logging:1","text":"## Debug Logging Strategy\n\n### Log Levels\n- ERROR: Something failed\n- WARN: Something unexpected\n- INFO: Normal operations\n- DEBUG: Detailed for debugging\n- TRACE: Very verbose\n\n### What to Log\n- Entry/exit of key functions\n- Decision points with values\n- External calls and responses\n- State transitions\n\n### Best Practices\n- Structured logging (JSON)\n- Include context IDs\n- Timestamps with timezone\n- Easy to grep/filter","start_line":1,"end_line":19}]}
{"source_id":"core","type":"plan","title":"Load Testing Strategy","signals":["iterate_loop"],"tags":["testing","performance","load"],"summary":"Strategy for conducting load tests.","chunks":[{"chunk_id":"core:load-testing:1","text":"## Load Testing Strategy\n\n### Test Types\n- Smoke: Basic functionality under load\n- Load: Normal expected load\n- Stress: Beyond normal capacity\n- Spike: Sudden traffic bursts\n- Soak: Extended duration\n\n### Metrics to Capture\n- Response times (p50, p95, p99)\n- Error rates\n- Throughput\n- Resource utilization\n\n### Process\n1. Baseline performance\n2. Increase load gradually\n3. Find breaking point\n4. Document limits","start_line":1,"end_line":18}]}
{"source_id":"core","type":"plan","title":"Capacity Planning Guide","signals":["state_machine"],"tags":["planning","capacity","infrastructure"],"summary":"Guide for infrastructure capacity planning.","chunks":[{"chunk_id":"core:capacity-planning:1","text":"## Capacity Planning Guide\n\n### Current State\n- Measure current usage\n- Peak vs average load\n- Growth trend analysis\n\n### Projections\n- 3-6 month forecast\n- Account for seasonal peaks\n- Include planned features\n\n### Thresholds\n- Alert at 70% capacity\n- Scale at 80% capacity\n- Emergency at 90% capacity\n\n### Review Cadence\n- Monthly metrics review\n- Quarterly planning update","start_line":1,"end_line":18}]}

{"source_id":"core","type":"contract","title":"Rust Web Service Contract","signals":["contract_lock"],"tags":["rust","web","axum","actix"],"summary":"Contract template for high-performance Rust web services including middleware, error handling, and async runtime settings.","chunks":[{"chunk_id":"core:rust-web-contract:1","text":"## Rust Web Service Contract\n\n### Service Overview\n- **Name**: [Service Name]\n- **Framework**: Axum / Actix-web\n- **Runtime**: Tokio (Multi-thread)\n\n### Core Components\n- **Router**: Centralized route definitions\n- **Handlers**: Async functions returning Result<impl IntoResponse, AppError>\n- **State**: Arc<AppState> for shared resources (DB pool, config)\n- **Middleware**: Tracing, CORS, Timeout, Compression\n\n### Error Handling\n- Custom AppError enum implementing IntoResponse\n- Centralized error logging\n- User-friendly error messages (no internal details)\n\n### Performance Targets\n- P99 Latency < 50ms\n- Throughput > 10k req/sec\n- Memory < 100MB idle","start_line":1,"end_line":20}]}
{"source_id":"core","type":"contract","title":"Go Microservice Contract","signals":["contract_lock"],"tags":["go","microservice","grpc"],"summary":"Contract template for Go microservices using gRPC/Protobuf and Clean Architecture.","chunks":[{"chunk_id":"core:go-microservice-contract:1","text":"## Go Microservice Contract\n\n### Service Overview\n- **Name**: [Service Name]\n- **Protocol**: gRPC + HTTP/JSON Gateway\n- **Architecture**: Clean Architecture (Transport -> Endpoint -> Service -> Repository)\n\n### API Definition\n- **Protobuf**: Defined in /api/proto/v1\n- **Versioning**: Package versioning (v1, v2)\n- **Validation**: Protoc-gen-validate rules\n\n### Core Layers\n1. **Transport**: gRPC/HTTP handlers, decoding\n2. **Endpoint**: Request/Response structs, middleware\n3. **Service**: Business logic interface\n4. **Repository**: Data access interface\n\n### Observability\n- Structured logging (slog/zap)\n- Prometheus metrics (latency, errors, saturation)\n- Distributed tracing (OpenTelemetry)","start_line":1,"end_line":20}]}
{"source_id":"core","type":"contract","title":"TUI Application Contract","signals":["contract_lock"],"tags":["tui","rust","go","cli"],"summary":"Contract template for Terminal User Interface applications covering layout, input handling, and rendering loop.","chunks":[{"chunk_id":"core:tui-contract:1","text":"## TUI Application Contract\n\n### App Overview\n- **Name**: [App Name]\n- **Library**: Ratatui (Rust) / Bubbletea (Go)\n- **Theme**: Adaptive (Dark/Light support)\n\n### Architecture\n- **Model**: Application state\n- **View**: Rendering logic (Widgets, Layouts)\n- **Update**: Message handling loop\n\n### Key Components\n- **Input Handler**: Keyboard/Mouse events -> Actions\n- **Layout Engine**: Flexbox/Grid constraints\n- **Widgets**: List, Table, Chart, Paragraph\n\n### UX Requirements\n- **Responsive**: Adapts to terminal resize\n- **Shortcuts**: Vim-like navigation (j/k/h/l)\n- **Help**: Contextual help overlay (?)","start_line":1,"end_line":20}]}
{"source_id":"core","type":"contract","title":"Modern React App Contract","signals":["contract_lock"],"tags":["react","web","frontend"],"summary":"Contract template for modern React applications using Next.js/Remix, Server Components, and Tailwind CSS.","chunks":[{"chunk_id":"core:react-contract:1","text":"## Modern React App Contract\n\n### App Overview\n- **Framework**: Next.js (App Router) / Remix\n- **Styling**: Tailwind CSS + Shadcn/UI\n- **State**: Server State (TanStack Query) + Client State (Zustand)\n\n### Architecture\n- **Server Components**: Data fetching, heavy rendering\n- **Client Components**: Interactivity, hooks\n- **Layouts**: Nested layouts for persistence\n\n### Data Strategy\n- **Fetching**: Server-side fetching (RSC)\n- **Mutations**: Server Actions / API Routes\n- **Caching**: Revalidation strategy (Time-based / On-demand)\n\n### Performance\n- **Core Web Vitals**: All green (LCP, CLS, INP)\n- **Bundle Size**: < 100KB initial load JS\n- **Images**: Next/Image optimization","start_line":1,"end_line":20}]}
{"source_id":"core","type":"plan","title":"Database Migration Plan","signals":["state_machine"],"tags":["database","migration","plan"],"summary":"Plan template for safe database migrations including backup, dry-run, and rollback procedures.","chunks":[{"chunk_id":"core:db-migration-plan:1","text":"## Database Migration Plan\n\n### Pre-Migration Checklist\n- [ ] Backup verified (restore tested)\n- [ ] Migration script reviewed by DBA\n- [ ] Dry-run on staging successful\n- [ ] Application downtime scheduled (if needed)\n\n### Execution Steps\n1. **Lock**: Prevent new writes (if offline migration)\n2. **Backup**: Take point-in-time snapshot\n3. **Migrate**: Run `sqlx migrate run` / `prisma migrate deploy`\n4. **Verify**: Check schema changes and row counts\n5. **Unlock**: Enable application writes\n\n### Rollback Strategy\n- **Down Script**: Tested SQL to revert changes\n- **Restore**: Restore from snapshot if data corruption occurs\n- **Verification**: Ensure app works with old schema","start_line":1,"end_line":18}]}
{"source_id":"core","type":"plan","title":"Distributed System Implementation Plan","signals":["state_machine"],"tags":["distributed","plan","system"],"summary":"Implementation plan for distributed systems covering consensus, replication, and partition tolerance.","chunks":[{"chunk_id":"core:dist-sys-plan:1","text":"## Distributed System Implementation Plan\n\n### Phase 1: Node Architecture\n- [ ] Node lifecycle (join, leave, crash)\n- [ ] RPC interface definition\n- [ ] Local storage engine\n- [ ] Configuration propagation\n\n### Phase 2: Consensus & Replication\n- [ ] Leader election (Raft/Paxos)\n- [ ] Log replication\n- [ ] State machine application\n- [ ] Snapshotting for log compaction\n\n### Phase 3: Resilience\n- [ ] Network partition handling\n- [ ] Byzantine fault tolerance (if needed)\n- [ ] Jepsen testing suite\n- [ ] Chaos engineering drills\n\n### Phase 4: Operations\n- [ ] Monitoring dashboard (Grafana)\n- [ ] Alerting rules\n- [ ] Rolling upgrade procedure","start_line":1,"end_line":20}]}
{"source_id":"core","type":"evidence","title":"Performance Audit Checklist","signals":["evidence_audit"],"tags":["performance","audit","checklist"],"summary":"Checklist for performance auditing covering CPU, memory, I/O, and network metrics.","chunks":[{"chunk_id":"core:perf-audit:1","text":"## Performance Audit Checklist\n\n### CPU Profiling\n- [ ] Hot paths identified (Flamegraph)\n- [ ] Lock contention analysis\n- [ ] Context switch rate checked\n- [ ] SIMD opportunities identified\n\n### Memory Analysis\n- [ ] Leak detection (Valgrind/Heaptrack)\n- [ ] Allocation rate (gc pressure)\n- [ ] Cache hit rates (L1/L2/L3)\n- [ ] Struct padding optimization\n\n### I/O & Network\n- [ ] Disk IOPS saturation check\n- [ ] Network throughput vs bandwidth\n- [ ] Serialization overhead measured\n- [ ] Database query performance (N+1 check)","start_line":1,"end_line":18}]}
{"source_id":"core","type":"evidence","title":"Security Audit Checklist","signals":["security_pattern"],"tags":["security","audit","checklist"],"summary":"Comprehensive security audit checklist covering auth, data, network, and dependencies.","chunks":[{"chunk_id":"core:sec-audit:1","text":"## Security Audit Checklist\n\n### Authentication & AuthZ\n- [ ] No hardcoded credentials\n- [ ] JWT signature verification\n- [ ] Password hashing (Argon2/Bcrypt)\n- [ ] RBAC enforcement on all endpoints\n\n### Data Security\n- [ ] SQL injection prevention (Prepared statements)\n- [ ] XSS prevention (Content Security Policy)\n- [ ] CSRF tokens implemented\n- [ ] Sensitive data redacted in logs\n\n### Infrastructure\n- [ ] TLS configuration (HSTS, Cipher suites)\n- [ ] Firewalls and Security Groups\n- [ ] Container security (Rootless, Minimal base)\n- [ ] Dependency vulnerability scan (Audit)","start_line":1,"end_line":18}]}
{"source_id":"core","type":"contract","title":"REST API Design Contract","signals":["contract_lock"],"tags":["api","rest","design"],"summary":"Contract template for REST API design covering endpoints, HTTP methods, status codes, and pagination.","chunks":[{"chunk_id":"core:rest-api-design:1","text":"## REST API Design Contract\n\n### Endpoint Naming\n- Use nouns, not verbs: `/users`, `/orders`\n- Use plural nouns: `/users` not `/user`\n- Use lowercase with hyphens: `/user-profiles`\n\n### HTTP Methods\n| Method | Use Case | Idempotent |\n|--------|----------|------------|\n| GET | Read | Yes |\n| POST | Create | No |\n| PUT | Full Update | Yes |\n| PATCH | Partial Update | No |\n| DELETE | Remove | Yes |\n\n### Status Codes\n- 200: Success\n- 201: Created\n- 204: No Content\n- 400: Bad Request\n- 401: Unauthorized\n- 403: Forbidden\n- 404: Not Found\n- 500: Internal Error","start_line":1,"end_line":24}]}
{"source_id":"core","type":"contract","title":"GraphQL API Contract","signals":["contract_lock"],"tags":["api","graphql","design"],"summary":"Contract template for GraphQL API design covering schema, queries, mutations, and subscriptions.","chunks":[{"chunk_id":"core:graphql-api:1","text":"## GraphQL API Contract\n\n### Schema Design\n- **Types**: Use PascalCase (User, Order)\n- **Fields**: Use camelCase (firstName, createdAt)\n- **Enums**: Use SCREAMING_SNAKE_CASE\n\n### Query Patterns\n- Single item: `user(id: ID!): User`\n- List: `users(first: Int, after: String): UserConnection`\n- Use connections for pagination\n\n### Mutations\n- Input types: `CreateUserInput`, `UpdateUserInput`\n- Return payload: `CreateUserPayload { user, errors }`\n\n### Best Practices\n- N+1 prevention with DataLoader\n- Depth limiting (max 5 levels)\n- Query complexity analysis\n- Rate limiting per operation","start_line":1,"end_line":20}]}
{"source_id":"core","type":"iterate","title":"Code Review Checklist","signals":["iterate_loop"],"tags":["review","checklist","quality"],"summary":"Checklist for conducting effective code reviews focusing on correctness, maintainability, and security.","chunks":[{"chunk_id":"core:code-review:1","text":"## Code Review Checklist\n\n### Correctness\n- [ ] Logic handles edge cases\n- [ ] Error handling is appropriate\n- [ ] No off-by-one errors\n- [ ] Concurrent access is safe\n\n### Maintainability\n- [ ] Code is self-documenting\n- [ ] Functions are small and focused\n- [ ] No magic numbers or strings\n- [ ] Consistent naming conventions\n\n### Performance\n- [ ] No N+1 queries\n- [ ] Appropriate data structures\n- [ ] No unnecessary allocations\n\n### Security\n- [ ] Input validation present\n- [ ] No SQL injection risk\n- [ ] Sensitive data protected","start_line":1,"end_line":22}]}
{"source_id":"core","type":"iterate","title":"PR Description Template","signals":["iterate_loop"],"tags":["pr","template","git"],"summary":"Template for writing effective pull request descriptions with context, changes, and testing.","chunks":[{"chunk_id":"core:pr-checklist-template:1","text":"## PR Description Template\n\n### Context\n<!-- Why is this change needed? -->\n\n### Changes\n- [ ] Added/Modified feature X\n- [ ] Updated tests\n- [ ] Updated documentation\n\n### Type\n- [ ] Feature\n- [ ] Bug Fix\n- [ ] Refactor\n- [ ] Documentation\n\n### Testing\n- [ ] Unit tests added/updated\n- [ ] Integration tests pass\n- [ ] Manual testing performed\n\n### Screenshots\n<!-- If UI changes, add screenshots -->","start_line":1,"end_line":22}]}
{"source_id":"core","type":"plan","title":"CI/CD Pipeline Plan","signals":["state_machine"],"tags":["cicd","devops","plan"],"summary":"Plan template for CI/CD pipeline covering build, test, security, and deployment stages.","chunks":[{"chunk_id":"core:cicd-plan:1","text":"## CI/CD Pipeline Plan\n\n### Stage 1: Build\n- [ ] Compile/transpile source\n- [ ] Run linters (eslint, clippy)\n- [ ] Check formatting\n- [ ] Generate artifacts\n\n### Stage 2: Test\n- [ ] Unit tests\n- [ ] Integration tests\n- [ ] Coverage report (>80%)\n\n### Stage 3: Security\n- [ ] Dependency scan (Dependabot/Snyk)\n- [ ] Secret detection\n- [ ] Container scan\n\n### Stage 4: Deploy\n- [ ] Staging deployment\n- [ ] Smoke tests\n- [ ] Production deployment\n- [ ] Health checks","start_line":1,"end_line":22}]}
{"source_id":"core","type":"plan","title":"Incident Response Plan","signals":["state_machine"],"tags":["incident","sre","plan"],"summary":"Plan template for incident response covering detection, mitigation, resolution, and post-mortem.","chunks":[{"chunk_id":"core:incident-plan:1","text":"## Incident Response Plan\n\n### Detection (0-5 min)\n- Alert received via PagerDuty/Slack\n- Acknowledge incident\n- Assess severity (P1-P4)\n\n### Mitigation (5-30 min)\n- Rollback if recent deploy\n- Scale resources if load issue\n- Enable feature flags fallback\n- Communicate to stakeholders\n\n### Resolution\n- Root cause identified\n- Fix implemented\n- Tests verified\n- Deploy fix\n\n### Post-Mortem (within 48h)\n- Timeline of events\n- Root cause analysis\n- Action items with owners\n- Lessons learned","start_line":1,"end_line":22}]}
{"source_id":"core","type":"evidence","title":"API Documentation Checklist","signals":["evidence_audit"],"tags":["api","documentation","checklist"],"summary":"Checklist for comprehensive API documentation covering endpoints, examples, and error codes.","chunks":[{"chunk_id":"core:api-docs:1","text":"## API Documentation Checklist\n\n### Essentials\n- [ ] Base URL and versioning\n- [ ] Authentication method\n- [ ] Rate limits specified\n\n### For Each Endpoint\n- [ ] HTTP method and path\n- [ ] Request parameters (query, path, body)\n- [ ] Request body schema with example\n- [ ] Response schema with example\n- [ ] Error codes and messages\n\n### Examples\n- [ ] cURL examples\n- [ ] Language-specific SDKs\n- [ ] Postman collection\n\n### Changelog\n- [ ] Breaking changes highlighted\n- [ ] Deprecation notices","start_line":1,"end_line":20}]}
{"source_id":"core","type":"evidence","title":"Logging Standards","signals":["evidence_audit"],"tags":["logging","observability","standards"],"summary":"Standards for structured logging covering log levels, fields, and best practices.","chunks":[{"chunk_id":"core:logging-standards:1","text":"## Logging Standards\n\n### Log Levels\n- **ERROR**: System failures requiring action\n- **WARN**: Potential issues to monitor\n- **INFO**: Key business events\n- **DEBUG**: Detailed diagnostic info\n\n### Required Fields\n- timestamp: ISO 8601\n- level: log level\n- service: service name\n- trace_id: distributed tracing\n- user_id: (if authenticated)\n\n### Best Practices\n- Never log sensitive data (PII, secrets)\n- Use structured JSON format\n- Include context (request_id, user_id)\n- Rate limit high-volume logs","start_line":1,"end_line":20}]}
{"source_id":"core","type":"contract","title":"Microservice Boundaries Contract","signals":["contract_lock"],"tags":["microservices","architecture","boundaries"],"summary":"Contract for defining microservice boundaries covering ownership, APIs, and data isolation.","chunks":[{"chunk_id":"core:microservice-boundaries:1","text":"## Microservice Boundaries Contract\n\n### Service Identity\n- **Name**: [service-name]\n- **Owner**: [team]\n- **Domain**: [bounded context]\n\n### API Contract\n- Sync: REST/gRPC endpoints\n- Async: Event topics produced/consumed\n- Schema registry for versioning\n\n### Data Ownership\n- Own database instance\n- No direct DB access from other services\n- Data shared via API/events\n\n### Dependencies\n- Upstream services called\n- Downstream consumers\n- Circuit breaker policies","start_line":1,"end_line":20}]}
{"source_id":"core","type":"contract","title":"Feature Flag Contract","signals":["contract_lock"],"tags":["feature-flag","release","contract"],"summary":"Contract for feature flag implementation covering naming, rollout, and cleanup.","chunks":[{"chunk_id":"core:feature-flag:1","text":"## Feature Flag Contract\n\n### Naming Convention\n- Format: `ff_<feature>_<variant>`\n- Example: `ff_new_checkout_enabled`\n\n### Flag Types\n- **Release**: Gradual rollout (0-100%)\n- **Experiment**: A/B testing\n- **Ops**: Kill switch for features\n- **Permission**: User segment targeting\n\n### Lifecycle\n1. Create flag (disabled by default)\n2. Gradual rollout (10% -> 50% -> 100%)\n3. Monitor metrics\n4. Remove flag code (within 30 days of 100%)\n\n### Cleanup\n- Stale flags: >90 days at 100%\n- Quarterly flag audit\n- Remove dead code paths","start_line":1,"end_line":20}]}
{"source_id":"core","type":"contract","title":"Docker Container Contract","signals":["contract_lock","release_install"],"tags":["docker","container","devops"],"summary":"Contract for Docker container best practices covering multi-stage builds, security, and health checks.","chunks":[{"chunk_id":"core:docker-contract:1","text":"## Docker Container Contract\n\n### Image Requirements\n- **Base Image**: Use official slim/alpine variants\n- **Multi-stage**: Build in one stage, run in minimal\n- **Non-root**: Run as non-root user (USER 1000)\n\n### Dockerfile Best Practices\n- Order layers by change frequency\n- Combine RUN commands to reduce layers\n- Use .dockerignore for build context\n- Pin dependency versions\n\n### Health & Signals\n- HEALTHCHECK instruction defined\n- Handle SIGTERM gracefully\n- Startup time < 30 seconds\n\n### Security\n- No secrets in image layers\n- Read-only root filesystem\n- Drop all capabilities, add needed","start_line":1,"end_line":20}]}
{"source_id":"core","type":"contract","title":"Kubernetes Deployment Contract","signals":["contract_lock","release_install"],"tags":["kubernetes","k8s","deployment"],"summary":"Contract for Kubernetes deployments covering resource limits, probes, and rolling updates.","chunks":[{"chunk_id":"core:k8s-contract:1","text":"## Kubernetes Deployment Contract\n\n### Resource Management\n- **Requests**: Minimum guaranteed resources\n- **Limits**: Maximum allowed resources\n- **QoS**: Target Guaranteed or Burstable class\n\n### Probes\n- **Liveness**: Restart if unhealthy (path: /healthz)\n- **Readiness**: Remove from LB if not ready (path: /ready)\n- **Startup**: Allow slow startup (initialDelaySeconds)\n\n### Rolling Update\n- maxSurge: 25%\n- maxUnavailable: 0 (for zero-downtime)\n- minReadySeconds: 10\n\n### Pod Disruption Budget\n- minAvailable: 2 (or percentage)\n- Allow graceful node drains","start_line":1,"end_line":18}]}
{"source_id":"core","type":"plan","title":"Unit Testing Strategy","signals":["iterate_loop"],"tags":["testing","unit","strategy"],"summary":"Comprehensive unit testing strategy covering test structure, mocking, and coverage.","chunks":[{"chunk_id":"core:unit-test-strategy:1","text":"## Unit Testing Strategy\n\n### Test Structure (AAA)\n- **Arrange**: Set up test data and mocks\n- **Act**: Execute the function under test\n- **Assert**: Verify the result\n\n### Naming Convention\n- test_<function>_<scenario>_<expected>\n- Example: test_calculate_total_with_discount_returns_reduced_price\n\n### Mocking Guidelines\n- Mock external dependencies only\n- Use dependency injection for testability\n- Avoid testing implementation details\n\n### Coverage Targets\n- 80% line coverage minimum\n- 100% for critical paths\n- Focus on branch coverage for conditionals","start_line":1,"end_line":18}]}
{"source_id":"core","type":"plan","title":"Integration Testing Strategy","signals":["iterate_loop"],"tags":["testing","integration","strategy"],"summary":"Integration testing patterns covering database setup, API testing, and test isolation.","chunks":[{"chunk_id":"core:integration-test-strategy:1","text":"## Integration Testing Strategy\n\n### Database Tests\n- Use transactions with rollback\n- Or: Fresh database per test suite\n- Seed with minimal required data\n\n### API Tests\n- Test through HTTP layer\n- Validate status codes and bodies\n- Test auth flows end-to-end\n\n### Isolation\n- Each test independent\n- No shared mutable state\n- Clean up after tests\n\n### Performance\n- Integration tests can be slower\n- Parallelize where safe\n- Use test containers for dependencies","start_line":1,"end_line":18}]}
{"source_id":"core","type":"iterate","title":"Git Commit Message Convention","signals":["evidence_audit"],"tags":["git","commit","convention"],"summary":"Conventional commit message format for clear and automated changelog generation.","chunks":[{"chunk_id":"core:git-commit-convention:1","text":"## Git Commit Message Convention\n\n### Format\n<type>(<scope>): <subject>\n\n### Types\n- **feat**: New feature\n- **fix**: Bug fix\n- **docs**: Documentation only\n- **style**: Formatting, no code change\n- **refactor**: Code change, no feature/fix\n- **test**: Adding tests\n- **chore**: Maintenance tasks\n\n### Rules\n- Subject: imperative mood, no period\n- Body: explain what and why\n- Footer: breaking changes, issue refs\n\n### Examples\n- feat(auth): add OAuth2 login\n- fix(api): handle null response","start_line":1,"end_line":20}]}
{"source_id":"core","type":"iterate","title":"Git Branch Strategy","signals":["state_machine"],"tags":["git","branching","workflow"],"summary":"Git branching strategies for team development including GitFlow and trunk-based.","chunks":[{"chunk_id":"core:git-branch-strategy:1","text":"## Git Branch Strategy\n\n### Trunk-Based (Recommended)\n- main: always deployable\n- Short-lived feature branches\n- Feature flags for incomplete work\n- Merge via PR with CI gates\n\n### GitFlow (Legacy)\n- main: production releases\n- develop: integration branch\n- feature/*: new features\n- release/*: release prep\n- hotfix/*: production fixes\n\n### Branch Naming\n- feature/TICKET-123-description\n- fix/TICKET-456-bug-name\n- chore/update-dependencies","start_line":1,"end_line":18}]}
{"source_id":"core","type":"security","title":"Container Security Checklist","signals":["security_pattern"],"tags":["container","docker","security"],"summary":"Security checklist for container images and runtime.","chunks":[{"chunk_id":"core:container-security:1","text":"## Container Security Checklist\n\n### Build Time\n- [ ] Use minimal base images\n- [ ] No secrets in build args\n- [ ] Pin base image digests\n- [ ] Scan for vulnerabilities (Trivy)\n\n### Runtime\n- [ ] Run as non-root user\n- [ ] Read-only root filesystem\n- [ ] Drop all capabilities\n- [ ] No privileged containers\n\n### Network\n- [ ] Network policies defined\n- [ ] Ingress/egress restricted\n- [ ] Service mesh encryption","start_line":1,"end_line":18}]}
{"source_id":"core","type":"evidence","title":"Alerting Best Practices","signals":["evidence_audit"],"tags":["alerting","monitoring","sre"],"summary":"Best practices for actionable alerts that reduce noise and improve response.","chunks":[{"chunk_id":"core:alerting-best-practices:1","text":"## Alerting Best Practices\n\n### Alert Quality\n- Every alert must be actionable\n- Include runbook link in alert\n- Clear severity levels (P1-P4)\n\n### Reduce Noise\n- Aggregate related alerts\n- Use appropriate thresholds\n- Avoid flapping (min duration)\n\n### On-Call\n- Clear escalation paths\n- Rotation schedules\n- Post-incident review\n\n### Metrics\n- Track alert frequency\n- Measure time-to-resolution\n- Review and tune regularly","start_line":1,"end_line":18}]}
{"source_id":"core","type":"plan","title":"Code Refactoring Playbook","signals":["iterate_loop"],"tags":["refactoring","code-quality","playbook"],"summary":"Systematic approach to code refactoring with safety and measurable improvements.","chunks":[{"chunk_id":"core:refactoring-playbook:1","text":"## Code Refactoring Playbook\n\n### Before Refactoring\n- [ ] Tests cover affected code\n- [ ] Benchmark if performance-related\n- [ ] Small, incremental changes\n\n### Safe Refactoring Steps\n1. Extract: Pull out functions/classes\n2. Rename: Improve naming clarity\n3. Move: Better file organization\n4. Simplify: Reduce complexity\n\n### Verification\n- All tests still pass\n- No behavior changes\n- Performance maintained\n\n### Anti-patterns\n- Refactoring and adding features together\n- Big-bang rewrites\n- Skipping tests","start_line":1,"end_line":18}]}
{"source_id":"core","type":"contract","title":"API Rate Limiting Contract","signals":["contract_lock","security_pattern"],"tags":["api","rate-limit","contract"],"summary":"Contract for API rate limiting covering quotas, headers, and client handling.","chunks":[{"chunk_id":"core:rate-limit-contract:1","text":"## API Rate Limiting Contract\n\n### Limits\n- **Anonymous**: 60 requests/hour\n- **Authenticated**: 1000 requests/hour\n- **Premium**: 10000 requests/hour\n\n### Response Headers\n- X-RateLimit-Limit: Total allowed\n- X-RateLimit-Remaining: Left in window\n- X-RateLimit-Reset: Unix timestamp\n\n### On Limit Exceeded\n- HTTP 429 Too Many Requests\n- Retry-After header\n- Clear error message\n\n### Client Behavior\n- Respect Retry-After\n- Exponential backoff\n- Cache responses where possible","start_line":1,"end_line":18}]}
{"source_id":"core","type":"template","title":"Dockerfile Multi-Stage Template","signals":["release_install"],"tags":["docker","dockerfile","template"],"summary":"Multi-stage Dockerfile template for minimal production images.","chunks":[{"chunk_id":"core:dockerfile-template:1","text":"## Dockerfile Multi-Stage Template\n\n### Rust Example\n```dockerfile\n# Build stage\nFROM rust:1.75-slim AS builder\nWORKDIR /app\nCOPY . .\nRUN cargo build --release\n\n# Runtime stage\nFROM debian:bookworm-slim\nRUN useradd -r -u 1000 app\nCOPY --from=builder /app/target/release/myapp /usr/local/bin/\nUSER app\nCMD [\"myapp\"]\n```\n\n### Benefits\n- Small final image (<100MB)\n- No build tools in production\n- Non-root user for security","start_line":1,"end_line":20}]}
{"source_id":"core","type":"template","title":"GitHub Actions Workflow Template","signals":["release_install","iterate_loop"],"tags":["github-actions","ci","template"],"summary":"Reusable GitHub Actions workflow template for Rust/Node/Go projects.","chunks":[{"chunk_id":"core:gh-actions-template:1","text":"## GitHub Actions Workflow Template\n\n### Structure\n```yaml\nname: CI\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  check:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Setup\n        uses: actions/setup-node@v4\n      - run: npm ci\n      - run: npm test\n```\n\n### Best Practices\n- Cache dependencies\n- Fail fast on errors\n- Matrix for multi-platform","start_line":1,"end_line":22}]}
{"source_id":"core","type":"iterate","title":"Code Review Response Guide","signals":["iterate_loop","evidence_audit"],"tags":["code-review","collaboration","guide"],"summary":"Guide for responding to code review feedback constructively and efficiently.","chunks":[{"chunk_id":"core:review-response-guide:1","text":"## Code Review Response Guide\n\n### Receiving Feedback\n- Read all comments before responding\n- Assume positive intent\n- Ask for clarification if unclear\n- Thank reviewers for their time\n\n### Responding\n- Address each comment explicitly\n- Explain reasoning for disagreements\n- Mark resolved when fixed\n- Request re-review when ready\n\n### Common Responses\n- \"Done\" - Fixed as suggested\n- \"Good catch!\" - Acknowledge mistakes\n- \"Let's discuss\" - Need conversation\n- \"Will address in follow-up\" - Defer to new PR","start_line":1,"end_line":18}]}
{"source_id":"core","type":"contract","title":"Monorepo Structure Contract","signals":["contract_lock"],"tags":["monorepo","architecture","structure"],"summary":"Contract for monorepo organization covering package structure, dependencies, and tooling.","chunks":[{"chunk_id":"core:monorepo-contract:1","text":"## Monorepo Structure Contract\n\n### Directory Layout\n```\n/\n├── apps/           # Deployable applications\n├── packages/       # Shared libraries\n├── tools/          # Build/dev tooling\n└── docs/           # Documentation\n```\n\n### Dependency Rules\n- packages/* can depend on other packages/*\n- apps/* can depend on packages/*\n- No circular dependencies\n- Version sync across packages\n\n### Tooling\n- Turborepo / Nx for build orchestration\n- Changesets for versioning\n- Shared ESLint/TSConfig","start_line":1,"end_line":18}]}
{"source_id":"core","type":"context_engineering","title":"Model Context Protocol (MCP) Overview","signals":["context_engineering","provider_adapter"],"tags":["mcp","ai","protocol","integration"],"summary":"Overview of Model Context Protocol (MCP) - the standardized protocol for connecting AI models to external tools and data sources.","chunks":[{"chunk_id":"core:mcp-overview:1","text":"## Model Context Protocol (MCP) Overview\n\n### What is MCP?\nAn open standard for connecting AI assistants to external data sources and tools, enabling:\n- Standardized tool discovery and invocation\n- Secure resource access\n- Dynamic context injection\n\n### Core Concepts\n- **Host**: AI application (Claude Desktop, IDE)\n- **Client**: MCP client in the host\n- **Server**: External service providing tools/resources\n- **Transport**: Communication layer (stdio, SSE, WebSocket)\n\n### Key Benefits\n- Universal tool interface\n- Secure sandboxed execution\n- Dynamic capability discovery\n- Consistent error handling\n\n### Use Cases\n- File system access\n- Database queries\n- API integrations\n- Code execution environments","start_line":1,"end_line":26}]}
{"source_id":"core","type":"contract","title":"MCP Server Contract","signals":["contract_lock","provider_adapter"],"tags":["mcp","server","contract","ai"],"summary":"Contract template for building MCP servers that expose tools and resources to AI assistants.","chunks":[{"chunk_id":"core:mcp-server-contract:1","text":"## MCP Server Contract\n\n### Server Overview\n- **Name**: [server-name]\n- **Transport**: stdio / SSE / WebSocket\n- **Purpose**: [What resources/tools it provides]\n\n### Tools Exposed\n| Name | Description | Parameters | Returns |\n|------|-------------|------------|--------|\n| read_file | Read file contents | path: string | content: string |\n| query_db | Execute SQL query | sql: string | rows: array |\n\n### Resources Provided\n- URI scheme: `resource://server-name/path`\n- MIME types supported\n- Caching policy\n\n### Security\n- Input validation on all parameters\n- Sandboxed execution environment\n- No arbitrary code execution\n- Rate limiting per client\n\n### Error Handling\n- Structured error codes\n- User-friendly messages\n- Recovery suggestions","start_line":1,"end_line":28}]}
{"source_id":"core","type":"plan","title":"MCP Server Implementation Plan","signals":["state_machine"],"tags":["mcp","implementation","plan"],"summary":"Implementation plan for building MCP servers with tool definitions, resource handling, and transport setup.","chunks":[{"chunk_id":"core:mcp-server-plan:1","text":"## MCP Server Implementation Plan\n\n### Phase 1: Foundation\n- [ ] Choose transport (stdio for CLI, SSE for web)\n- [ ] Set up MCP SDK (@modelcontextprotocol/sdk)\n- [ ] Define server metadata (name, version, capabilities)\n- [ ] Implement basic request/response loop\n\n### Phase 2: Tools\n- [ ] Define tool schemas (JSON Schema)\n- [ ] Implement tool handlers\n- [ ] Add input validation (Zod/JSON Schema)\n- [ ] Return structured results\n\n### Phase 3: Resources\n- [ ] Define resource URI schemes\n- [ ] Implement resource listing\n- [ ] Handle resource reads\n- [ ] Add content type detection\n\n### Phase 4: Production\n- [ ] Add logging and tracing\n- [ ] Implement rate limiting\n- [ ] Handle graceful shutdown\n- [ ] Write integration tests","start_line":1,"end_line":24}]}
{"source_id":"core","type":"context_engineering","title":"RAG (Retrieval-Augmented Generation) Patterns","signals":["context_engineering"],"tags":["rag","ai","retrieval","vector"],"summary":"Patterns for implementing effective Retrieval-Augmented Generation systems.","chunks":[{"chunk_id":"core:rag-patterns:1","text":"## RAG Patterns\n\n### Architecture\n```\nQuery → Embed → Search → Rerank → Augment → Generate\n```\n\n### Embedding Strategy\n- Chunk size: 256-512 tokens (experiment)\n- Overlap: 10-20% for context continuity\n- Model: text-embedding-3-small/large\n\n### Retrieval\n- Vector similarity (cosine/dot product)\n- Hybrid search (vector + keyword BM25)\n- MMR for diversity\n\n### Reranking\n- Cross-encoder for precision\n- Filter by metadata\n- Deduplicate similar chunks\n\n### Context Injection\n- Prepend to system prompt\n- Or insert in user message\n- Include source attribution\n\n### Quality Metrics\n- Recall@k for retrieval\n- Answer relevance score\n- Faithfulness to sources","start_line":1,"end_line":28}]}
{"source_id":"core","type":"contract","title":"RAG Pipeline Contract","signals":["contract_lock","context_engineering"],"tags":["rag","pipeline","contract"],"summary":"Contract template for RAG pipeline systems covering ingestion, indexing, retrieval, and generation.","chunks":[{"chunk_id":"core:rag-contract:1","text":"## RAG Pipeline Contract\n\n### Pipeline Overview\n- **Data Sources**: Documents, APIs, databases\n- **Vector Store**: Pinecone / Weaviate / Qdrant / Chroma\n- **Embedding Model**: OpenAI / Cohere / local\n- **LLM**: GPT-4 / Claude / Llama\n\n### Ingestion\n- File formats supported (PDF, MD, HTML)\n- Chunking strategy (recursive, semantic)\n- Metadata extraction (title, date, source)\n\n### Retrieval\n- Top-k results (default: 5)\n- Similarity threshold (> 0.7)\n- Hybrid search weighting\n\n### Generation\n- System prompt with instructions\n- Context window management\n- Citation format\n\n### Quality Gates\n- Chunk relevance > 0.7\n- Answer groundedness check\n- Hallucination detection","start_line":1,"end_line":26}]}
{"source_id":"core","type":"context_engineering","title":"Agentic Workflow State Machine","signals":["state_machine","agent_pattern"],"tags":["agent","workflow","state-machine"],"summary":"State machine patterns for building reliable agentic AI workflows with planning, execution, and reflection loops.","chunks":[{"chunk_id":"core:agentic-workflow:1","text":"## Agentic Workflow State Machine\n\n### States\n```\nIDLE → PLANNING → EXECUTING → REFLECTING → COMPLETE\n         ↑           ↓\n         ←── RETRY ←──\n```\n\n### PLANNING Phase\n- Decompose goal into subtasks\n- Select tools for each subtask\n- Estimate token/cost budget\n- Validate plan feasibility\n\n### EXECUTING Phase\n- Execute one action at a time\n- Capture tool outputs\n- Update working memory\n- Check safety guardrails\n\n### REFLECTING Phase\n- Evaluate progress toward goal\n- Detect errors or stalls\n- Decide: continue, retry, or abort\n- Update plan if needed\n\n### Transitions\n- Max iterations: 10 (configurable)\n- Timeout per action: 60s\n- Escalate to human if stuck","start_line":1,"end_line":28}]}
{"source_id":"core","type":"contract","title":"AI Agent Memory Contract","signals":["contract_lock","agent_pattern"],"tags":["agent","memory","contract"],"summary":"Contract for AI agent memory systems covering short-term, long-term, and episodic memory.","chunks":[{"chunk_id":"core:agent-memory-contract:1","text":"## AI Agent Memory Contract\n\n### Memory Types\n- **Working Memory**: Current task context (in prompt)\n- **Short-term**: Conversation history (sliding window)\n- **Long-term**: Persistent facts (vector DB)\n- **Episodic**: Past task summaries\n\n### Short-term Memory\n- Token limit: Last N messages\n- Summarize older messages\n- Keep user preferences\n\n### Long-term Memory\n- Store: user facts, learned preferences\n- Retrieve: semantic search on query\n- Update: periodically consolidate\n\n### Memory Operations\n- Save(key, value, metadata)\n- Retrieve(query, top_k)\n- Forget(key) - explicit deletion\n- Summarize(conversation) - compression","start_line":1,"end_line":22}]}
{"source_id":"core","type":"plan","title":"Multi-Agent System Plan","signals":["state_machine","agent_pattern"],"tags":["multi-agent","orchestration","plan"],"summary":"Implementation plan for multi-agent systems with role specialization, communication, and coordination.","chunks":[{"chunk_id":"core:multi-agent-plan:1","text":"## Multi-Agent System Plan\n\n### Phase 1: Agent Definitions\n- [ ] Define agent roles (Planner, Executor, Critic)\n- [ ] Set agent capabilities and constraints\n- [ ] Design system prompts per role\n- [ ] Implement agent interfaces\n\n### Phase 2: Communication\n- [ ] Message passing protocol\n- [ ] Shared blackboard/workspace\n- [ ] Turn-taking or parallel execution\n- [ ] Conflict resolution rules\n\n### Phase 3: Orchestration\n- [ ] Supervisor agent or fixed workflow\n- [ ] Task delegation logic\n- [ ] Result aggregation\n- [ ] Consensus mechanisms\n\n### Phase 4: Safety\n- [ ] Agent isolation (no direct tool access)\n- [ ] Supervisor approval for actions\n- [ ] Budget limits per agent\n- [ ] Logging all inter-agent messages","start_line":1,"end_line":24}]}
{"source_id":"core","type":"evidence","title":"LLM Evaluation Framework","signals":["evidence_audit","iterate_loop"],"tags":["llm","evaluation","testing"],"summary":"Framework for evaluating LLM outputs covering accuracy, safety, and performance metrics.","chunks":[{"chunk_id":"core:llm-eval-framework:1","text":"## LLM Evaluation Framework\n\n### Evaluation Types\n- **Automated**: Programmatic checks\n- **LLM-as-Judge**: Use another LLM to evaluate\n- **Human Eval**: Manual review for quality\n\n### Automated Metrics\n- Exact match / BLEU / ROUGE (NLP)\n- JSON validity (structured output)\n- Regex patterns (format compliance)\n- Latency and token usage\n\n### LLM-as-Judge Criteria\n- Relevance: Does it answer the question?\n- Correctness: Is the information accurate?\n- Helpfulness: Is it useful to the user?\n- Safety: No harmful content?\n\n### Golden Dataset\n- Curated Q&A pairs with expected answers\n- Edge cases and adversarial inputs\n- Diverse topics and difficulty levels\n- Version controlled with code","start_line":1,"end_line":24}]}
{"source_id":"core","type":"plan","title":"LLM Testing Strategy","signals":["iterate_loop"],"tags":["llm","testing","strategy"],"summary":"Strategy for testing LLM-powered applications covering prompt regression, A/B testing, and monitoring.","chunks":[{"chunk_id":"core:llm-testing-strategy:1","text":"## LLM Testing Strategy\n\n### Prompt Regression Testing\n- Golden test cases for each prompt\n- Assert output structure/format\n- Track quality scores over time\n- Alert on regression (score drop)\n\n### A/B Testing\n- Compare prompt variants\n- Measure: quality, latency, cost\n- Statistical significance required\n- Document winning variant\n\n### Continuous Monitoring\n- Sample production requests\n- Human review random samples\n- Track error categories\n- Alert on new failure modes\n\n### Tools\n- Promptfoo for evaluation\n- LangSmith for tracing\n- Braintrust for experiments","start_line":1,"end_line":22}]}
{"source_id":"core","type":"template","title":"Cursor Rules Template","signals":["context_engineering"],"tags":["cursor","rules","ai-coding","template"],"summary":"Template for .cursorrules files to configure AI coding assistant behavior per project.","chunks":[{"chunk_id":"core:cursor-rules:1","text":"## Cursor Rules Template\n\n### File: .cursorrules\n```markdown\n# Project Context\nThis is a [language] project using [framework].\n\n# Code Style\n- Use [tabs/spaces] for indentation\n- Prefer [functional/OOP] patterns\n- Error handling: [Result types/exceptions]\n\n# Conventions\n- File naming: [snake_case/kebab-case]\n- Test files: [*.test.ts/*_test.go]\n- Import order: [stdlib, external, internal]\n\n# Dos\n- Write comprehensive error messages\n- Add JSDoc/docstrings for public APIs\n- Use meaningful variable names\n\n# Don'ts\n- Don't use any/unknown types\n- Don't commit console.log statements\n- Don't ignore errors silently\n```","start_line":1,"end_line":26}]}
{"source_id":"core","type":"template","title":"GitHub Copilot Instructions Template","signals":["context_engineering"],"tags":["copilot","instructions","ai-coding","template"],"summary":"Template for .github/copilot-instructions.md to customize GitHub Copilot behavior.","chunks":[{"chunk_id":"core:copilot-instructions:1","text":"## GitHub Copilot Instructions Template\n\n### File: .github/copilot-instructions.md\n```markdown\n# Project Overview\nBrief description of what this project does.\n\n# Technology Stack\n- Language: TypeScript 5.x\n- Runtime: Node.js 20 LTS\n- Framework: Express / Next.js\n- Database: PostgreSQL\n\n# Architecture\n- src/api - API routes\n- src/services - Business logic\n- src/models - Data models\n- src/utils - Shared utilities\n\n# Coding Standards\n- Use async/await over callbacks\n- Prefer composition over inheritance\n- All functions must have return types\n\n# Testing\n- Unit tests with Vitest\n- Integration tests in tests/integration\n- Aim for 80% coverage\n```","start_line":1,"end_line":28}]}
{"source_id":"core","type":"contract","title":"AI Safety Guardrails Contract","signals":["contract_lock","security_pattern"],"tags":["ai","safety","guardrails","contract"],"summary":"Contract for implementing AI safety guardrails covering input filtering, output validation, and escalation.","chunks":[{"chunk_id":"core:ai-safety-contract:1","text":"## AI Safety Guardrails Contract\n\n### Input Guardrails\n- **PII Detection**: Mask SSN, credit cards, emails\n- **Injection Detection**: Prompt injection patterns\n- **Content Filtering**: Block harmful requests\n- **Length Limits**: Max input tokens\n\n### Output Guardrails\n- **Hallucination Check**: Verify against sources\n- **Tone Enforcement**: Professional, helpful\n- **Format Validation**: Expected structure\n- **Sensitive Info Leak**: No internal details\n\n### Runtime Controls\n- **Rate Limiting**: Per user/session\n- **Cost Caps**: Max spend per request\n- **Timeout**: Max processing time\n- **Circuit Breaker**: Disable on high error rate\n\n### Escalation\n- Uncertain → Return \"I don't know\"\n- Policy violation → Block and log\n- System error → Graceful fallback","start_line":1,"end_line":26}]}
{"source_id":"core","type":"iterate","title":"Prompt Engineering Playbook","signals":["iterate_loop","context_engineering"],"tags":["prompt","engineering","llm","playbook"],"summary":"Playbook for effective prompt engineering with techniques for clarity, structure, and reliability.","chunks":[{"chunk_id":"core:prompt-engineering:1","text":"## Prompt Engineering Playbook\n\n### Structure\n1. **Role**: Define the AI's persona\n2. **Context**: Provide relevant background\n3. **Task**: Clear instruction\n4. **Format**: Expected output structure\n5. **Examples**: Few-shot demonstrations\n\n### Techniques\n- **Chain of Thought**: \"Think step by step\"\n- **Self-Consistency**: Multiple samples, vote\n- **ReAct**: Reason + Act interleaved\n- **Structured Output**: JSON mode, function calling\n\n### Reliability Tips\n- Be specific, not vague\n- Include edge case handling\n- Test with adversarial inputs\n- Version control your prompts\n\n### Anti-patterns\n- Overly long system prompts (> 2000 tokens)\n- Conflicting instructions\n- Assuming unstated context","start_line":1,"end_line":24}]}
{"source_id":"core","type":"plan","title":"Vibe Coding Workflow","signals":["state_machine","context_engineering"],"tags":["vibe-coding","ai-assisted","workflow"],"summary":"Workflow for AI-assisted 'vibe coding' - rapid prototyping with AI pair programming.","chunks":[{"chunk_id":"core:vibe-coding-workflow:1","text":"## Vibe Coding Workflow\n\n### Phase 1: Spec\n- Write clear requirements in natural language\n- Define acceptance criteria\n- List constraints and non-goals\n- Create contract before coding\n\n### Phase 2: Generate\n- Use AI to scaffold initial code\n- Provide context (existing code, patterns)\n- Review generated code carefully\n- Iterate on feedback\n\n### Phase 3: Refine\n- Run tests, fix failures\n- Apply linting and formatting\n- Refactor for clarity\n- Add documentation\n\n### Phase 4: Verify\n- Full test suite passes\n- Security scan clean\n- Performance acceptable\n- Code review by human\n\n### Best Practices\n- Never ship AI code without review\n- Understand every line you commit\n- AI augments, doesn't replace judgment","start_line":1,"end_line":28}]}
{"source_id":"core","type":"evidence","title":"AI Code Review Checklist","signals":["evidence_audit","iterate_loop"],"tags":["ai","code-review","checklist"],"summary":"Checklist for reviewing AI-generated code before committing.","chunks":[{"chunk_id":"core:ai-code-review:1","text":"## AI Code Review Checklist\n\n### Understanding\n- [ ] I understand what this code does\n- [ ] I can explain it to a teammate\n- [ ] Logic matches my intent\n\n### Correctness\n- [ ] Edge cases handled\n- [ ] No obvious bugs\n- [ ] Error handling appropriate\n- [ ] Types are correct\n\n### Security\n- [ ] No hardcoded secrets\n- [ ] Input validation present\n- [ ] No injection vulnerabilities\n\n### Quality\n- [ ] Code is idiomatic for the language\n- [ ] No unnecessary complexity\n- [ ] Tests cover new code\n- [ ] Documentation updated","start_line":1,"end_line":22}]}
{"source_id":"core","type":"contract","title":"Tool Use Contract (Function Calling)","signals":["contract_lock","agent_pattern"],"tags":["tools","function-calling","ai"],"summary":"Contract for LLM tool use and function calling covering schema, validation, and error handling.","chunks":[{"chunk_id":"core:tool-use-contract:1","text":"## Tool Use Contract\n\n### Tool Definition\n- **Name**: Verb-noun format (get_weather, search_docs)\n- **Description**: When and why to use\n- **Parameters**: JSON Schema with descriptions\n- **Returns**: Expected output format\n\n### Parameter Design\n- Required vs optional clearly marked\n- Enums for constrained values\n- Examples in descriptions\n- Default values documented\n\n### Validation\n- Validate all inputs before execution\n- Return structured errors for invalid input\n- Type coercion where safe\n\n### Error Handling\n- Clear error codes and messages\n- Suggest corrections if possible\n- Never expose internal errors\n\n### Safety\n- Confirm destructive actions\n- Rate limit expensive operations\n- Log all tool invocations","start_line":1,"end_line":26}]}
{"source_id":"core","type":"context_engineering","title":"Context Assembly Strategies","signals":["context_engineering"],"tags":["context","assembly","optimization"],"summary":"Strategies for assembling optimal context for LLM prompts including prioritization and compression.","chunks":[{"chunk_id":"core:context-assembly:1","text":"## Context Assembly Strategies\n\n### Priority Ranking\n1. Current task instructions (highest)\n2. Immediate user query\n3. Relevant code/docs (RAG)\n4. Conversation history\n5. User profile/preferences\n6. General knowledge (lowest)\n\n### Compression Techniques\n- **Summarization**: Condense long histories\n- **Truncation**: Remove oldest messages\n- **Extraction**: Pull key facts only\n- **Deduplication**: Remove redundant info\n\n### Dynamic Selection\n- Score context by relevance to query\n- Fit within token budget\n- Leave room for response\n\n### Quality Signals\n- Recency (newer = more relevant)\n- Semantic similarity to query\n- User engagement (frequently referenced)\n- Source authority","start_line":1,"end_line":24}]}
{"source_id":"core","type":"plan","title":"Prompt Template Management","signals":["state_machine"],"tags":["prompt","template","management"],"summary":"Plan for managing prompt templates with versioning, testing, and deployment.","chunks":[{"chunk_id":"core:prompt-management:1","text":"## Prompt Template Management\n\n### Storage\n- Version controlled in repo\n- Separate folder: /prompts\n- Named by use case: chat.md, summarize.md\n\n### Templating\n- Use variables: {{user_name}}, {{context}}\n- Jinja2 / Handlebars syntax\n- Validate template before deploy\n\n### Testing\n- Golden test cases per template\n- A/B testing infrastructure\n- Track quality metrics over versions\n\n### Deployment\n- Promote from dev → staging → prod\n- Feature flags for rollback\n- Monitor quality post-deploy\n\n### Best Practices\n- Document template purpose\n- Include example inputs/outputs\n- Review changes like code","start_line":1,"end_line":22}]}
{"source_id":"core","type":"security","title":"LLM Security Patterns","signals":["security_pattern"],"tags":["llm","security","injection"],"summary":"Security patterns for LLM applications covering prompt injection, data exfiltration, and model abuse.","chunks":[{"chunk_id":"core:llm-security:1","text":"## LLM Security Patterns\n\n### Prompt Injection Prevention\n- Separate system and user prompts clearly\n- Validate user input before insertion\n- Use structured outputs (JSON mode)\n- Monitor for injection attempts\n\n### Data Exfiltration\n- Don't include secrets in prompts\n- Redact PII before sending\n- Validate outputs for leaked data\n- Log requests without sensitive content\n\n### Model Abuse Prevention\n- Rate limit by user/IP\n- Cost caps per request/session\n- Monitor for unusual patterns\n- CAPTCHA for public endpoints\n\n### Supply Chain\n- Validate third-party prompts\n- Audit MCP servers\n- Pin model versions\n- Test after model updates","start_line":1,"end_line":24}]}
{"source_id":"core","type":"template","title":"AI Project README Template","signals":["evidence_audit"],"tags":["readme","ai","template"],"summary":"README template for AI-powered projects covering model usage, prompts, and evaluation.","chunks":[{"chunk_id":"core:ai-readme-template:1","text":"## AI Project README Template\n\n### Model Usage\n- **Provider**: OpenAI / Anthropic / Local\n- **Model**: gpt-4-turbo / claude-3.5-sonnet\n- **Estimated Cost**: $X per 1000 requests\n\n### Setup\n```bash\nexport OPENAI_API_KEY=sk-...\nnpm install\nnpm start\n```\n\n### Prompts\n- Located in `/prompts` directory\n- Main system prompt: `prompts/system.md`\n- Tool definitions: `prompts/tools.json`\n\n### Evaluation\n- Golden test set: `eval/golden.jsonl`\n- Run evals: `npm run eval`\n- Baseline scores in `eval/baseline.json`\n\n### Known Limitations\n- May hallucinate on [topic]\n- Slow on [edge case]\n- Not suitable for [use case]","start_line":1,"end_line":28}]}
{"source_id":"core","type":"context_engineering","title":"AI Environment Pack System","signals":["context_engineering","provider_adapter"],"tags":["vibe-coding","pack","environment","ai"],"summary":"Pack system for composable, versionable AI environments - the evolution from vibe coding to vibe engineering.","chunks":[{"chunk_id":"core:ai-pack-system:1","text":"## AI Environment Pack System\n\n### Concept: Vibe Engineering\nElevate vibe coding to vibe engineering by treating AI context as composable, versionable environments.\n\n### Pack Components\n- **Rules**: AI operating instructions and workflows\n- **Context**: Persistent knowledge base (memory bank)\n- **Tools**: Helper scripts the AI can invoke\n\n### Pack Lifecycle\n1. **Add**: Install packs to project library\n2. **Compose**: Mix and match packs for your needs\n3. **Sync**: Generate assistant-specific rule files\n4. **Version**: Track changes in source control\n\n### Profile System\n- Named groups of packs for instant switching\n- `dev-profile`: Development packs\n- `review-profile`: Code review packs\n- `deploy-profile`: Deployment packs\n\n### Multi-Assistant Sync\n- Define once, deploy to: Cursor, Copilot, Claude, Gemini\n- Automatic format translation per assistant\n- Consistent behavior across all tools","start_line":1,"end_line":26}]}
{"source_id":"core","type":"contract","title":"AI Memory Bank Contract","signals":["contract_lock","context_engineering"],"tags":["memory","context","persistence","ai"],"summary":"Contract for persistent AI memory systems - project documentation, learned patterns, and context that survives across sessions.","chunks":[{"chunk_id":"core:memory-bank-contract:1","text":"## AI Memory Bank Contract\n\n### Memory Structure\n```\nmemory/\n├── project/          # Project-specific context\n│   ├── architecture.md\n│   ├── conventions.md\n│   └── decisions.md\n├── docs/             # Documentation context\n│   └── user_guide/\n└── patterns/         # Learned patterns\n    └── common_fixes.md\n```\n\n### Memory Types\n- **Static**: Architecture docs, coding standards\n- **Learned**: Patterns discovered during development\n- **Session**: Current task context (ephemeral)\n\n### Memory Operations\n- **Read**: Always include relevant memory in context\n- **Write**: Update after significant discoveries\n- **Prune**: Remove outdated information\n- **Version**: Track memory changes in git\n\n### Best Practices\n- Keep memory files focused and concise\n- Use markdown for human+AI readability\n- Reference memory in conversations","start_line":1,"end_line":30}]}
{"source_id":"core","type":"plan","title":"Project Analysis & Detection Plan","signals":["state_machine"],"tags":["analysis","detection","automation"],"summary":"Plan for automatic project analysis - detecting technologies, frameworks, and patterns to generate AI-aware configurations.","chunks":[{"chunk_id":"core:project-analysis-plan:1","text":"## Project Analysis & Detection Plan\n\n### Phase 1: Technology Detection\n- [ ] Parse package.json / Cargo.toml / pyproject.toml\n- [ ] Detect frameworks (React, Next.js, FastAPI, Axum)\n- [ ] Identify build tools (Vite, Webpack, esbuild)\n- [ ] Recognize testing frameworks (Jest, Vitest, pytest)\n\n### Phase 2: Pattern Recognition\n- [ ] Analyze file structure conventions\n- [ ] Detect naming patterns (camelCase, snake_case)\n- [ ] Identify architectural patterns (MVC, Clean, Hexagonal)\n- [ ] Extract common code patterns\n\n### Phase 3: Rule Generation\n- [ ] Create project-specific AI rules\n- [ ] Generate framework best practices\n- [ ] Add detected patterns as conventions\n- [ ] Configure tool integrations\n\n### Phase 4: Deployment\n- [ ] Generate .cursorrules / CLAUDE.md\n- [ ] Create .github/copilot-instructions.md\n- [ ] Set up IDE-specific configurations","start_line":1,"end_line":24}]}
{"source_id":"core","type":"contract","title":"AI Context Migration Contract","signals":["contract_lock","context_engineering"],"tags":["migration","context","conversion"],"summary":"Contract for migrating existing AI contexts between different assistant formats.","chunks":[{"chunk_id":"core:context-migration-contract:1","text":"## AI Context Migration Contract\n\n### Supported Sources\n- CLAUDE.md files and .claude/ directories\n- .cursorrules and .cursor/ configurations\n- .github/copilot-instructions.md\n- .windsurf/ rules and configurations\n\n### Migration Process\n1. **Detect**: Scan for existing AI contexts\n2. **Parse**: Extract rules, patterns, instructions\n3. **Normalize**: Convert to universal format\n4. **Enhance**: Add project-specific adaptations\n5. **Deploy**: Generate target assistant files\n\n### Confidence Levels\n- **High**: Direct format match, no changes\n- **Medium**: Minor adaptations needed\n- **Low**: Manual review recommended\n\n### Best Practices\n- Always backup before migration\n- Review converted rules manually\n- Test with simple prompts first\n- Iterate based on AI behavior","start_line":1,"end_line":24}]}
{"source_id":"core","type":"contract","title":"Decorator-Based Tool Pattern","signals":["contract_lock","agent_pattern"],"tags":["tools","decorator","python","pattern"],"summary":"Pattern for creating AI tools using decorators - converting Python functions into Claude-compatible tools.","chunks":[{"chunk_id":"core:decorator-tool-pattern:1","text":"## Decorator-Based Tool Pattern\n\n### Basic Pattern\n```python\nfrom toolkit import BaseTool, tool\n\nclass CalculatorTool(BaseTool):\n    @tool()\n    async def add(self, a: float, b: float) -> dict:\n        \"\"\"Adds two numbers together\"\"\"\n        return {\"result\": a + b}\n```\n\n### Decorator Options\n- `@tool()`: Basic async tool\n- `@tool(parallel=True)`: CPU-intensive, runs in process pool\n- `@tool(timeout_s=60)`: Custom timeout\n\n### Best Practices\n- Use type hints for auto-schema generation\n- Docstrings become tool descriptions\n- Return dicts for structured output\n- Use context managers for cleanup\n\n### Error Handling\n- Raise specific exceptions\n- Return error info in dict\n- Log failures for debugging","start_line":1,"end_line":26}]}
{"source_id":"core","type":"security","title":"Runtime Isolation Patterns","signals":["security_pattern","agent_pattern"],"tags":["isolation","docker","security","runtime"],"summary":"Patterns for isolating AI tool execution using containers for production safety.","chunks":[{"chunk_id":"core:runtime-isolation:1","text":"## Runtime Isolation Patterns\n\n### Why Isolate?\n- Prevent unintended system access\n- Control exactly which tools are available\n- Consistent behavior across environments\n- Production-ready safety guarantees\n\n### Docker Isolation (Production)\n- Container runs only defined tools\n- No access to system tools (ls, grep)\n- Clean, predictable execution\n- ~3 second startup overhead\n\n### Subprocess Isolation (Development)\n- Process isolation with limited scope\n- Fast startup (~0.5 seconds)\n- Good for local development\n- Still isolated from main process\n\n### Permission-Based File Access\n```python\npermissions = [\n    (\"*.txt\", \"read\"),\n    (\"data/**\", \"write\"),\n    (\"logs/*.log\", \"read\"),\n]\nfs_tool = FileSystemTool(permissions=permissions)\n```","start_line":1,"end_line":28}]}
{"source_id":"core","type":"template","title":"Universal AI Rules Template","signals":["context_engineering"],"tags":["rules","universal","template"],"summary":"Universal template for AI rules that work across multiple assistants - Cursor, Copilot, Claude, Gemini.","chunks":[{"chunk_id":"core:universal-ai-rules:1","text":"## Universal AI Rules Template\n\n### Format: Works Everywhere\n```markdown\n# Project: [Name]\n\n## Context\n- Language: [TypeScript/Rust/Python]\n- Framework: [Next.js/Axum/FastAPI]\n- Testing: [Vitest/pytest/cargo test]\n\n## Code Conventions\n- Naming: [camelCase/snake_case]\n- Imports: [order preference]\n- Error handling: [pattern]\n\n## Architecture\n- Structure: [description]\n- Key directories: [list]\n- Entry points: [files]\n\n## Do's\n- [Preferred patterns]\n\n## Don'ts\n- [Anti-patterns to avoid]\n```\n\n### Assistant-Specific Locations\n- Cursor: `.cursor/rules/*.mdc`\n- Copilot: `.github/copilot-instructions.md`\n- Claude: `CLAUDE.md` or `.claude/`\n- Gemini: `GEMINI.md`","start_line":1,"end_line":32}]}
{"source_id":"core","type":"plan","title":"AI Rule Authoring Plan","signals":["state_machine"],"tags":["rules","authoring","plan"],"summary":"Plan for authoring effective AI assistant rules that improve code suggestions and reduce iterations.","chunks":[{"chunk_id":"core:rule-authoring-plan:1","text":"## AI Rule Authoring Plan\n\n### Phase 1: Analyze Project\n- [ ] Identify tech stack (framework, language, tools)\n- [ ] Document coding conventions\n- [ ] List common patterns used\n- [ ] Note anti-patterns to avoid\n\n### Phase 2: Write Core Rules\n- [ ] Project overview (one paragraph)\n- [ ] Directory structure explanation\n- [ ] Key architectural decisions\n- [ ] Code style requirements\n\n### Phase 3: Add Specifics\n- [ ] Framework-specific patterns\n- [ ] Testing conventions\n- [ ] Error handling patterns\n- [ ] Security requirements\n\n### Phase 4: Test & Iterate\n- [ ] Test with simple prompts\n- [ ] Measure suggestion quality\n- [ ] Refine based on AI behavior\n- [ ] Remove redundant rules","start_line":1,"end_line":24}]}
{"source_id":"core","type":"evidence","title":"AI Suggestion Quality Metrics","signals":["evidence_audit","iterate_loop"],"tags":["metrics","quality","ai","suggestions"],"summary":"Metrics for measuring and improving AI code suggestion quality.","chunks":[{"chunk_id":"core:ai-suggestion-metrics:1","text":"## AI Suggestion Quality Metrics\n\n### Key Metrics\n- **Acceptance Rate**: % of suggestions accepted\n- **First-Try Success**: % correct on first attempt\n- **Iteration Count**: Average edits per task\n- **Relevance Score**: How well suggestions match context\n\n### Measurement Methods\n- Track accepted vs rejected suggestions\n- Count back-and-forth clarifications\n- Time from prompt to working code\n- Manual quality sampling\n\n### Improvement Signals\n- 60% faster initial suggestions (good rules)\n- 85% more relevant completions\n- 40% fewer clarifications needed\n- 90% consistency in patterns\n\n### Optimization Actions\n- Add missing context to rules\n- Remove conflicting instructions\n- Include more examples\n- Update for new patterns","start_line":1,"end_line":24}]}
{"source_id":"core","type":"contract","title":"Type-Safe Data Transfer Contract","signals":["contract_lock","agent_pattern"],"tags":["data-transfer","pydantic","type-safety"],"summary":"Contract for type-safe data transfer between AI agents and applications using schema validation.","chunks":[{"chunk_id":"core:data-transfer-contract:1","text":"## Type-Safe Data Transfer Contract\n\n### Schema Definition (Pydantic)\n```python\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass UserProfile(BaseModel):\n    name: str = Field(..., description=\"Full name\")\n    age: int = Field(..., ge=0, le=150)\n    interests: List[str] = Field(default_factory=list)\n```\n\n### Transfer Flow\n1. Define schema with validation rules\n2. AI receives schema with descriptions\n3. AI outputs data matching schema\n4. Application validates and uses data\n\n### Benefits\n- Type checking catches errors early\n- Descriptions guide AI output format\n- Validation ensures data quality\n- Clear contract between AI and code\n\n### Error Handling\n- Return validation errors to AI\n- Allow retry with corrections\n- Log malformed outputs for analysis","start_line":1,"end_line":26}]}
{"source_id":"core","type":"plan","title":"Composable AI Environment Plan","signals":["state_machine","context_engineering"],"tags":["composable","environment","plan"],"summary":"Plan for building composable AI environments that can be mixed, matched, and versioned.","chunks":[{"chunk_id":"core:composable-env-plan:1","text":"## Composable AI Environment Plan\n\n### Phase 1: Core Packs\n- [ ] Language pack (TypeScript, Rust, Python)\n- [ ] Framework pack (React, Axum, FastAPI)\n- [ ] Testing pack (unit, integration, e2e)\n- [ ] Security pack (auth, validation, secrets)\n\n### Phase 2: Role Packs\n- [ ] Developer pack (coding conventions)\n- [ ] Reviewer pack (code review checklist)\n- [ ] DevOps pack (CI/CD, deployment)\n- [ ] Architect pack (design decisions)\n\n### Phase 3: Project Packs\n- [ ] Project-specific conventions\n- [ ] Custom patterns and utilities\n- [ ] Team preferences\n\n### Composition Rules\n- Packs layer, later overrides earlier\n- No circular dependencies\n- Clear precedence order\n- Document conflicts","start_line":1,"end_line":24}]}
{"source_id":"core","type":"iterate","title":"AI Context Debugging Playbook","signals":["iterate_loop"],"tags":["debugging","context","ai"],"summary":"Playbook for debugging when AI assistant gives unexpected or incorrect suggestions.","chunks":[{"chunk_id":"core:ai-context-debug:1","text":"## AI Context Debugging Playbook\n\n### Symptom: Wrong Framework Patterns\n- Check: Are framework rules loaded?\n- Fix: Add explicit framework to rules\n- Verify: Test with framework-specific prompt\n\n### Symptom: Ignoring Conventions\n- Check: Is convention documented in rules?\n- Fix: Add clear Do/Don't examples\n- Verify: Ask AI to explain conventions\n\n### Symptom: Outdated Suggestions\n- Check: When were rules last updated?\n- Fix: Refresh rules with current patterns\n- Verify: Check for deprecated patterns\n\n### Symptom: Context Overflow\n- Check: Total token count in context\n- Fix: Summarize or split rules\n- Verify: Most important rules at top\n\n### General Debug Steps\n1. Review current loaded context\n2. Simplify to minimal reproduction\n3. Add explicit instruction\n4. Document fix in rules","start_line":1,"end_line":26}]}
{"source_id":"core","type":"evidence","title":"CLAUDE.md Quality Scoring System","signals":["evidence_audit","context_engineering"],"tags":["claude","quality","scoring","metrics"],"summary":"Quality scoring system (0-100) for evaluating CLAUDE.md files based on completeness, clarity, and effectiveness.","chunks":[{"chunk_id":"core:claude-quality-scoring:1","text":"## CLAUDE.md Quality Scoring System\n\n### Scoring Categories (0-100)\n\n**Structure (25 points)**\n- Clear sections: 5pts\n- Logical organization: 5pts\n- Proper markdown formatting: 5pts\n- Table of contents: 5pts\n- Consistent heading levels: 5pts\n\n**Content (35 points)**\n- Project overview present: 5pts\n- Tech stack documented: 5pts\n- Architecture explained: 10pts\n- Coding conventions: 10pts\n- Examples included: 5pts\n\n**Actionability (25 points)**\n- Clear Do's list: 10pts\n- Clear Don'ts list: 10pts\n- Decision criteria: 5pts\n\n**Completeness (15 points)**\n- All major areas covered: 5pts\n- No contradictions: 5pts\n- Up-to-date information: 5pts\n\n### Quality Tiers\n- 90-100: Excellent - Ready for production\n- 70-89: Good - Minor improvements needed\n- 50-69: Fair - Significant gaps\n- 0-49: Poor - Major rewrite needed","start_line":1,"end_line":32}]}
{"source_id":"core","type":"contract","title":"Guardian Agent Pattern","signals":["contract_lock","agent_pattern"],"tags":["guardian","auto-sync","agent","pattern"],"summary":"Guardian agent pattern for automatic synchronization of AI context files when project changes are detected.","chunks":[{"chunk_id":"core:guardian-agent-pattern:1","text":"## Guardian Agent Pattern\n\n### Purpose\nAutomatically keep AI context files in sync with codebase changes.\n\n### Trigger Events\n- Package dependency changes\n- New files/directories created\n- Configuration file updates\n- Architecture changes detected\n\n### Guardian Actions\n1. **Watch**: Monitor file system for changes\n2. **Analyze**: Determine if context update needed\n3. **Propose**: Generate context file changes\n4. **Apply**: Update files (with confirmation or auto)\n\n### Implementation Modes\n- **Auto-sync**: Apply changes automatically\n- **Suggest**: Create PR/commit with changes\n- **Report**: Only notify, no changes\n\n### Monitored Files\n- package.json / Cargo.toml / pyproject.toml\n- tsconfig.json / .eslintrc\n- Directory structure changes\n- New framework files detected\n\n### Best Practices\n- Run on git hooks (pre-commit)\n- CI validation of context freshness\n- Version control all context files","start_line":1,"end_line":30}]}
{"source_id":"core","type":"plan","title":"Modular CLAUDE.md Architecture Plan","signals":["state_machine","context_engineering"],"tags":["claude","modular","architecture","plan"],"summary":"Plan for modular CLAUDE.md architecture with root and component-specific context files.","chunks":[{"chunk_id":"core:modular-claude-plan:1","text":"## Modular CLAUDE.md Architecture Plan\n\n### Structure\n```\nproject/\n├── CLAUDE.md              # Root: global context\n├── backend/\n│   └── CLAUDE.md          # Backend-specific\n├── frontend/\n│   └── CLAUDE.md          # Frontend-specific\n├── shared/\n│   └── CLAUDE.md          # Shared libraries\n└── docs/\n    └── CLAUDE.md          # Documentation context\n```\n\n### Root CLAUDE.md Contains\n- Project overview and mission\n- Cross-cutting concerns\n- Team conventions\n- Architecture principles\n\n### Component CLAUDE.md Contains\n- Component-specific patterns\n- Local dependencies\n- Testing approach for component\n- API contracts\n\n### Context Loading\n- Claude loads nearest CLAUDE.md first\n- Inherits from parent directories\n- Local rules override global","start_line":1,"end_line":32}]}
{"source_id":"core","type":"contract","title":"Spec-Driven Development Contract","signals":["contract_lock","agent_pattern"],"tags":["spec","specification","development","contract"],"summary":"Contract for spec-driven development where specifications drive automated code generation and validation.","chunks":[{"chunk_id":"core:spec-driven-contract:1","text":"## Spec-Driven Development Contract\n\n### Specification Structure\n```yaml\nspec:\n  name: UserService\n  type: service\n  description: Handles user CRUD operations\n  \ninterfaces:\n  - name: createUser\n    input: CreateUserInput\n    output: User\n    errors: [ValidationError, DuplicateError]\n    \nconstraints:\n  - email must be unique\n  - password min 8 characters\n  - rate limit: 100/min\n```\n\n### Workflow\n1. **Write Spec**: Human defines requirements\n2. **Generate**: AI generates implementation\n3. **Validate**: Tests verify spec compliance\n4. **Iterate**: Refine spec and regenerate\n\n### Benefits\n- Single source of truth\n- Automated test generation\n- Documentation always current\n- Clear contract between teams","start_line":1,"end_line":30}]}
{"source_id":"core","type":"plan","title":"Autonomous Coding Agent Plan","signals":["state_machine","agent_pattern"],"tags":["autonomous","agent","coding","plan"],"summary":"Plan for building autonomous coding agents that can plan, implement, and validate code changes.","chunks":[{"chunk_id":"core:autonomous-agent-plan:1","text":"## Autonomous Coding Agent Plan\n\n### Phase 1: Understanding\n- [ ] Parse issue/task description\n- [ ] Analyze relevant codebase context\n- [ ] Identify affected files and functions\n- [ ] Map dependencies and impacts\n\n### Phase 2: Planning\n- [ ] Break task into subtasks\n- [ ] Define success criteria\n- [ ] Estimate complexity\n- [ ] Identify risks and edge cases\n\n### Phase 3: Implementation\n- [ ] Generate code changes\n- [ ] Write/update tests\n- [ ] Update documentation\n- [ ] Format and lint\n\n### Phase 4: Validation\n- [ ] Run test suite\n- [ ] Check coverage maintained\n- [ ] Verify no regressions\n- [ ] Security scan\n\n### Phase 5: Submission\n- [ ] Create branch and commits\n- [ ] Open pull request\n- [ ] Respond to review feedback\n- [ ] Iterate until merged","start_line":1,"end_line":30}]}
{"source_id":"core","type":"contract","title":"SDLC Automation Contract","signals":["contract_lock","agent_pattern"],"tags":["sdlc","automation","lifecycle","contract"],"summary":"Contract for AI-automated Software Development Lifecycle covering requirements, design, implementation, testing, and deployment.","chunks":[{"chunk_id":"core:sdlc-automation-contract:1","text":"## SDLC Automation Contract\n\n### Automated Phases\n\n**1. Requirements Analysis**\n- Parse natural language requirements\n- Extract user stories\n- Identify acceptance criteria\n- Generate test scenarios\n\n**2. Design**\n- Generate architecture diagrams\n- Propose database schema\n- Define API contracts\n- Create component breakdown\n\n**3. Implementation**\n- Generate boilerplate code\n- Implement business logic\n- Create tests alongside code\n- Add inline documentation\n\n**4. Testing**\n- Run unit tests\n- Execute integration tests\n- Perform security scanning\n- Validate performance\n\n**5. Deployment**\n- Generate CI/CD pipelines\n- Create deployment configs\n- Set up monitoring\n- Automate rollback procedures\n\n### Human Checkpoints\n- Design review before implementation\n- Code review before merge\n- Security approval before production","start_line":1,"end_line":34}]}
{"source_id":"core","type":"plan","title":"AI Team Collaboration Plan","signals":["state_machine","agent_pattern"],"tags":["team","collaboration","multi-agent","plan"],"summary":"Plan for AI agents working as a team with different roles and responsibilities.","chunks":[{"chunk_id":"core:ai-team-plan:1","text":"## AI Team Collaboration Plan\n\n### Agent Roles\n\n**Architect Agent**\n- Reviews design decisions\n- Ensures consistency with patterns\n- Validates architecture compliance\n\n**Developer Agent**\n- Implements code changes\n- Writes unit tests\n- Follows coding conventions\n\n**QA Agent**\n- Reviews code for bugs\n- Writes integration tests\n- Validates edge cases\n\n**Security Agent**\n- Scans for vulnerabilities\n- Reviews auth/authz logic\n- Checks for data exposure\n\n**DevOps Agent**\n- Manages CI/CD pipelines\n- Handles deployment configs\n- Monitors production health\n\n### Collaboration Protocol\n1. Task assigned to Developer Agent\n2. Implementation reviewed by QA Agent\n3. Architecture validated by Architect Agent\n4. Security approved by Security Agent\n5. Deployment handled by DevOps Agent","start_line":1,"end_line":34}]}
{"source_id":"core","type":"template","title":"Task as Code Template","signals":["agent_pattern"],"tags":["task","code","template","orchestration"],"summary":"Template for defining tasks as code - structured task definitions that AI agents can execute.","chunks":[{"chunk_id":"core:task-as-code:1","text":"## Task as Code Template\n\n### Task Definition (YAML)\n```yaml\ntask:\n  id: implement-user-auth\n  title: Implement User Authentication\n  type: feature\n  priority: high\n  \ncontext:\n  - src/auth/**\n  - docs/security.md\n  \nsteps:\n  - name: Design\n    agent: architect\n    output: design_doc.md\n    \n  - name: Implement\n    agent: developer\n    input: design_doc.md\n    output: code_changes\n    \n  - name: Test\n    agent: qa\n    input: code_changes\n    output: test_results\n    \nvalidation:\n  - tests_pass: true\n  - coverage_min: 80\n  - security_scan: clean\n```\n\n### Benefits\n- Reproducible task execution\n- Clear progress tracking\n- Auditable workflow\n- Easy to iterate and improve","start_line":1,"end_line":38}]}
{"source_id":"core","type":"contract","title":"AI-First Development Contract","signals":["contract_lock","agent_pattern"],"tags":["ai-first","development","contract"],"summary":"Contract for AI-first development methodology where AI is the primary implementer and humans provide oversight.","chunks":[{"chunk_id":"core:ai-first-contract:1","text":"## AI-First Development Contract\n\n### Principles\n1. **AI Generates, Human Validates**\n   - AI writes first draft of code\n   - Human reviews and approves\n   - AI iterates on feedback\n\n2. **Specification Over Implementation**\n   - Clear specs before coding\n   - Tests define behavior\n   - AI implements to pass tests\n\n3. **Continuous Context**\n   - Project context always available\n   - Historical decisions preserved\n   - Patterns documented and enforced\n\n### Workflow\n```\nHuman: Define requirement\n  ↓\nAI: Generate implementation\n  ↓\nCI: Validate (tests, lint, security)\n  ↓\nHuman: Review and approve\n  ↓\nAI: Address feedback\n  ↓\nMerge and Deploy\n```\n\n### Guardrails\n- No AI changes to production without review\n- Security-sensitive code requires human\n- Breaking changes flagged for discussion","start_line":1,"end_line":32}]}
{"source_id":"core","type":"evidence","title":"Agent Execution Audit Trail","signals":["evidence_audit","agent_pattern"],"tags":["audit","agent","execution","tracing"],"summary":"Standards for auditing AI agent execution including actions taken, decisions made, and outcomes.","chunks":[{"chunk_id":"core:agent-audit-trail:1","text":"## Agent Execution Audit Trail\n\n### Required Fields\n- **session_id**: Unique execution session\n- **timestamp**: ISO 8601 with timezone\n- **agent_id**: Which agent executed\n- **action**: What was attempted\n- **input**: Parameters provided\n- **output**: Result or error\n- **duration_ms**: Execution time\n\n### Action Categories\n- **read**: File read, search, retrieval\n- **write**: File create/modify, code generation\n- **execute**: Run commands, tests\n- **communicate**: API calls, messages\n\n### Audit Storage\n- JSON Lines format\n- Retained for 90 days minimum\n- Searchable by session, agent, action\n- Redact sensitive data\n\n### Compliance\n- Reproducible: Re-run from audit\n- Traceable: Full decision chain\n- Auditable: Human can review\n- Deletable: GDPR compliant","start_line":1,"end_line":28}]}
{"source_id":"core","type":"iterate","title":"Agent Error Recovery Playbook","signals":["iterate_loop","agent_pattern"],"tags":["agent","error","recovery","playbook"],"summary":"Playbook for recovering from AI agent errors including retry strategies, fallbacks, and escalation.","chunks":[{"chunk_id":"core:agent-error-recovery:1","text":"## Agent Error Recovery Playbook\n\n### Error Categories\n\n**Transient Errors**\n- API timeout\n- Rate limit exceeded\n- Network hiccup\n→ Retry with exponential backoff\n\n**Input Errors**\n- Invalid parameters\n- Missing context\n- Ambiguous instruction\n→ Request clarification or fix input\n\n**Logic Errors**\n- Wrong tool selected\n- Incorrect reasoning\n- Hallucinated facts\n→ Reset and retry with more context\n\n**Resource Errors**\n- Token limit exceeded\n- Memory exhausted\n- Cost limit reached\n→ Summarize context, reduce scope\n\n### Escalation Triggers\n- Same error 3 times\n- Critical operation failed\n- Security violation detected\n→ Pause and notify human","start_line":1,"end_line":32}]}
{"source_id":"core","type":"contract","title":"Intelligent Test Generation Contract","signals":["contract_lock","iterate_loop"],"tags":["testing","generation","ai","contract"],"summary":"Contract for AI-powered test generation covering unit tests, edge cases, and property-based testing.","chunks":[{"chunk_id":"core:test-generation-contract:1","text":"## Intelligent Test Generation Contract\n\n### Test Types Generated\n\n**Unit Tests**\n- Happy path scenarios\n- Edge cases from type analysis\n- Error handling paths\n- Boundary conditions\n\n**Integration Tests**\n- API endpoint coverage\n- Database interactions\n- External service mocks\n\n**Property-Based Tests**\n- Invariants from function signatures\n- Fuzz testing for inputs\n- Randomized data generation\n\n### Generation Rules\n- One test file per source file\n- Descriptive test names\n- AAA pattern (Arrange, Act, Assert)\n- Isolated, no shared state\n\n### Quality Gates\n- Coverage: 80% minimum\n- All assertions meaningful\n- No flaky tests\n- Fast execution (< 10s per suite)","start_line":1,"end_line":30}]}
{"source_id":"core","type":"plan","title":"Code Understanding Pipeline Plan","signals":["state_machine","context_engineering"],"tags":["understanding","analysis","pipeline","plan"],"summary":"Plan for building code understanding pipelines that analyze and index codebases for AI consumption.","chunks":[{"chunk_id":"core:code-understanding-plan:1","text":"## Code Understanding Pipeline Plan\n\n### Phase 1: Parsing\n- [ ] Parse source files (AST extraction)\n- [ ] Extract function/class signatures\n- [ ] Identify dependencies and imports\n- [ ] Map file relationships\n\n### Phase 2: Analysis\n- [ ] Generate call graphs\n- [ ] Identify design patterns\n- [ ] Detect code smells\n- [ ] Calculate complexity metrics\n\n### Phase 3: Indexing\n- [ ] Create semantic embeddings\n- [ ] Build full-text search index\n- [ ] Store in vector database\n- [ ] Generate summaries per file/function\n\n### Phase 4: Context Generation\n- [ ] Auto-generate project README\n- [ ] Create CLAUDE.md from analysis\n- [ ] Build API documentation\n- [ ] Generate onboarding guide\n\n### Refresh Strategy\n- Incremental updates on file change\n- Full reindex weekly\n- Cache invalidation on structure change","start_line":1,"end_line":28}]}
{"source_id":"core","type":"security","title":"AI Agent Sandbox Security","signals":["security_pattern","agent_pattern"],"tags":["sandbox","security","isolation","agent"],"summary":"Security patterns for sandboxing AI agent execution to prevent unintended system access.","chunks":[{"chunk_id":"core:agent-sandbox-security:1","text":"## AI Agent Sandbox Security\n\n### Isolation Layers\n\n**Process Isolation**\n- Separate process per agent\n- Limited system calls (seccomp)\n- No network access by default\n- Restricted file system view\n\n**Container Isolation**\n- Minimal base image\n- Read-only root filesystem\n- No privileged access\n- Resource limits (CPU, memory)\n\n**Virtual Machine Isolation**\n- Full OS separation\n- Hardware-level isolation\n- Snapshot and rollback\n- For highest security requirements\n\n### Permission Model\n```yaml\npermissions:\n  files:\n    read: [\"src/**\", \"docs/**\"]\n    write: [\"output/**\"]\n  network:\n    allowed: [\"api.openai.com\"]\n  commands:\n    allowed: [\"npm test\", \"cargo build\"]\n    denied: [\"rm -rf\", \"curl\"]\n```","start_line":1,"end_line":32}]}
{"source_id":"core","type":"template","title":"GEMINI.md Template","signals":["context_engineering"],"tags":["gemini","template","google","ai"],"summary":"Template for GEMINI.md configuration files for Google Gemini AI assistant context.","chunks":[{"chunk_id":"core:gemini-template:1","text":"## GEMINI.md Template\n\n### File: GEMINI.md\n```markdown\n# Project Context for Gemini\n\n## Overview\n[Brief project description]\n\n## Tech Stack\n- Language: [TypeScript/Python/Go]\n- Framework: [Next.js/FastAPI/Gin]\n- Database: [PostgreSQL/MongoDB]\n\n## Project Structure\n```\nsrc/\n├── api/       # API routes\n├── services/  # Business logic\n├── models/    # Data models\n└── utils/     # Utilities\n```\n\n## Coding Standards\n- [Naming conventions]\n- [Error handling patterns]\n- [Testing requirements]\n\n## Gemini-Specific Instructions\n- Use structured outputs when possible\n- Include code comments for complex logic\n- Follow project's existing patterns\n```","start_line":1,"end_line":32}]}
{"source_id":"core","type":"template","title":"WINDSURF.md Template","signals":["context_engineering"],"tags":["windsurf","template","ai"],"summary":"Template for Windsurf AI assistant configuration files.","chunks":[{"chunk_id":"core:windsurf-template:1","text":"## WINDSURF.md Template\n\n### File: .windsurf/rules.md\n```markdown\n# Windsurf Rules\n\n## Project Info\n- Name: [Project Name]\n- Type: [Web App/API/CLI]\n- Language: [Primary Language]\n\n## Cascade Agent Behavior\n- Always read relevant files before changes\n- Write tests for new functions\n- Format code after modifications\n- Commit with conventional messages\n\n## Memory Persistence\n- Store learned patterns in .windsurf/memory/\n- Reference previous solutions\n- Track project-specific conventions\n\n## Tool Usage\n- Prefer built-in tools over shell commands\n- Use semantic search for large codebases\n- Batch file operations when possible\n```","start_line":1,"end_line":26}]}
{"source_id":"core","type":"contract","title":"Semantic Code Search Contract","signals":["contract_lock","context_engineering"],"tags":["search","semantic","code","contract"],"summary":"Contract for semantic code search systems enabling natural language queries over codebases.","chunks":[{"chunk_id":"core:semantic-search-contract:1","text":"## Semantic Code Search Contract\n\n### Index Components\n- **Code Chunks**: Function-level embeddings\n- **Documentation**: Comments, docstrings, README\n- **Commit Messages**: Historical context\n- **Issues/PRs**: Problem-solution pairs\n\n### Query Types\n- \"How does authentication work?\"\n- \"Where is the database connection?\"\n- \"Functions that handle user input\"\n- \"Similar code to this function\"\n\n### Ranking Signals\n- Semantic similarity (cosine distance)\n- Recency (newer code preferred)\n- Popularity (frequently accessed)\n- Relevance (file path match)\n\n### Quality Metrics\n- Recall@10: 80% minimum\n- Latency: < 500ms p95\n- Precision: Relevant in top 3 results\n\n### Index Freshness\n- Real-time on file save\n- Full reindex nightly","start_line":1,"end_line":28}]}
{"source_id":"core","type":"plan","title":"Knowledge Graph for Code Plan","signals":["state_machine","context_engineering"],"tags":["knowledge-graph","code","plan"],"summary":"Plan for building knowledge graphs that represent codebase structure, relationships, and semantics.","chunks":[{"chunk_id":"core:knowledge-graph-plan:1","text":"## Knowledge Graph for Code Plan\n\n### Phase 1: Entity Extraction\n- [ ] Files, classes, functions, variables\n- [ ] Types and interfaces\n- [ ] Configuration values\n- [ ] External dependencies\n\n### Phase 2: Relationship Mapping\n- [ ] imports/exports\n- [ ] calls/called_by\n- [ ] implements/extends\n- [ ] uses/used_by\n- [ ] tests/tested_by\n\n### Phase 3: Semantic Enrichment\n- [ ] Purpose descriptions\n- [ ] Category classification\n- [ ] Complexity ratings\n- [ ] Quality scores\n\n### Phase 4: Query Interface\n- [ ] GraphQL API for queries\n- [ ] Natural language query translation\n- [ ] Visualization dashboard\n- [ ] Integration with AI assistants\n\n### Use Cases\n- Impact analysis for changes\n- Dependency visualization\n- Dead code detection\n- Architecture documentation","start_line":1,"end_line":32}]}
{"source_id":"core","type":"evidence","title":"AI Development Metrics Dashboard","signals":["evidence_audit"],"tags":["metrics","dashboard","development"],"summary":"Key metrics for tracking AI-assisted development productivity and quality.","chunks":[{"chunk_id":"core:ai-dev-metrics:1","text":"## AI Development Metrics Dashboard\n\n### Productivity Metrics\n- **Throughput**: PRs merged per week\n- **Velocity**: Story points completed\n- **Cycle Time**: Commit to production\n- **AI Contribution**: % code by AI\n\n### Quality Metrics\n- **Defect Rate**: Bugs per feature\n- **Test Coverage**: % lines covered\n- **Code Review Time**: Hours per PR\n- **Rework Rate**: % changes revised\n\n### AI-Specific Metrics\n- **Suggestion Acceptance**: % accepted\n- **Context Relevance**: Score 0-100\n- **Iteration Count**: Attempts per task\n- **Token Efficiency**: Tokens per output\n\n### Trend Indicators\n- Week-over-week improvement\n- Compare AI vs manual tasks\n- Track regression causes\n- Identify training opportunities","start_line":1,"end_line":26}]}
{"source_id":"core","type":"iterate","title":"Continuous Learning for AI Agents","signals":["iterate_loop","agent_pattern"],"tags":["learning","continuous","agent"],"summary":"Patterns for AI agents to learn and improve from past interactions and outcomes.","chunks":[{"chunk_id":"core:agent-learning:1","text":"## Continuous Learning for AI Agents\n\n### Learning Sources\n- **Success Patterns**: What worked well\n- **Failure Analysis**: What went wrong\n- **User Feedback**: Explicit corrections\n- **Outcome Data**: Test results, deployments\n\n### Memory Updates\n- Store successful solutions\n- Record common mistakes\n- Track user preferences\n- Build project-specific patterns\n\n### Learning Cycle\n1. Execute task\n2. Observe outcome\n3. Extract lessons\n4. Update memory/rules\n5. Apply to future tasks\n\n### Anti-Patterns\n- Overfitting to recent examples\n- Ignoring edge cases\n- Contradicting established rules\n- Learning wrong patterns from noise","start_line":1,"end_line":26}]}
{"source_id":"core","type":"contract","title":"Conversational AI Contract","signals":["contract_lock","agent_pattern"],"tags":["conversational","chat","ai","contract"],"summary":"Contract for conversational AI interfaces covering tone, context management, and interaction patterns.","chunks":[{"chunk_id":"core:conversational-ai-contract:1","text":"## Conversational AI Contract\n\n### Tone & Style\n- **Professional**: Business-appropriate language\n- **Helpful**: Prioritize user success\n- **Concise**: Minimize unnecessary words\n- **Accurate**: Never guess, say \"I don't know\"\n\n### Context Management\n- Remember conversation history\n- Reference earlier messages naturally\n- Summarize long conversations\n- Clear context on topic change\n\n### Interaction Patterns\n- Confirm understanding before acting\n- Ask clarifying questions\n- Provide options when ambiguous\n- Explain reasoning when helpful\n\n### Response Structure\n- Lead with the answer\n- Support with details\n- End with next steps\n- Use formatting for clarity\n\n### Error Handling\n- Acknowledge mistakes\n- Correct and continue\n- Learn from corrections","start_line":1,"end_line":28}]}
{"source_id":"core","type":"contract","title":"CrewAI Multi-Agent Crew Contract","signals":["contract_lock","agent_pattern"],"tags":["crewai","multi-agent","crew","orchestration"],"summary":"Contract template for CrewAI-style multi-agent crews with roles, tasks, and process definitions.","chunks":[{"chunk_id":"core:crewai-crew-contract:1","text":"## CrewAI Multi-Agent Crew Contract\n\n### Crew Definition\n```yaml\ncrew:\n  name: [Crew Name]\n  process: sequential | hierarchical\n  verbose: true\n  memory: true\n```\n\n### Agent Roles\n```yaml\nagents:\n  researcher:\n    role: \"Senior Data Researcher\"\n    goal: \"Uncover cutting-edge developments in {topic}\"\n    backstory: \"You're a seasoned researcher known for finding relevant information\"\n    tools: [SerperDevTool, WebScraperTool]\n    \n  analyst:\n    role: \"Reporting Analyst\"\n    goal: \"Create detailed reports based on research findings\"\n    backstory: \"You're a meticulous analyst with keen eye for detail\"\n```\n\n### Task Definitions\n```yaml\ntasks:\n  research_task:\n    description: \"Conduct thorough research about {topic}\"\n    expected_output: \"10 bullet points of relevant information\"\n    agent: researcher\n    \n  reporting_task:\n    description: \"Expand research into full report\"\n    expected_output: \"Detailed markdown report\"\n    agent: analyst\n    output_file: report.md\n```","start_line":1,"end_line":38}]}
{"source_id":"core","type":"plan","title":"CrewAI Flows Implementation Plan","signals":["state_machine","agent_pattern"],"tags":["crewai","flows","orchestration","plan"],"summary":"Implementation plan for CrewAI Flows - event-driven workflows with precise control over agent execution.","chunks":[{"chunk_id":"core:crewai-flows-plan:1","text":"## CrewAI Flows Implementation Plan\n\n### Phase 1: Flow Architecture\n- [ ] Define Pydantic state model\n- [ ] Create Flow class extending Flow[State]\n- [ ] Implement @start() entry point\n- [ ] Add @listen() handlers for events\n\n### Phase 2: Crew Integration\n- [ ] Define agents with roles and tools\n- [ ] Create tasks with expected outputs\n- [ ] Configure crew process (sequential/hierarchical)\n- [ ] Connect crew.kickoff() in flow steps\n\n### Phase 3: Control Flow\n- [ ] Add @router() for conditional branching\n- [ ] Implement or_() / and_() combinators\n- [ ] Handle state transitions\n- [ ] Add error recovery handlers\n\n### Phase 4: Production\n- [ ] Enable memory persistence\n- [ ] Add observability/tracing\n- [ ] Configure retries and timeouts\n- [ ] Deploy with Crew Control Plane\n\n### Key Pattern: Crews in Flows\n```python\n@listen(fetch_data)\ndef analyze_with_crew(self, data):\n    crew = Crew(agents=[...], tasks=[...])\n    return crew.kickoff(inputs=data)\n```","start_line":1,"end_line":32}]}
{"source_id":"core","type":"contract","title":"LangGraph StateGraph Contract","signals":["contract_lock","agent_pattern"],"tags":["langgraph","state","graph","contract"],"summary":"Contract template for LangGraph StateGraph-based agent workflows with durable execution.","chunks":[{"chunk_id":"core:langgraph-contract:1","text":"## LangGraph StateGraph Contract\n\n### State Definition\n```python\nfrom typing_extensions import TypedDict\n\nclass AgentState(TypedDict):\n    messages: list[BaseMessage]\n    context: str\n    current_step: str\n    results: dict\n```\n\n### Graph Construction\n```python\nfrom langgraph.graph import START, StateGraph\n\ngraph = StateGraph(AgentState)\ngraph.add_node(\"retrieve\", retrieve_context)\ngraph.add_node(\"generate\", generate_response)\ngraph.add_node(\"validate\", validate_output)\n\ngraph.add_edge(START, \"retrieve\")\ngraph.add_edge(\"retrieve\", \"generate\")\ngraph.add_conditional_edges(\"generate\", should_retry)\n```\n\n### Core Benefits\n- **Durable Execution**: Persists through failures\n- **Human-in-the-Loop**: Interrupt and modify state\n- **Comprehensive Memory**: Short and long-term\n- **LangSmith Integration**: Full observability","start_line":1,"end_line":30}]}
{"source_id":"core","type":"plan","title":"LangGraph Agent Implementation Plan","signals":["state_machine","agent_pattern"],"tags":["langgraph","agent","implementation","plan"],"summary":"Implementation plan for building LangGraph-based agents with checkpointing and memory.","chunks":[{"chunk_id":"core:langgraph-agent-plan:1","text":"## LangGraph Agent Implementation Plan\n\n### Phase 1: State Design\n- [ ] Define TypedDict for agent state\n- [ ] Plan state transitions\n- [ ] Design checkpoint strategy\n- [ ] Choose memory implementation\n\n### Phase 2: Node Implementation\n- [ ] Create processing nodes (functions)\n- [ ] Implement tool nodes\n- [ ] Add conditional routing logic\n- [ ] Handle error states\n\n### Phase 3: Graph Assembly\n- [ ] Instantiate StateGraph\n- [ ] Add all nodes\n- [ ] Connect edges (static and conditional)\n- [ ] Compile graph with checkpointer\n\n### Phase 4: Integration\n- [ ] Add LangSmith tracing\n- [ ] Configure persistence (SQLite/Postgres)\n- [ ] Implement human-in-the-loop hooks\n- [ ] Deploy with LangSmith Deployment\n\n### Key Pattern: Conditional Edges\n```python\ndef route_decision(state):\n    if state[\"needs_review\"]:\n        return \"human_review\"\n    return \"complete\"\n\ngraph.add_conditional_edges(\"validate\", route_decision)\n```","start_line":1,"end_line":34}]}
{"source_id":"core","type":"contract","title":"Human-in-the-Loop AI Contract","signals":["contract_lock","agent_pattern"],"tags":["human-in-loop","ai","contract","oversight"],"summary":"Contract for AI systems with human oversight - when to pause, how to present decisions, and approval workflows.","chunks":[{"chunk_id":"core:human-in-loop-contract:1","text":"## Human-in-the-Loop AI Contract\n\n### Pause Triggers\n- High-stakes decisions (money, data deletion)\n- Low confidence predictions (< 80%)\n- Novel situations not in training\n- User explicitly requests review\n- Policy-sensitive content detected\n\n### Presentation Format\n```markdown\n## Decision Point: [Action Name]\n\n**Proposed Action**: [What AI wants to do]\n**Confidence**: [X%]\n**Reasoning**: [Why this action]\n**Alternatives**: [Other options considered]\n\n[ ] Approve  [ ] Modify  [ ] Reject\n```\n\n### Approval Workflow\n1. AI pauses execution\n2. Human receives notification\n3. Human reviews with full context\n4. Human approves/modifies/rejects\n5. AI resumes with decision\n\n### Timeout Handling\n- Default timeout: 24 hours\n- Escalation after timeout\n- Safe default action if critical","start_line":1,"end_line":30}]}
{"source_id":"core","type":"plan","title":"Durable Execution Pattern Plan","signals":["state_machine","agent_pattern"],"tags":["durable","execution","persistence","plan"],"summary":"Plan for implementing durable execution - agents that persist through failures and resume from checkpoints.","chunks":[{"chunk_id":"core:durable-execution-plan:1","text":"## Durable Execution Pattern Plan\n\n### Phase 1: Checkpointing\n- [ ] Define checkpoint state schema\n- [ ] Implement state serialization\n- [ ] Choose persistence backend (SQLite/Postgres)\n- [ ] Create checkpoint save/load logic\n\n### Phase 2: Recovery\n- [ ] Detect incomplete executions on startup\n- [ ] Resume from last checkpoint\n- [ ] Handle partial step completion\n- [ ] Implement idempotent operations\n\n### Phase 3: Long-Running Support\n- [ ] Handle multi-day executions\n- [ ] Manage external state changes\n- [ ] Support version migrations\n- [ ] Implement graceful interruption\n\n### Key Pattern: Checkpoint-Resume\n```python\ncheckpointer = SqliteSaver.from_conn_string(\":memory:\")\ngraph = builder.compile(checkpointer=checkpointer)\n\n# Resume from thread_id\nconfig = {\"configurable\": {\"thread_id\": \"session-123\"}}\nresult = graph.invoke(state, config)\n```","start_line":1,"end_line":28}]}
{"source_id":"core","type":"contract","title":"Agent Tracing & Observability Contract","signals":["contract_lock","evidence_audit"],"tags":["tracing","observability","langsmith","contract"],"summary":"Contract for AI agent observability covering tracing, metrics, and debugging visibility.","chunks":[{"chunk_id":"core:agent-observability-contract:1","text":"## Agent Tracing & Observability Contract\n\n### Required Traces\n- Every LLM call (input, output, latency)\n- Tool invocations (name, params, result)\n- State transitions (before, after)\n- Errors and retries\n\n### Trace Metadata\n- session_id: Unique execution session\n- user_id: Who initiated (if applicable)\n- cost: Token usage and estimated cost\n- duration_ms: Time for each step\n\n### Visualization Requirements\n- Execution flow diagram\n- State timeline view\n- Token usage breakdown\n- Error highlighting\n\n### Alerting Rules\n- Latency > 2x baseline\n- Error rate > 5%\n- Cost per request > threshold\n- Stuck execution (no progress 5min)\n\n### Tools Integration\n- LangSmith for LangGraph\n- CrewAI Control Plane for CrewAI\n- OpenTelemetry for custom","start_line":1,"end_line":30}]}
{"source_id":"core","type":"template","title":"Agent Role Prompt Template","signals":["context_engineering","agent_pattern"],"tags":["agent","role","prompt","template"],"summary":"Template for crafting effective agent role prompts with backstory, goals, and behavioral constraints.","chunks":[{"chunk_id":"core:agent-role-template:1","text":"## Agent Role Prompt Template\n\n### Structure\n```markdown\n# Role: {Role Title}\n\n## Identity\nYou are a {role_description}. Your expertise lies in {domain_expertise}.\n\n## Backstory\n{backstory_providing_context_and_motivation}\n\n## Goal\n{specific_measurable_goal}\n\n## Constraints\n- {constraint_1}\n- {constraint_2}\n- {constraint_3}\n\n## Output Format\n{expected_output_format}\n\n## Examples\n{few_shot_examples_if_needed}\n```\n\n### Best Practices\n- Be specific about expertise domain\n- Backstory adds personality and motivation\n- Goals should be measurable\n- Constraints prevent unwanted behaviors\n- Include output format expectations","start_line":1,"end_line":32}]}
{"source_id":"core","type":"plan","title":"Agent Tool Integration Plan","signals":["state_machine","agent_pattern"],"tags":["tools","integration","agent","plan"],"summary":"Plan for integrating external tools into AI agents - discovery, invocation, and error handling.","chunks":[{"chunk_id":"core:agent-tool-plan:1","text":"## Agent Tool Integration Plan\n\n### Phase 1: Tool Definition\n- [ ] Define tool interface (name, description, params)\n- [ ] Create JSON schema for parameters\n- [ ] Implement tool execution logic\n- [ ] Add input validation\n\n### Phase 2: Discovery\n- [ ] Register tools with agent\n- [ ] Generate tool descriptions for LLM\n- [ ] Handle dynamic tool loading\n- [ ] Support tool versioning\n\n### Phase 3: Invocation\n- [ ] Parse LLM tool calls\n- [ ] Validate parameters\n- [ ] Execute with timeout\n- [ ] Handle async tools\n\n### Phase 4: Error Handling\n- [ ] Catch tool exceptions\n- [ ] Format error for LLM\n- [ ] Implement retries\n- [ ] Log tool failures\n\n### Tool Schema Example\n```json\n{\n  \"name\": \"search_web\",\n  \"description\": \"Search the web for information\",\n  \"parameters\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"query\": {\"type\": \"string\"}\n    },\n    \"required\": [\"query\"]\n  }\n}\n```","start_line":1,"end_line":40}]}
{"source_id":"core","type":"contract","title":"Sequential vs Hierarchical Process Contract","signals":["contract_lock","agent_pattern"],"tags":["process","sequential","hierarchical","contract"],"summary":"Contract defining when to use sequential vs hierarchical multi-agent processes.","chunks":[{"chunk_id":"core:process-contract:1","text":"## Sequential vs Hierarchical Process Contract\n\n### Sequential Process\n**When to Use:**\n- Tasks have clear dependencies\n- Output of one feeds into next\n- Simple, linear workflows\n- Fewer than 5 agents\n\n**Pattern:**\n```\nAgent A → Agent B → Agent C → Output\n```\n\n### Hierarchical Process\n**When to Use:**\n- Complex tasks needing coordination\n- Dynamic task assignment\n- Parallel work possible\n- Many specialized agents\n\n**Pattern:**\n```\n        Manager\n       /   |   \\\nAgent A  Agent B  Agent C\n       \\   |   /\n        Output\n```\n\n### Selection Criteria\n| Factor | Sequential | Hierarchical |\n|--------|------------|-------------|\n| Complexity | Low | High |\n| Parallelism | No | Yes |\n| Coordination | Minimal | Required |\n| Agents | 2-4 | 5+ |","start_line":1,"end_line":34}]}
{"source_id":"core","type":"iterate","title":"Agent Prompt Iteration Playbook","signals":["iterate_loop","agent_pattern"],"tags":["prompt","iteration","agent","playbook"],"summary":"Playbook for iteratively improving agent prompts based on performance feedback.","chunks":[{"chunk_id":"core:prompt-iteration-playbook:1","text":"## Agent Prompt Iteration Playbook\n\n### Iteration Cycle\n1. **Observe**: Run agent on test cases\n2. **Analyze**: Identify failure patterns\n3. **Hypothesize**: Guess root cause\n4. **Modify**: Update prompt/tools\n5. **Validate**: Test on same cases\n6. **Regress**: Ensure no new failures\n\n### Common Issues & Fixes\n\n**Issue: Agent ignores instructions**\n→ Move critical instructions to end\n→ Use explicit \"IMPORTANT:\" markers\n→ Reduce overall prompt length\n\n**Issue: Wrong tool selection**\n→ Improve tool descriptions\n→ Add examples to prompt\n→ Reduce tool count\n\n**Issue: Hallucinated actions**\n→ Add verification steps\n→ Include \"if unsure\" instructions\n→ Require source citations\n\n### Metrics to Track\n- Task completion rate\n- Tool accuracy\n- Response quality score\n- Cost per successful task","start_line":1,"end_line":32}]}
{"source_id":"core","type":"contract","title":"Agent Memory Architecture Contract","signals":["contract_lock","agent_pattern"],"tags":["memory","architecture","agent","contract"],"summary":"Contract for agent memory systems - working memory, conversation history, and persistent knowledge.","chunks":[{"chunk_id":"core:agent-memory-arch:1","text":"## Agent Memory Architecture Contract\n\n### Memory Layers\n\n**Layer 1: Working Memory (In-Context)**\n- Current task context\n- Recent tool outputs\n- Immediate scratchpad\n- Token limit: ~50% of context\n\n**Layer 2: Conversation History**\n- Recent messages (sliding window)\n- Summarized older messages\n- User preferences learned\n- Persistence: Session-based\n\n**Layer 3: Long-Term Memory**\n- Semantic search over facts\n- User profile information\n- Learned patterns/solutions\n- Persistence: Vector database\n\n### Memory Operations\n```python\nmemory.remember(key, value, metadata)\nmemory.recall(query, top_k=5)\nmemory.forget(key)  # Explicit deletion\nmemory.summarize(conversation)  # Compress\n```\n\n### Quality Attributes\n- Retrieval latency: < 100ms\n- Relevance: Top-3 contains answer 90%+\n- Freshness: Recent over stale","start_line":1,"end_line":32}]}
{"source_id":"core","type":"template","title":"AGENTS.md Template","signals":["context_engineering"],"tags":["agents","codex","openai","template"],"summary":"Template for AGENTS.md files used by OpenAI Codex and similar autonomous coding agents.","chunks":[{"chunk_id":"core:agents-md-template:1","text":"## AGENTS.md Template\n\n### File: AGENTS.md\n```markdown\n# Agent Instructions\n\n## Repository Overview\nBrief description of what this codebase does.\n\n## Development Setup\n```bash\n# Installation\nnpm install  # or cargo build, pip install, etc.\n\n# Running tests\nnpm test\n\n# Building\nnpm run build\n```\n\n## Code Structure\n- `src/` - Main source code\n- `tests/` - Test files\n- `docs/` - Documentation\n\n## Coding Conventions\n- Use TypeScript strict mode\n- Follow existing patterns\n- Write tests for new code\n\n## Pull Request Guidelines\n- Clear title and description\n- Tests pass\n- No linting errors\n```\n\n### Purpose\n- Used by autonomous coding agents\n- Provides context for code generation\n- Defines acceptable changes","start_line":1,"end_line":40}]}
{"source_id":"core","type":"contract","title":"Event-Driven Agent Contract","signals":["contract_lock","agent_pattern"],"tags":["event-driven","reactive","agent","contract"],"summary":"Contract for event-driven agents that respond to triggers rather than running continuously.","chunks":[{"chunk_id":"core:event-driven-agent:1","text":"## Event-Driven Agent Contract\n\n### Trigger Events\n- **Webhook**: External service notification\n- **Schedule**: Cron-based execution\n- **File Change**: Watch for modifications\n- **Queue Message**: Async job processing\n- **User Action**: Direct invocation\n\n### Event Schema\n```json\n{\n  \"event_type\": \"file_changed\",\n  \"timestamp\": \"2025-01-21T10:00:00Z\",\n  \"source\": \"github\",\n  \"payload\": {\n    \"path\": \"src/main.rs\",\n    \"action\": \"modified\"\n  }\n}\n```\n\n### Processing Pattern\n1. Receive event\n2. Validate event schema\n3. Route to appropriate handler\n4. Execute agent logic\n5. Emit result event\n6. Acknowledge completion\n\n### Idempotency\n- Events may be delivered multiple times\n- Use event_id for deduplication\n- Make handlers idempotent","start_line":1,"end_line":32}]}
{"source_id":"core","type":"plan","title":"Agent Deployment Plan","signals":["release_install","agent_pattern"],"tags":["deployment","agent","production","plan"],"summary":"Plan for deploying AI agents to production with scaling, monitoring, and rollback strategies.","chunks":[{"chunk_id":"core:agent-deployment-plan:1","text":"## Agent Deployment Plan\n\n### Phase 1: Preparation\n- [ ] Lock agent configuration\n- [ ] Freeze prompt versions\n- [ ] Pin model versions\n- [ ] Document expected behavior\n\n### Phase 2: Staging\n- [ ] Deploy to staging environment\n- [ ] Run evaluation suite\n- [ ] Compare against baseline\n- [ ] Load test with synthetic traffic\n\n### Phase 3: Canary Release\n- [ ] Route 5% traffic to new version\n- [ ] Monitor key metrics\n- [ ] Compare with production baseline\n- [ ] Gradual increase if healthy\n\n### Phase 4: Full Deployment\n- [ ] Route 100% traffic\n- [ ] Monitor for 24 hours\n- [ ] Keep rollback ready\n- [ ] Update documentation\n\n### Rollback Triggers\n- Error rate > 2x baseline\n- Latency > 2x baseline\n- Cost per request > budget\n- User complaints spike","start_line":1,"end_line":32}]}
{"source_id":"core","type":"evidence","title":"Agent Evaluation Metrics","signals":["evidence_audit","agent_pattern"],"tags":["evaluation","metrics","agent","evidence"],"summary":"Metrics for evaluating AI agent performance covering accuracy, efficiency, and safety.","chunks":[{"chunk_id":"core:agent-eval-metrics:1","text":"## Agent Evaluation Metrics\n\n### Accuracy Metrics\n- **Task Completion Rate**: % tasks fully completed\n- **Correctness**: % outputs verified correct\n- **Tool Accuracy**: % correct tool selections\n- **Hallucination Rate**: % responses with false info\n\n### Efficiency Metrics\n- **Steps per Task**: Average actions to complete\n- **Token Usage**: Tokens per successful task\n- **Latency**: Time from start to completion\n- **Cost**: $ per task completion\n\n### Safety Metrics\n- **Refusal Rate**: % correctly refused unsafe requests\n- **Leak Rate**: % outputs with sensitive data\n- **Harm Rate**: % outputs with harmful content\n- **Error Recovery**: % errors handled gracefully\n\n### Quality Metrics\n- **User Satisfaction**: Survey scores\n- **Clarity**: Readability of outputs\n- **Helpfulness**: Did it solve the problem?\n- **Consistency**: Same input → same output","start_line":1,"end_line":26}]}
{"source_id":"core","type":"contract","title":"Agent Cost Control Contract","signals":["contract_lock","agent_pattern"],"tags":["cost","budget","agent","contract"],"summary":"Contract for controlling AI agent costs including token budgets, rate limits, and spending caps.","chunks":[{"chunk_id":"core:agent-cost-contract:1","text":"## Agent Cost Control Contract\n\n### Budget Tiers\n| Tier | Per Request | Per Hour | Per Day |\n|------|-------------|----------|--------|\n| Free | $0.01 | $0.10 | $1.00 |\n| Pro | $0.10 | $1.00 | $10.00 |\n| Enterprise | $1.00 | $10.00 | $100.00 |\n\n### Token Budgets\n- Input tokens: 10,000 max per request\n- Output tokens: 4,000 max per request\n- Context window: 80% max utilization\n\n### Cost Optimization Strategies\n- Cache common queries\n- Use cheaper models for simple tasks\n- Compress context before sending\n- Batch similar requests\n\n### Enforcement\n- Pre-request cost estimation\n- Reject if over budget\n- Alert at 80% of budget\n- Daily cost reports\n\n### Overage Handling\n- Graceful degradation\n- Queue non-urgent requests\n- Notify user of limits","start_line":1,"end_line":30}]}
{"source_id":"core","type":"iterate","title":"Agent Debugging Checklist","signals":["iterate_loop","agent_pattern"],"tags":["debugging","checklist","agent"],"summary":"Checklist for debugging AI agent issues covering prompts, tools, and execution flow.","chunks":[{"chunk_id":"core:agent-debug-checklist:1","text":"## Agent Debugging Checklist\n\n### Prompt Issues\n- [ ] Is the system prompt too long?\n- [ ] Are instructions clear and specific?\n- [ ] Are there conflicting instructions?\n- [ ] Is the output format specified?\n\n### Tool Issues\n- [ ] Are tool descriptions accurate?\n- [ ] Do parameter schemas match implementation?\n- [ ] Are required params marked correctly?\n- [ ] Is the tool returning expected format?\n\n### State Issues\n- [ ] Is state being persisted correctly?\n- [ ] Are checkpoints being saved?\n- [ ] Is memory retrieval working?\n- [ ] Are there stale state issues?\n\n### Execution Issues\n- [ ] Is the model receiving full context?\n- [ ] Are API calls succeeding?\n- [ ] Is there a timeout occurring?\n- [ ] Are retries happening correctly?\n\n### Quick Fixes\n- Add \"IMPORTANT:\" before critical instructions\n- Reduce tool count to essentials\n- Split complex tasks into subtasks\n- Add explicit examples to prompt","start_line":1,"end_line":32}]}
{"source_id":"core","type":"contract","title":"Terminal AI Agent Contract","signals":["contract_lock","terminal_agent"],"tags":["aider","terminal","agent","contract"],"summary":"Contract for terminal-based AI coding agents like Aider - repo mapping, auto-commit, watch mode.","chunks":[{"chunk_id":"core:terminal-ai-agent:1","text":"## Terminal AI Agent Contract\n\n### Core Capabilities\n\n**Repo Mapping**\n- Generate repository structure map\n- Identify relevant files for context\n- Support 100+ programming languages\n- Use tree-sitter for code parsing\n\n**Auto-Commit**\n- Automatically commit changes after edits\n- Generate meaningful commit messages\n- Integrate with existing git workflow\n- Support undo via git reset\n\n**Watch Mode**\n- Monitor files for changes\n- Parse comments for AI instructions\n- Apply edits on file save\n- IDE-agnostic operation\n\n**Voice Input**\n- Transcribe voice to text commands\n- Request features by speaking\n- Hands-free coding support\n\n### Quality Attributes\n- Latency: < 5s for simple edits\n- Accuracy: Syntactically correct 95%+\n- Undo: All changes reversible\n- Integration: Works with any IDE","start_line":1,"end_line":32}]}
{"source_id":"core","type":"template","title":"RepoMap Generation Template","signals":["context_engineering","terminal_agent"],"tags":["repomap","context","template"],"summary":"Template for generating repository maps to help AI understand codebase structure.","chunks":[{"chunk_id":"core:repomap-template:1","text":"## RepoMap Generation Template\n\n### Structure\n```\n# Repository Structure\n\n## Entry Points\n- main.rs - Application entry point\n- lib.rs - Library exports\n\n## Core Modules\n/src/\n  cli/     - Command line interface\n  brain/   - Knowledge management\n  state/   - State persistence\n\n## Key Files\n- Cargo.toml - Dependencies and metadata\n- README.md - Project documentation\n\n## Dependencies (Key)\n- tokio - Async runtime\n- serde - Serialization\n- clap - CLI parsing\n```\n\n### Generation Rules\n1. Include directory tree (depth 2-3)\n2. Annotate purpose of each directory\n3. Highlight entry points\n4. Note key dependencies\n5. Exclude build/vendor dirs\n6. Size-sort by importance\n\n### Context Selection\n- Include files matching task domain\n- Prioritize recently modified\n- Respect token budget\n- Allow manual file addition","start_line":1,"end_line":38}]}
{"source_id":"core","type":"contract","title":"Auto-Commit Integration Contract","signals":["contract_lock","git_integration"],"tags":["git","auto-commit","contract"],"summary":"Contract for AI agents that automatically commit changes to version control.","chunks":[{"chunk_id":"core:auto-commit-contract:1","text":"## Auto-Commit Integration Contract\n\n### Commit Workflow\n1. Agent makes code changes\n2. Stage modified files\n3. Generate commit message from changes\n4. Create commit with attribution\n5. Allow review before push\n\n### Commit Message Format\n```\n<type>(<scope>): <description>\n\n<body explaining what changed>\n\n🤖 Generated by AI Agent\nModel: claude-3.5-sonnet\nPrompt: \"<user request summary>\"\n```\n\n### Types\n- feat: New feature\n- fix: Bug fix\n- refactor: Code restructure\n- docs: Documentation\n- test: Add/modify tests\n\n### Safety Rules\n- Never auto-push to remote\n- Never commit sensitive data\n- Always allow undo (git reset)\n- Preserve user's branch state\n- Atomic commits (one change = one commit)","start_line":1,"end_line":32}]}
{"source_id":"core","type":"plan","title":"Watch Mode Implementation Plan","signals":["release_install","terminal_agent"],"tags":["watch","file-monitor","plan"],"summary":"Plan for implementing watch mode in terminal AI agents - file monitoring and comment-based instructions.","chunks":[{"chunk_id":"core:watch-mode-plan:1","text":"## Watch Mode Implementation Plan\n\n### Phase 1: File Monitoring\n- [ ] Set up file watcher (notify, fswatch)\n- [ ] Filter for relevant file types\n- [ ] Debounce rapid changes\n- [ ] Handle file creation/deletion\n\n### Phase 2: Comment Parsing\n- [ ] Detect AI instruction comments\n  - `// AI: <instruction>`\n  - `# TODO(AI): <instruction>`\n  - `/* @ai <instruction> */`\n- [ ] Extract instruction context\n- [ ] Parse multi-line instructions\n\n### Phase 3: Instruction Execution\n- [ ] Queue instructions\n- [ ] Process in order\n- [ ] Apply edits to files\n- [ ] Remove instruction comments\n- [ ] Show diff before applying\n\n### Phase 4: Integration\n- [ ] IDE extension hooks\n- [ ] Terminal output formatting\n- [ ] Status indicators\n- [ ] Error recovery","start_line":1,"end_line":30}]}
{"source_id":"core","type":"contract","title":"Lint and Test Integration Contract","signals":["contract_lock","quality_assurance"],"tags":["linting","testing","integration","contract"],"summary":"Contract for AI agents that run linters and tests automatically after making changes.","chunks":[{"chunk_id":"core:lint-test-contract:1","text":"## Lint and Test Integration Contract\n\n### Workflow\n1. Agent makes code changes\n2. Run configured linters\n3. If lint errors: attempt auto-fix\n4. Run relevant tests\n5. If test failures: show error, offer fix\n6. Only commit if all pass\n\n### Linter Integration\n```yaml\nlinters:\n  - command: \"cargo clippy\"\n    fix: \"cargo clippy --fix\"\n  - command: \"eslint .\"\n    fix: \"eslint --fix .\"\n  - command: \"ruff check .\"\n    fix: \"ruff check --fix .\"\n```\n\n### Test Selection\n- Run tests in changed files\n- Run tests importing changed modules\n- Run full suite on critical paths\n- Support test filtering by name\n\n### Failure Handling\n- Parse error messages\n- Show relevant code context\n- Offer AI-powered fix\n- Allow manual intervention\n- Track fix success rate","start_line":1,"end_line":32}]}
{"source_id":"core","type":"contract","title":"Continuous AI Agent Contract","signals":["contract_lock","continuous_ai"],"tags":["continue","cloud-agent","headless","contract"],"summary":"Contract for continuous AI agents - cloud agents, CLI agents, IDE agents with headless and TUI modes.","chunks":[{"chunk_id":"core:continuous-ai-contract:1","text":"## Continuous AI Agent Contract\n\n### Agent Modes\n\n**Cloud Agents (Headless)**\n- Run on PR opens, schedules, or triggers\n- Async background processing\n- No human-in-the-loop\n- Event-driven execution\n\n**CLI Agents (TUI)**\n- Interactive terminal UI\n- Step-by-step approval\n- Real-time execution view\n- Human-in-the-loop\n\n**IDE Agents**\n- Trigger from VS Code/JetBrains\n- Background refactoring\n- Keep coding while agent works\n- Inline result display\n\n### Workflow Triggers\n- PR opened/updated\n- Cron schedule\n- Manual invocation\n- File change events\n- Webhook calls\n\n### Quality Attributes\n- Observability: Full execution logs\n- Reproducibility: Same input → same output\n- Safety: Human approval for critical actions","start_line":1,"end_line":32}]}
{"source_id":"core","type":"template","title":"Cloud Agent Workflow Template","signals":["context_engineering","continuous_ai"],"tags":["workflow","cloud","automation","template"],"summary":"Template for defining cloud agent workflows triggered by events like PR opens or schedules.","chunks":[{"chunk_id":"core:cloud-agent-workflow:1","text":"## Cloud Agent Workflow Template\n\n### Workflow Definition\n```yaml\nname: pr-review-agent\ntrigger:\n  event: pull_request\n  actions: [opened, synchronize]\n\nsteps:\n  - name: analyze-changes\n    agent: code-reviewer\n    input: ${{ github.event.pull_request }}\n    \n  - name: check-security\n    agent: security-scanner\n    input: ${{ steps.analyze-changes.output }}\n    \n  - name: post-review\n    agent: reviewer\n    action: comment\n    input: ${{ steps.check-security.output }}\n```\n\n### Event Types\n- `pull_request`: PR lifecycle events\n- `schedule`: Cron-based triggers\n- `webhook`: Custom HTTP triggers\n- `file_change`: Repo file modifications\n\n### Approval Gates\n```yaml\nsteps:\n  - name: deploy\n    requires_approval: true\n    approvers: [\"@devops-team\"]\n```","start_line":1,"end_line":36}]}
{"source_id":"core","type":"plan","title":"TUI Agent Implementation Plan","signals":["release_install","continuous_ai"],"tags":["tui","terminal-ui","plan"],"summary":"Plan for implementing terminal UI for AI agents with step-by-step approval and real-time updates.","chunks":[{"chunk_id":"core:tui-agent-plan:1","text":"## TUI Agent Implementation Plan\n\n### Phase 1: Core TUI\n- [ ] Choose TUI framework (Bubble Tea, ratatui)\n- [ ] Design layout (panels, status bar)\n- [ ] Implement keyboard navigation\n- [ ] Add color/styling support\n\n### Phase 2: Execution View\n- [ ] Show agent thinking process\n- [ ] Display tool calls in real-time\n- [ ] Progress indicators\n- [ ] Expandable/collapsible sections\n\n### Phase 3: Approval Flow\n- [ ] Pause before critical actions\n- [ ] Show diff preview\n- [ ] Accept/Reject/Edit controls\n- [ ] Undo support\n\n### Phase 4: Session Management\n- [ ] Save/restore sessions\n- [ ] Session history view\n- [ ] Export conversations\n- [ ] Multi-agent tabs\n\n### Key Components\n- Input panel: User prompts\n- Output panel: Agent responses\n- Status bar: Model, tokens, cost\n- Action panel: Tool executions","start_line":1,"end_line":32}]}
{"source_id":"core","type":"contract","title":"Headless Agent Execution Contract","signals":["contract_lock","continuous_ai"],"tags":["headless","automation","contract"],"summary":"Contract for headless agent execution - no human interaction, fully automated workflows.","chunks":[{"chunk_id":"core:headless-agent-contract:1","text":"## Headless Agent Execution Contract\n\n### Characteristics\n- No user input during execution\n- All parameters pre-configured\n- Results stored for later review\n- Runs in CI/CD or cloud\n\n### Configuration\n```yaml\nagent:\n  name: code-formatter\n  mode: headless\n  timeout: 300  # seconds\n  max_iterations: 50\n  \ninputs:\n  files: ${{ github.files }}\n  rules: .prettierrc\n  \noutputs:\n  - type: commit\n    branch: auto/format-${{ run_id }}\n  - type: pr\n    title: \"Auto-format code\"\n```\n\n### Safety Constraints\n- Budget limits (tokens, cost)\n- Iteration limits\n- Scope restrictions (files, actions)\n- Timeout enforcement\n\n### Observability\n- Execution logs stored\n- Token usage tracked\n- Cost reported\n- Errors captured with context","start_line":1,"end_line":36}]}
{"source_id":"core","type":"contract","title":"Local LLM Integration Contract","signals":["contract_lock","local_ai"],"tags":["ollama","llama.cpp","local","contract"],"summary":"Contract for integrating local LLMs via Ollama, llama.cpp, or similar local inference engines.","chunks":[{"chunk_id":"core:local-llm-contract:1","text":"## Local LLM Integration Contract\n\n### Supported Backends\n- **Ollama**: REST API, model library\n- **llama.cpp**: High-perf C++ inference\n- **vLLM**: Python inference server\n- **LM Studio**: Desktop GUI + API\n\n### Endpoint Configuration\n```yaml\nlocal_provider:\n  type: ollama\n  base_url: $LOCAL_ENDPOINT  # e.g., localhost:11434\n  model: llama3.2:latest\n  context_window: 8192\n  \n# Or llama.cpp server\nlocal_provider:\n  type: llama_cpp\n  base_url: $LOCAL_ENDPOINT  # e.g., localhost:8080\n  api_format: openai_compatible\n```\n\n### Quality Attributes\n- Latency: < 50ms first token\n- Privacy: Data never leaves machine\n- Cost: $0 per token (compute only)\n- Offline: Works without internet\n\n### Model Formats\n- GGUF: Quantized models\n- SafeTensors: Safe format\n- ONNX: Cross-platform","start_line":1,"end_line":34}]}
{"source_id":"core","type":"template","title":"Ollama Integration Template","signals":["context_engineering","local_ai"],"tags":["ollama","api","template"],"summary":"Template for integrating Ollama local models with REST API patterns.","chunks":[{"chunk_id":"core:ollama-template:1","text":"## Ollama Integration Template\n\n### REST API Endpoints\n```bash\n# Generate completion\ncurl $OLLAMA_HOST/api/generate \\\n  -d '{\"model\": \"llama3.2\", \"prompt\": \"Hello\"}'\n\n# Chat completion (OpenAI compatible)\ncurl $OLLAMA_HOST/v1/chat/completions \\\n  -d '{\"model\": \"llama3.2\", \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]}'\n\n# List models\ncurl $OLLAMA_HOST/api/tags\n\n# Pull model\ncurl $OLLAMA_HOST/api/pull \\\n  -d '{\"name\": \"llama3.2\"}'\n```\n\n### Modelfile Customization\n```dockerfile\nFROM llama3.2\n\nPARAMETER temperature 0.7\nPARAMETER num_ctx 8192\n\nSYSTEM \"You are a helpful coding assistant.\"\n```\n\n### Features\n- Streaming responses\n- Model library (100+ models)\n- Custom system prompts\n- Parameter tuning\n- GGUF import","start_line":1,"end_line":36}]}
{"source_id":"core","type":"template","title":"llama.cpp Server Template","signals":["context_engineering","local_ai"],"tags":["llama.cpp","server","template"],"summary":"Template for running llama.cpp as an OpenAI-compatible server for local inference.","chunks":[{"chunk_id":"core:llama-cpp-server:1","text":"## llama.cpp Server Template\n\n### Start Server\n```bash\n# Basic server\n./llama-server -m model.gguf --port 8080\n\n# With GPU acceleration\n./llama-server -m model.gguf -ngl 35 --port 8080\n\n# Multi-model from HuggingFace\n./llama-server \\\n  --model-url $HF_MODEL_URL \\\n  --alias my-model \\\n  --port 8080\n```\n\n### OpenAI-Compatible Endpoints\n```bash\n# Chat completions\ncurl $LLAMA_SERVER/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"model\": \"my-model\", \"messages\": [...]}'\n\n# Embeddings\ncurl $LLAMA_SERVER/v1/embeddings \\\n  -d '{\"model\": \"my-model\", \"input\": \"text\"}'\n```\n\n### Backend Options\n- Metal: Apple Silicon GPU\n- CUDA: NVIDIA GPU\n- Vulkan: Cross-platform GPU\n- CPU: AVX/AVX2 optimized\n\n### Quantization Levels\n- Q4_K_M: Good balance\n- Q5_K_M: Better quality\n- Q8_0: Near-original","start_line":1,"end_line":40}]}
{"source_id":"core","type":"plan","title":"GGUF Model Integration Plan","signals":["release_install","local_ai"],"tags":["gguf","quantization","plan"],"summary":"Plan for integrating GGUF quantized models into AI applications.","chunks":[{"chunk_id":"core:gguf-model-plan:1","text":"## GGUF Model Integration Plan\n\n### Phase 1: Model Selection\n- [ ] Choose base model (Llama, Mistral, Qwen)\n- [ ] Select quantization level (Q4, Q5, Q8)\n- [ ] Verify VRAM requirements\n- [ ] Test inference speed\n\n### Phase 2: Download & Setup\n- [ ] Download from HuggingFace\n- [ ] Verify file integrity\n- [ ] Configure model path\n- [ ] Set up context window size\n\n### Phase 3: Integration\n- [ ] Add to model config\n- [ ] Test via API endpoint\n- [ ] Benchmark throughput\n- [ ] Compare with cloud models\n\n### Quantization Tradeoffs\n| Quant | Size | Quality | Speed |\n|-------|------|---------|-------|\n| Q4_K_M | 4GB | Good | Fast |\n| Q5_K_M | 5GB | Better | Medium |\n| Q8_0 | 8GB | Best | Slow |\n\n### Hardware Requirements\n- Q4: 8GB RAM minimum\n- Q5: 12GB RAM minimum\n- Q8: 16GB RAM minimum\n- GPU: 6GB+ VRAM for offload","start_line":1,"end_line":34}]}
{"source_id":"core","type":"contract","title":"Context Auto-Compact Contract","signals":["contract_lock","context_management"],"tags":["auto-compact","summarization","contract"],"summary":"Contract for automatically compacting/summarizing context when approaching token limits.","chunks":[{"chunk_id":"core:auto-compact-contract:1","text":"## Context Auto-Compact Contract\n\n### Trigger Conditions\n- Context reaches 95% of token limit\n- User requests summarization\n- Session exceeds threshold\n\n### Compaction Process\n1. Identify conversation segments\n2. Score by relevance to current task\n3. Summarize low-priority segments\n4. Preserve critical context\n5. Replace full text with summary\n\n### Preservation Rules\n**Always Keep:**\n- System prompt\n- Last N user messages (configurable)\n- Active file contents\n- Pending tool results\n\n**Can Summarize:**\n- Older conversation turns\n- Completed tool outputs\n- Resolved discussions\n\n### Summary Format\n```\n[COMPACT] Previous context (turns 1-15):\n- User requested feature X\n- Modified files: a.rs, b.rs\n- Key decisions: used pattern Y\n```\n\n### Quality Attributes\n- Preserve intent, not verbatim text\n- Keep actionable information\n- Maintain continuity","start_line":1,"end_line":36}]}
{"source_id":"core","type":"contract","title":"Multi-Provider Configuration Contract","signals":["contract_lock","provider_abstraction"],"tags":["multi-provider","config","contract"],"summary":"Contract for configuring multiple LLM providers with fallback and routing logic.","chunks":[{"chunk_id":"core:multi-provider-contract:1","text":"## Multi-Provider Configuration Contract\n\n### Provider Configuration\n```yaml\nproviders:\n  anthropic:\n    api_key: $ANTHROPIC_API_KEY\n    models: [claude-3-sonnet, claude-3-opus]\n    \n  openai:\n    api_key: $OPENAI_API_KEY\n    models: [gpt-4o, gpt-4-turbo]\n    \n  local:\n    type: ollama\n    base_url: $LOCAL_ENDPOINT\n    models: [llama3.2, codellama]\n```\n\n### Routing Rules\n- Default: anthropic/claude-3-sonnet\n- Fallback: openai/gpt-4o\n- Simple tasks: local/llama3.2\n- Cost threshold: switch to cheaper\n\n### Provider Selection Logic\n1. Check rate limits\n2. Estimate cost\n3. Select by routing rules\n4. Attempt request\n5. On failure: try fallback\n\n### Quality Attributes\n- Seamless failover\n- Cost optimization\n- Latency awareness\n- Provider-agnostic interface","start_line":1,"end_line":36}]}
{"source_id":"core","type":"template","title":"MCP Server Integration Template","signals":["context_engineering","mcp"],"tags":["mcp","server","integration","template"],"summary":"Template for integrating MCP (Model Context Protocol) servers for extended agent capabilities.","chunks":[{"chunk_id":"core:mcp-server-template:1","text":"## MCP Server Integration Template\n\n### Server Configuration\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\"],\n      \"env\": {\"ALLOWED_PATHS\": \"/workspace\"}\n    },\n    \"github\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-github\"],\n      \"env\": {\"GITHUB_TOKEN\": \"$GH_TOKEN\"}\n    },\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-memory\"]\n    }\n  }\n}\n```\n\n### Capabilities\n- **Resources**: Read context from external sources\n- **Tools**: Execute actions via MCP tools\n- **Prompts**: Pre-defined prompt templates\n- **Sampling**: Request LLM completions\n\n### Tool Discovery\n1. Connect to MCP server\n2. List available tools\n3. Generate tool schemas for LLM\n4. Route tool calls through MCP\n5. Return results to agent","start_line":1,"end_line":38}]}
{"source_id":"core","type":"contract","title":"LSP Integration Contract","signals":["contract_lock","code_intelligence"],"tags":["lsp","language-server","contract"],"summary":"Contract for integrating Language Server Protocol for code intelligence in AI coding agents.","chunks":[{"chunk_id":"core:lsp-integration-contract:1","text":"## LSP Integration Contract\n\n### Capabilities\n- **Completions**: Code suggestions\n- **Diagnostics**: Errors and warnings\n- **Hover**: Type information\n- **Go to Definition**: Symbol navigation\n- **Find References**: Usage search\n- **Rename**: Refactoring support\n\n### Integration Flow\n1. Start language server for project\n2. Register file watchers\n3. Sync document state\n4. Query on demand\n5. Include in AI context\n\n### Context Enhancement\n```\n## LSP Context\nDiagnostics for src/main.rs:\n- Line 42: unused variable `x`\n- Line 58: type mismatch\n\nSymbol at cursor:\n- Name: process_data\n- Type: fn(Vec<u8>) -> Result<Data>\n- References: 5 locations\n```\n\n### Quality Attributes\n- Real-time diagnostics\n- Accurate type info\n- Language-agnostic\n- IDE-independent","start_line":1,"end_line":34}]}
{"source_id":"core","type":"plan","title":"Session Management Plan","signals":["release_install","session"],"tags":["session","persistence","plan"],"summary":"Plan for implementing session management - save, restore, and resume AI agent conversations.","chunks":[{"chunk_id":"core:session-mgmt-plan:1","text":"## Session Management Plan\n\n### Phase 1: Session Storage\n- [ ] Define session schema\n- [ ] Implement save on exit\n- [ ] Implement resume on start\n- [ ] Add session listing\n\n### Phase 2: Session Data\n```json\n{\n  \"session_id\": \"abc123\",\n  \"created\": \"2025-01-21T10:00:00Z\",\n  \"model\": \"claude-3-sonnet\",\n  \"messages\": [...],\n  \"files_in_context\": [\"src/main.rs\"],\n  \"tool_states\": {},\n  \"checkpoints\": [...]\n}\n```\n\n### Phase 3: Session Operations\n- [ ] Fork session (branch)\n- [ ] Merge sessions\n- [ ] Export to markdown\n- [ ] Share session link\n\n### Phase 4: Auto-Save\n- [ ] Save every N messages\n- [ ] Save on tool execution\n- [ ] Save before compact\n- [ ] Crash recovery","start_line":1,"end_line":32}]}
{"source_id":"core","type":"contract","title":"IDE Plugin Architecture Contract","signals":["contract_lock","ide_extension"],"tags":["plugin","extension","ide","contract"],"summary":"Contract for AI coding assistant plugins/extensions for VS Code, JetBrains, and other IDEs.","chunks":[{"chunk_id":"core:ide-plugin-contract:1","text":"## IDE Plugin Architecture Contract\n\n### Plugin Structure\n```\n.claude/\n  commands/\n    fix-bug.md    # Custom slash commands\n    review.md\n  plugins/\n    linter/       # Plugin directory\n      manifest.json\n      index.js\n  settings.json   # Local config\n```\n\n### Extension Points\n- **Commands**: Custom slash commands\n- **Context Providers**: Add context sources\n- **Actions**: Pre/post edit hooks\n- **Formatters**: Output formatting\n\n### Command Definition\n```markdown\n---\nname: fix-bug\ndescription: Fix a bug in the code\nargs:\n  - name: issue\n    description: Bug description\n---\n\nFix the following bug: $issue\nFirst understand the root cause, then implement fix.\n```\n\n### Quality Attributes\n- Isolated execution\n- Version compatibility\n- Hot reload support","start_line":1,"end_line":38}]}
{"source_id":"core","type":"template","title":"Custom Slash Command Template","signals":["context_engineering","ide_extension"],"tags":["slash-command","custom","template"],"summary":"Template for creating custom slash commands in AI coding assistants.","chunks":[{"chunk_id":"core:slash-command-template:1","text":"## Custom Slash Command Template\n\n### File: .claude/commands/review-pr.md\n```markdown\n---\nname: review-pr\ndescription: Review a pull request thoroughly\nargs:\n  - name: pr_number\n    required: true\n    description: PR number to review\n---\n\n# PR Review Command\n\nReview PR #$pr_number with the following criteria:\n\n## Code Quality\n- Check for code smells\n- Verify naming conventions\n- Look for duplication\n\n## Security\n- Check for vulnerabilities\n- Verify input validation\n- Review auth/authz\n\n## Testing\n- Are tests adequate?\n- Do tests pass?\n- Edge cases covered?\n\n## Output\nProvide structured review with:\n- Summary\n- Issues found\n- Suggestions\n- Approval recommendation\n```\n\n### Usage\n```\n/review-pr 123\n```","start_line":1,"end_line":42}]}
{"source_id":"core","type":"plan","title":"VS Code Extension Development Plan","signals":["release_install","ide_extension"],"tags":["vscode","extension","plan"],"summary":"Plan for developing VS Code extensions that integrate AI coding capabilities.","chunks":[{"chunk_id":"core:vscode-ext-plan:1","text":"## VS Code Extension Development Plan\n\n### Phase 1: Core Extension\n- [ ] Generate extension scaffold\n- [ ] Register commands\n- [ ] Implement activation events\n- [ ] Add configuration schema\n\n### Phase 2: AI Integration\n- [ ] Connect to LLM provider\n- [ ] Implement inline suggestions\n- [ ] Add chat panel\n- [ ] Context extraction from editor\n\n### Phase 3: Features\n- [ ] Code actions (quick fixes)\n- [ ] Hover information\n- [ ] Code lens (inline actions)\n- [ ] Diagnostics integration\n\n### Phase 4: UX Polish\n- [ ] Progress indicators\n- [ ] Diff preview\n- [ ] Accept/reject controls\n- [ ] Keyboard shortcuts\n\n### Extension Manifest\n```json\n{\n  \"activationEvents\": [\"onLanguage:*\"],\n  \"contributes\": {\n    \"commands\": [{\"command\": \"ai.explain\"}],\n    \"configuration\": {\"properties\": {}}\n  }\n}\n```","start_line":1,"end_line":36}]}
{"source_id":"core","type":"contract","title":"Non-Interactive Mode Contract","signals":["contract_lock","automation"],"tags":["non-interactive","scripting","contract"],"summary":"Contract for running AI coding agents in non-interactive/scripting mode for automation.","chunks":[{"chunk_id":"core:non-interactive-contract:1","text":"## Non-Interactive Mode Contract\n\n### Invocation\n```bash\n# Single prompt mode\naider --message \"Fix the bug in main.rs\" --yes\n\n# From file\naider --message-file prompt.txt --yes\n\n# Pipe input\necho \"Add tests\" | aider --yes\n```\n\n### Flags\n- `--yes`: Auto-accept all changes\n- `--no-git`: Skip git operations\n- `--no-stream`: Return complete response\n- `--exit`: Exit after completion\n\n### Use Cases\n- CI/CD pipelines\n- Batch processing\n- Automated refactoring\n- Scripted code generation\n\n### Safety Considerations\n- Review changes post-execution\n- Use version control\n- Set token/cost limits\n- Log all operations\n- Run in sandboxed environment","start_line":1,"end_line":32}]}
{"source_id":"core","type":"template","title":"Workflow Automation Template","signals":["context_engineering","automation"],"tags":["workflow","automation","template"],"summary":"Template for automating multi-step coding workflows with AI agents.","chunks":[{"chunk_id":"core:workflow-automation-template:1","text":"## Workflow Automation Template\n\n### Workflow Definition\n```yaml\nname: feature-implementation\ndescription: Implement a feature from issue\n\ntrigger:\n  event: issue_labeled\n  label: ai-implement\n\nsteps:\n  - id: analyze\n    action: read_issue\n    output: requirements\n    \n  - id: plan\n    action: ai_prompt\n    prompt: \"Create implementation plan for: $requirements\"\n    output: plan\n    \n  - id: implement\n    action: ai_code\n    prompt: \"Implement according to: $plan\"\n    files: [\"src/**/*.rs\"]\n    output: changes\n    \n  - id: test\n    action: run_tests\n    on_failure: goto(implement)\n    \n  - id: pr\n    action: create_pr\n    title: \"feat: $issue.title\"\n    body: \"Implements #$issue.number\"\n```\n\n### Workflow Engine\n- Sequential step execution\n- Variable interpolation\n- Conditional branching\n- Retry on failure\n- Human approval gates","start_line":1,"end_line":44}]}
{"source_id":"core","type":"prompt","title":"Vibecode Partnership Principles","signals":["state_machine"],"tags":["vibecode","partnership","workflow"],"summary":"Partnership model for AI-assisted development with shared ownership, vision-first discovery, and iterative delivery.","chunks":[{"chunk_id":"core:vibecode-principles:1","text":"## Vibecode Partnership Principles\n\n- AI and human are partners: AI proposes, human decides.\n- Start with vision and context before building.\n- Work iteratively in small, reviewable steps.\n- Explain reasoning and offer options with tradeoffs.\n- Build quality in: tests, security, performance.\n- Document decisions and handover notes.","start_line":1,"end_line":8}]}
{"source_id":"core","type":"prompt","title":"Vibecode 6-Step Workflow","signals":["state_machine"],"tags":["vibecode","workflow","plan"],"summary":"Six-step delivery flow from vision to documentation with clear role ownership.","chunks":[{"chunk_id":"core:vibecode-workflow:1","text":"## Vibecode 6-Step Workflow\n\n1. Vision: clarify goals and success criteria.\n2. Context: gather constraints, stack, and scope.\n3. Blueprint: propose architecture and plan.\n4. Contract: lock requirements and acceptance criteria.\n5. Build: implement in small, reviewed steps.\n6. Refine: test, secure, optimize, and document.","start_line":1,"end_line":8}]}
{"source_id":"core","type":"prompt","title":"Vibecode Master Prompt Skeleton","signals":["state_machine"],"tags":["vibecode","prompt","roles"],"summary":"Role setup and response structure for architect-homeowner collaboration.","chunks":[{"chunk_id":"core:vibecode-master:1","text":"## Vibecode Master Prompt Skeleton\n\n### Roles\n- Architect: proposes patterns and a concrete vision.\n- Homeowner: provides goals, constraints, and approvals.\n\n### Response Order\n1. Detect project type.\n2. Propose a vision with layout, style, and stack.\n3. Ask focused questions to customize.\n4. Produce blueprint and confirm contract.\n5. Implement iteratively with checkpoints.","start_line":1,"end_line":12}]}
{"source_id":"core","type":"prompt","title":"Vibecode Debug Protocol","signals":["iterate_loop"],"tags":["vibecode","debugging","protocol"],"summary":"Structured debugging steps for isolating failures and proposing targeted fixes.","chunks":[{"chunk_id":"core:vibecode-debug:1","text":"## Vibecode Debug Protocol\n\n1. Reproduce the issue.\n2. Capture error output and context.\n3. Identify the smallest failing case.\n4. Hypothesize root causes.\n5. Validate with focused checks.\n6. Apply minimal fix.\n7. Re-run failing check.\n8. Add guard tests if needed.\n9. Document fix and next risks.","start_line":1,"end_line":10}]}
{"source_id":"core","type":"prompt","title":"Vibecode QA Strategy","signals":["iterate_loop"],"tags":["vibecode","qa","testing"],"summary":"Testing framework with core, edge, and performance tiers.","chunks":[{"chunk_id":"core:vibecode-qa:1","text":"## Vibecode QA Strategy\n\n- Core tests: critical paths and business rules.\n- Edge tests: boundary cases and invalid inputs.\n- Performance checks: timing and resource thresholds.\n\nDeliverables:\n- Test list mapped to requirements.\n- Expected outcomes per tier.\n- Evidence logs for test runs.","start_line":1,"end_line":9}]}
{"source_id":"core","type":"prompt","title":"Vibecode Security Audit Checklist","signals":["security_pattern"],"tags":["vibecode","security","audit"],"summary":"Security review checklist for common application risks and controls.","chunks":[{"chunk_id":"core:vibecode-security:1","text":"## Vibecode Security Audit Checklist\n\n- Authentication and session handling.\n- Authorization on all sensitive routes.\n- Input validation and output encoding.\n- Secret handling and logging redaction.\n- Dependency vulnerabilities.\n- Secure transport and storage.","start_line":1,"end_line":8}]}
{"source_id":"core","type":"prompt","title":"Vibecode Performance Review","signals":["iterate_loop"],"tags":["vibecode","performance","optimization"],"summary":"Performance review steps covering profiling, bottlenecks, and fixes.","chunks":[{"chunk_id":"core:vibecode-performance:1","text":"## Vibecode Performance Review\n\n1. Measure baseline metrics.\n2. Identify bottlenecks.\n3. Optimize hot paths.\n4. Validate against targets.\n5. Document tradeoffs and regressions.","start_line":1,"end_line":6}]}
{"source_id":"core","type":"prompt","title":"Vibecode Integration Protocol","signals":["state_machine"],"tags":["vibecode","integration","apis"],"summary":"Integration checklist for third-party services covering auth, webhooks, and error handling.","chunks":[{"chunk_id":"core:vibecode-integration:1","text":"## Vibecode Integration Protocol\n\n- Identify provider and auth method (OAuth, API key, JWT).\n- Document required scopes and secrets.\n- Define webhook events and retry strategy.\n- Map error codes to user-facing messages.\n- Add integration tests and sandbox mode.\n- Capture evidence of successful flows.","start_line":1,"end_line":7}]}
{"source_id":"core","type":"prompt","title":"Vibecode Handover (XRAY) Checklist","signals":["evidence_audit"],"tags":["vibecode","handover","documentation"],"summary":"Handover checklist for documenting architecture, setup, and operations.","chunks":[{"chunk_id":"core:vibecode-xray:1","text":"## Vibecode Handover (XRAY) Checklist\n\n- Project overview and goals.\n- Architecture diagram and key components.\n- Setup and run instructions.\n- Environment variables and secrets.\n- Deployment steps and rollback plan.\n- Known issues and follow-up tasks.","start_line":1,"end_line":7}]}
{"source_id":"core","type":"template","title":"Agent Template Schema","signals":["command_surface"],"tags":["agent","template","prompt"],"summary":"Frontmatter and structure for defining specialized agents.","chunks":[{"chunk_id":"core:agent-template:1","text":"## Agent Template Schema\n\n---\nname: agent-name\ndescription: Use this agent when [trigger]. Specializes in [domain]. Examples: <example>Context: [situation] user: '[request]' assistant: '[response]' <commentary>[why this agent]</commentary></example>\ncolor: blue\n---\n\nYou are a [domain] specialist.\n\nYour core expertise areas:\n- **Area 1**: [capabilities]\n- **Area 2**: [capabilities]\n- **Area 3**: [capabilities]\n\n## When to Use This Agent\n- [use case 1]\n- [use case 2]\n\n## Guidance\n- Provide actionable steps and examples.","start_line":1,"end_line":17}]}
{"source_id":"core","type":"template","title":"Command Template Schema","signals":["command_surface"],"tags":["command","template","prompt"],"summary":"Structure for slash command prompts with steps, checks, and outputs.","chunks":[{"chunk_id":"core:command-template:1","text":"## Command Template Schema\n\n---\nallowed-tools: [tool-list]\nargument-hint: [args]\ndescription: [what command does]\n---\n\n# Command Name\n\n## Context\n- Detect framework or constraints.\n- Gather minimal repo context.\n\n## Task\n1. [step]\n2. [step]\n3. [step]\n\n## Quality Standards\n- Tests or checks to run.\n- Validation criteria for success.","start_line":1,"end_line":17}]}
{"source_id":"core","type":"template","title":"Plugin Bundle Manifest Schema","signals":["provider_adapter"],"tags":["plugin","bundle","registry"],"summary":"Manifest schema for grouping agents, commands, and MCP servers into bundles.","chunks":[{"chunk_id":"core:plugin-manifest:1","text":"## Plugin Bundle Manifest Schema\n\n{\n  \"name\": \"bundle-name\",\n  \"description\": \"What this bundle provides\",\n  \"version\": \"1.0.0\",\n  \"keywords\": [\"tag\"],\n  \"commands\": [\"path/to/command.md\"],\n  \"agents\": [\"path/to/agent.md\"],\n  \"mcpServers\": [\"path/to/mcp.json\"]\n}\n\nUse bundles to ship curated toolkits (security, testing, devops).","start_line":1,"end_line":14}]}
{"source_id":"core","type":"template","title":"Project Profile Template","signals":["command_surface"],"tags":["project","template","profile"],"summary":"Project profile template describing stack, commands, and conventions for AI assistance.","chunks":[{"chunk_id":"core:project-profile:1","text":"## Project Profile Template\n\n### Project Overview\n- Purpose and users\n- Tech stack and frameworks\n\n### Development Commands\n- install, test, lint, build, run\n\n### Structure and Conventions\n- Directory layout\n- Naming rules\n- Code style\n\n### Workflow\n- Before starting, during development, before shipping","start_line":1,"end_line":13}]}
{"source_id":"core","type":"prompt","title":"Agent Role Catalog","signals":["command_surface"],"tags":["agent","catalog","roles"],"summary":"Common specialist agent roles and when to use them for faster, higher-quality outcomes.","chunks":[{"chunk_id":"core:agent-catalog:1","text":"## Agent Role Catalog\n\n- Frontend Developer: UI/UX components, accessibility, CSS systems.\n- Component Reviewer: review component quality, edge cases, and API design.\n- CLI UI Designer: terminal UX, prompts, flow, and output layout.\n- MCP Expert: design MCP servers, tools, and integrations.\n- Command Expert: design CLI commands and workflows.\n\nUse a specialist when the task is deep in that domain.","start_line":1,"end_line":9}]}
{"source_id":"core","type":"prompt","title":"Command Library Patterns","signals":["command_surface"],"tags":["command","library","patterns"],"summary":"Reusable patterns for CLI command prompts and workflow automation.","chunks":[{"chunk_id":"core:command-library:1","text":"## Command Library Patterns\n\n- Define purpose, scope, and expected output.\n- List prechecks (config, dependencies, versions).\n- Provide step-by-step actions with validation.\n- Include rollback or failure handling.\n- End with next-step suggestions.","start_line":1,"end_line":7}]}
{"source_id":"core","type":"prompt","title":"Plugin Bundle Catalog","signals":["provider_adapter"],"tags":["plugin","bundle","catalog"],"summary":"Example plugin bundle categories for specialized workflows and integrations.","chunks":[{"chunk_id":"core:bundle-catalog:1","text":"## Plugin Bundle Catalog\n\n- Git Workflow: feature, release, hotfix automation.\n- Testing Suite: E2E, unit, coverage, visual tests.\n- Security Pro: audits, dependency scans, compliance.\n- DevOps Automation: CI/CD, deploy, monitoring.\n- Performance Optimizer: profiling, bundle, caching.\n- Documentation Generator: API docs and changelog.","start_line":1,"end_line":8}]}
{"source_id":"core","type":"prompt","title":"Agent Command Pairing","signals":["command_surface"],"tags":["agent","command","workflow"],"summary":"Pairing agents with commands for faster execution and higher accuracy.","chunks":[{"chunk_id":"core:agent-command-pairing:1","text":"## Agent Command Pairing\n\n- Testing Suite commands + QA/Test Engineer agents.\n- Security commands + Security Auditor agents.\n- DevOps commands + DevOps Engineer agents.\n- Docs commands + Technical Writer agents.\n\nPairing improves focus, reduces context switches, and speeds delivery.","start_line":1,"end_line":7}]}
